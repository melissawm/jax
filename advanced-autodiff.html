
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Advanced automatic differentiation &#8212; JAX  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/style.css?v=537c1ddb" />
    <link rel="stylesheet" href="_static/style.css" type="text/css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=30646c52"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'advanced-autodiff';</script>
    <link rel="icon" href="_static/favicon.png"/>
    <link rel="author" title="About these documents" href="about.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Custom pytrees and initialization with unexpected values" href="custom_pytrees.html" />
    <link rel="prev" title="Control autodiff‚Äôs saved values with jax.checkpoint (aka jax.remat)" href="notebooks/autodiff_remat.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/jax_logo_250px.png" class="logo__image only-light" alt="JAX  documentation - Home"/>
    <script>document.write(`<img src="_static/jax_logo_250px.png" class="logo__image only-dark" alt="JAX  documentation - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/thinking_in_jax.html">Quickstart: How to think in JAX</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="notebooks/Common_Gotchas_in_JAX.html">üî™ JAX - The Sharp Bits üî™</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="tutorials.html">Tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="jit-compilation.html">Just-in-time compilation</a></li>
<li class="toctree-l2"><a class="reference internal" href="automatic-vectorization.html">Automatic vectorization</a></li>
<li class="toctree-l2"><a class="reference internal" href="automatic-differentiation.html">Automatic differentiation</a></li>
<li class="toctree-l2"><a class="reference internal" href="tracing.html">Tracing</a></li>
<li class="toctree-l2"><a class="reference internal" href="random-numbers.html">Pseudorandom numbers</a></li>
<li class="toctree-l2"><a class="reference internal" href="stateful-computations.html">Stateful computations</a></li>
<li class="toctree-l2"><a class="reference internal" href="control-flow.html">Control flow and logical operators with JIT</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytrees.html">Pytrees</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro_parallel.html">Introduction to Parallel Programming with JAX</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Resources and Advanced Guides</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="key-concepts.html">Key concepts</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="advanced_guide.html">Resources and Advanced Guides</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="notebooks/autodiff_cookbook.html">The Autodiff Cookbook</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/Custom_derivative_rules_for_Python_code.html">Custom derivative rules</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/autodiff_remat.html">Control autodiff‚Äôs saved values with <code class="docutils literal notranslate"><span class="pre">jax.checkpoint</span></code> (aka <code class="docutils literal notranslate"><span class="pre">jax.remat</span></code>)</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Advanced automatic differentiation</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom_pytrees.html">Custom pytrees and initialization with unexpected values</a></li>
<li class="toctree-l2"><a class="reference internal" href="errors.html">Errors</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="debugging.html">Introduction to debugging</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="debugging/print_breakpoint.html">Compiled prints and breakpoints</a></li>
<li class="toctree-l3"><a class="reference internal" href="debugging/checkify_guide.html">The <code class="docutils literal notranslate"><span class="pre">checkify</span></code> transformation</a></li>
<li class="toctree-l3"><a class="reference internal" href="debugging/flags.html">JAX debugging flags</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="debugging/flags.html">JAX debugging flags</a></li>
<li class="toctree-l2"><a class="reference internal" href="transfer_guard.html">Transfer guard</a></li>
<li class="toctree-l2"><a class="reference internal" href="persistent_compilation_cache.html">Persistent compilation cache</a></li>
<li class="toctree-l2"><a class="reference internal" href="buffer_donation.html">Buffer donation</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu_performance_tips.html">GPU performance tips</a></li>
<li class="toctree-l2"><a class="reference internal" href="benchmarking.html">Benchmarking JAX code</a></li>
<li class="toctree-l2"><a class="reference internal" href="profiling.html">Profiling computation</a></li>
<li class="toctree-l2"><a class="reference internal" href="device_memory_profiling.html">Profiling device memory</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/Distributed_arrays_and_automatic_parallelization.html">Distributed arrays and automatic parallelization</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/explicit-sharding.html">Explicit sharding (a.k.a. ‚Äúsharding in types‚Äù)</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/shard_map.html">Manual parallelism with <code class="docutils literal notranslate"><span class="pre">shard_map</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/host-offloading.html">JAX Memories and Host Offloading</a></li>
<li class="toctree-l2"><a class="reference internal" href="multi_process.html">Introduction to multi-controller JAX (aka multi-process/multi-host JAX)</a></li>
<li class="toctree-l2"><a class="reference internal" href="distributed_data_loading.html">Distributed data loading</a></li>
<li class="toctree-l2"><a class="reference internal" href="external-callbacks.html">External callbacks</a></li>
<li class="toctree-l2"><a class="reference internal" href="ffi.html">Foreign function interface (FFI)</a></li>
<li class="toctree-l2"><a class="reference internal" href="gradient-checkpointing.html">Gradient checkpointing with <code class="docutils literal notranslate"><span class="pre">jax.checkpoint</span></code> (<code class="docutils literal notranslate"><span class="pre">jax.remat</span></code>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="aot.html">Ahead-of-time lowering and compilation</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="export/index.html">Exporting and serialization</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="export/export.html">Exporting and serializing staged-out computations</a></li>
<li class="toctree-l3"><a class="reference internal" href="export/shape_poly.html">Shape polymorphism</a></li>
<li class="toctree-l3"><a class="reference internal" href="export/jax2tf.html">Interoperation with TensorFlow</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="type_promotion.html">Type promotion semantics</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="pallas/index.html">Pallas: a JAX kernel language</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="pallas/quickstart.html">Pallas Quickstart</a></li>
<li class="toctree-l3"><a class="reference internal" href="pallas/pipelining.html">Software Pipelining</a></li>
<li class="toctree-l3"><a class="reference internal" href="pallas/grid_blockspec.html">Grids and BlockSpecs</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pallas/tpu/index.html">Pallas TPU</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="pallas/tpu/details.html">Writing TPU kernels with Pallas</a></li>
<li class="toctree-l4"><a class="reference internal" href="pallas/tpu/pipelining.html">TPU Pipelining</a></li>
<li class="toctree-l4"><a class="reference internal" href="pallas/tpu/matmul.html">Matrix Multiplication</a></li>
<li class="toctree-l4"><a class="reference internal" href="pallas/tpu/sparse.html">Scalar Prefetch and Block-Sparse Computation</a></li>
<li class="toctree-l4"><a class="reference internal" href="pallas/tpu/distributed.html">Distributed Computing in Pallas for TPUs</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pallas/gpu/index.html">Pallas:Mosaic GPU</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="pallas/gpu/reference.html">Writing Mosaic GPU kernels with Pallas</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pallas/design/index.html">Pallas Design Notes</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="pallas/design/design.html">Pallas Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="pallas/design/async_note.html">Pallas Async Operations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pallas/CHANGELOG.html">Pallas Changelog</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/neural_network_with_tfds_data.html">Training a simple neural network, with tensorflow/datasets data loading</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/Neural_Network_and_Data_Loading.html">Training a simple neural network, with PyTorch data loading</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/vmapped_log_probs.html">Autobatching for Bayesian inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/convolutions.html">Generalized convolutions in JAX</a></li>
<li class="toctree-l2"><a class="reference internal" href="xla_flags.html">List of XLA compiler flags</a></li>
<li class="toctree-l2"><a class="reference internal" href="sharded-computation.html">Introduction to parallel programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax-primitives.html">JAX Internals: primitives</a></li>
<li class="toctree-l2"><a class="reference internal" href="jaxpr.html">JAX internals: The jaxpr language</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="contributor_guide.html">Developer notes</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="contributing.html">Contributing to JAX</a></li>
<li class="toctree-l2"><a class="reference internal" href="developer.html">Building from source</a></li>
<li class="toctree-l2"><a class="reference internal" href="investigating_a_regression.html">Investigating a regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="autodidax.html">Autodidax: JAX core from scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="autodidax2_part1.html">Autodidax2, part 1: JAX from scratch, again</a></li>

<li class="toctree-l2 has-children"><a class="reference internal" href="jep/index.html">JAX Enhancement Proposals (JEPs)</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="jep/263-prng.html">263: JAX PRNG Design</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/2026-custom-derivatives.html">2026: Custom JVP/VJP rules for JAX-transformable functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/4008-custom-vjp-update.html">4008: Custom VJP and `nondiff_argnums` update</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/4410-omnistaging.html">4410: Omnistaging</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/9263-typed-keys.html">9263: Typed keys &amp; pluggable RNGs</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/9407-type-promotion.html">9407: Design of Type Promotion Semantics for JAX</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/9419-jax-versioning.html">9419: Jax and Jaxlib versioning</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/10657-sequencing-effects.html">10657: Sequencing side-effects in JAX</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/11830-new-remat-checkpoint.html">11830: `jax.remat` / `jax.checkpoint` new implementation</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/12049-type-annotations.html">12049: Type Annotation Roadmap for JAX</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/14273-shard-map.html">14273: `shard_map` (`shmap`) for simple per-device code</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/15856-jex.html">15856: `jax.extend`, an extensions module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/17111-shmap-transpose.html">17111: Efficient transposition of `shard_map` (and other maps)</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/18137-numpy-scipy-scope.html">18137: Scope of JAX NumPy &amp; SciPy Wrappers</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/25516-effver.html">25516: Effort-based versioning</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/28661-jax-array-protocol.html">28661: Supporting the `__jax_array__` protocol</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="extensions.html">Extension guides</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="notebooks/Writing_custom_interpreters_in_Jax.html">Writing custom Jaxpr interpreters in JAX</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="jax.extend.html"><code class="docutils literal notranslate"><span class="pre">jax.extend</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="jax.extend.core.html"><code class="docutils literal notranslate"><span class="pre">jax.extend.core</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.extend.linear_util.html"><code class="docutils literal notranslate"><span class="pre">jax.extend.linear_util</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.extend.mlir.html"><code class="docutils literal notranslate"><span class="pre">jax.extend.mlir</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.extend.random.html"><code class="docutils literal notranslate"><span class="pre">jax.extend.random</span></code> module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="building_on_jax.html">Building on JAX</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="notes.html">Notes</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="api_compatibility.html">API compatibility</a></li>
<li class="toctree-l2"><a class="reference internal" href="deprecation.html">Python and NumPy version support policy</a></li>
<li class="toctree-l2"><a class="reference internal" href="async_dispatch.html">Asynchronous dispatch</a></li>
<li class="toctree-l2"><a class="reference internal" href="concurrency.html">Concurrency</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu_memory_allocation.html">GPU memory allocation</a></li>
<li class="toctree-l2"><a class="reference internal" href="rank_promotion_warning.html">Rank promotion warning</a></li>
<li class="toctree-l2"><a class="reference internal" href="default_dtypes.html">Default dtypes and the X64 flag</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="jax.html">Public API: <code class="docutils literal notranslate"><span class="pre">jax</span></code> package</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="jax.numpy.html"><code class="docutils literal notranslate"><span class="pre">jax.numpy</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.fft.html">jax.numpy.fft.fft</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.fft2.html">jax.numpy.fft.fft2</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.fftfreq.html">jax.numpy.fft.fftfreq</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.fftn.html">jax.numpy.fft.fftn</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.fftshift.html">jax.numpy.fft.fftshift</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.hfft.html">jax.numpy.fft.hfft</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.ifft.html">jax.numpy.fft.ifft</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.ifft2.html">jax.numpy.fft.ifft2</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.ifftn.html">jax.numpy.fft.ifftn</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.ifftshift.html">jax.numpy.fft.ifftshift</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.ihfft.html">jax.numpy.fft.ihfft</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.irfft.html">jax.numpy.fft.irfft</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.irfft2.html">jax.numpy.fft.irfft2</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.irfftn.html">jax.numpy.fft.irfftn</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.rfft.html">jax.numpy.fft.rfft</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.rfft2.html">jax.numpy.fft.rfft2</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.rfftfreq.html">jax.numpy.fft.rfftfreq</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.rfftn.html">jax.numpy.fft.rfftn</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="jax.scipy.html"><code class="docutils literal notranslate"><span class="pre">jax.scipy</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.scipy.stats.bernoulli.logpmf.html">jax.scipy.stats.bernoulli.logpmf</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.scipy.stats.bernoulli.pmf.html">jax.scipy.stats.bernoulli.pmf</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.scipy.stats.bernoulli.cdf.html">jax.scipy.stats.bernoulli.cdf</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.scipy.stats.bernoulli.ppf.html">jax.scipy.stats.bernoulli.ppf</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="jax.lax.html"><code class="docutils literal notranslate"><span class="pre">jax.lax</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.random.html"><code class="docutils literal notranslate"><span class="pre">jax.random</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.sharding.html"><code class="docutils literal notranslate"><span class="pre">jax.sharding</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.debug.html"><code class="docutils literal notranslate"><span class="pre">jax.debug</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.dlpack.html"><code class="docutils literal notranslate"><span class="pre">jax.dlpack</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.distributed.html"><code class="docutils literal notranslate"><span class="pre">jax.distributed</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.dtypes.html"><code class="docutils literal notranslate"><span class="pre">jax.dtypes</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.ffi.html"><code class="docutils literal notranslate"><span class="pre">jax.ffi</span></code> module</a></li>

<li class="toctree-l2"><a class="reference internal" href="jax.flatten_util.html"><code class="docutils literal notranslate"><span class="pre">jax.flatten_util</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.image.html"><code class="docutils literal notranslate"><span class="pre">jax.image</span></code> module</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="jax.nn.html"><code class="docutils literal notranslate"><span class="pre">jax.nn</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="jax.nn.initializers.html"><code class="docutils literal notranslate"><span class="pre">jax.nn.initializers</span></code> module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="jax.ops.html"><code class="docutils literal notranslate"><span class="pre">jax.ops</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.profiler.html"><code class="docutils literal notranslate"><span class="pre">jax.profiler</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.stages.html"><code class="docutils literal notranslate"><span class="pre">jax.stages</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.test_util.html"><code class="docutils literal notranslate"><span class="pre">jax.test_util</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.tree.html"><code class="docutils literal notranslate"><span class="pre">jax.tree</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.tree_util.html"><code class="docutils literal notranslate"><span class="pre">jax.tree_util</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.typing.html"><code class="docutils literal notranslate"><span class="pre">jax.typing</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.export.html"><code class="docutils literal notranslate"><span class="pre">jax.export</span></code> module</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="jax.extend.html"><code class="docutils literal notranslate"><span class="pre">jax.extend</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="jax.extend.core.html"><code class="docutils literal notranslate"><span class="pre">jax.extend.core</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.extend.linear_util.html"><code class="docutils literal notranslate"><span class="pre">jax.extend.linear_util</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.extend.mlir.html"><code class="docutils literal notranslate"><span class="pre">jax.extend.mlir</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.extend.random.html"><code class="docutils literal notranslate"><span class="pre">jax.extend.random</span></code> module</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="jax.example_libraries.html"><code class="docutils literal notranslate"><span class="pre">jax.example_libraries</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="jax.example_libraries.optimizers.html"><code class="docutils literal notranslate"><span class="pre">jax.example_libraries.optimizers</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.example_libraries.stax.html"><code class="docutils literal notranslate"><span class="pre">jax.example_libraries.stax</span></code> module</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="jax.experimental.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-20"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="jax.experimental.checkify.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.checkify</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.experimental.compilation_cache.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.compilation_cache</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.experimental.custom_dce.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.custom_dce</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.experimental.custom_partitioning.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.custom_partitioning</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.experimental.jet.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.jet</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.experimental.key_reuse.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.key_reuse</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.experimental.mesh_utils.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.mesh_utils</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.experimental.multihost_utils.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.multihost_utils</span></code> module</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="jax.experimental.pallas.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.pallas</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-21"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="jax.experimental.pallas.mosaic_gpu.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.pallas.mosaic_gpu</span></code> module</a></li>
<li class="toctree-l4"><a class="reference internal" href="jax.experimental.pallas.triton.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.pallas.triton</span></code> module</a></li>
<li class="toctree-l4"><a class="reference internal" href="jax.experimental.pallas.tpu.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.pallas.tpu</span></code> module</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="jax.experimental.pjit.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.pjit</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.experimental.serialize_executable.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.serialize_executable</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.experimental.shard_map.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.shard_map</span></code> module</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="jax.experimental.sparse.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.sparse</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-22"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.BCOO.html">jax.experimental.sparse.BCOO</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_broadcast_in_dim.html">jax.experimental.sparse.bcoo_broadcast_in_dim</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_concatenate.html">jax.experimental.sparse.bcoo_concatenate</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_dot_general.html">jax.experimental.sparse.bcoo_dot_general</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_dot_general_sampled.html">jax.experimental.sparse.bcoo_dot_general_sampled</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_dynamic_slice.html">jax.experimental.sparse.bcoo_dynamic_slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_extract.html">jax.experimental.sparse.bcoo_extract</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_fromdense.html">jax.experimental.sparse.bcoo_fromdense</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_gather.html">jax.experimental.sparse.bcoo_gather</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_multiply_dense.html">jax.experimental.sparse.bcoo_multiply_dense</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_multiply_sparse.html">jax.experimental.sparse.bcoo_multiply_sparse</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_update_layout.html">jax.experimental.sparse.bcoo_update_layout</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_reduce_sum.html">jax.experimental.sparse.bcoo_reduce_sum</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_reshape.html">jax.experimental.sparse.bcoo_reshape</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_slice.html">jax.experimental.sparse.bcoo_slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_sort_indices.html">jax.experimental.sparse.bcoo_sort_indices</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_squeeze.html">jax.experimental.sparse.bcoo_squeeze</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_sum_duplicates.html">jax.experimental.sparse.bcoo_sum_duplicates</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_todense.html">jax.experimental.sparse.bcoo_todense</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_transpose.html">jax.experimental.sparse.bcoo_transpose</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="jax.lib.html"><code class="docutils literal notranslate"><span class="pre">jax.lib</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.addressable_shards.html">jax.Array.addressable_shards</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.all.html">jax.Array.all</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.any.html">jax.Array.any</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.argmax.html">jax.Array.argmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.argmin.html">jax.Array.argmin</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.argpartition.html">jax.Array.argpartition</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.argsort.html">jax.Array.argsort</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.astype.html">jax.Array.astype</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.at.html">jax.Array.at</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.choose.html">jax.Array.choose</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.clip.html">jax.Array.clip</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.compress.html">jax.Array.compress</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.committed.html">jax.Array.committed</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.conj.html">jax.Array.conj</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.conjugate.html">jax.Array.conjugate</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.copy.html">jax.Array.copy</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.copy_to_host_async.html">jax.Array.copy_to_host_async</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.cumprod.html">jax.Array.cumprod</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.cumsum.html">jax.Array.cumsum</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.device.html">jax.Array.device</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.diagonal.html">jax.Array.diagonal</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.dot.html">jax.Array.dot</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.dtype.html">jax.Array.dtype</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.flat.html">jax.Array.flat</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.flatten.html">jax.Array.flatten</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.global_shards.html">jax.Array.global_shards</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.imag.html">jax.Array.imag</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.is_fully_addressable.html">jax.Array.is_fully_addressable</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.is_fully_replicated.html">jax.Array.is_fully_replicated</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.item.html">jax.Array.item</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.itemsize.html">jax.Array.itemsize</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.max.html">jax.Array.max</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.mean.html">jax.Array.mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.min.html">jax.Array.min</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.nbytes.html">jax.Array.nbytes</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.ndim.html">jax.Array.ndim</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.nonzero.html">jax.Array.nonzero</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.prod.html">jax.Array.prod</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.ptp.html">jax.Array.ptp</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.ravel.html">jax.Array.ravel</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.real.html">jax.Array.real</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.repeat.html">jax.Array.repeat</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.reshape.html">jax.Array.reshape</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.round.html">jax.Array.round</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.searchsorted.html">jax.Array.searchsorted</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.shape.html">jax.Array.shape</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.sharding.html">jax.Array.sharding</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.size.html">jax.Array.size</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.sort.html">jax.Array.sort</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.squeeze.html">jax.Array.squeeze</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.std.html">jax.Array.std</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.sum.html">jax.Array.sum</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.swapaxes.html">jax.Array.swapaxes</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.take.html">jax.Array.take</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.to_device.html">jax.Array.to_device</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.trace.html">jax.Array.trace</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.transpose.html">jax.Array.transpose</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.var.html">jax.Array.var</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.view.html">jax.Array.view</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.T.html">jax.Array.T</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.mT.html">jax.Array.mT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="about.html">About the project</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="faq.html">Frequently asked questions (FAQ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">Change log</a></li>
<li class="toctree-l1"><a class="reference internal" href="glossary.html">Glossary of terms</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="config_options.html">Configuration Options</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="advanced_guide.html" class="nav-link">Resources and Advanced Guides</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Advanced...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/jax-ml/jax" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/advanced-autodiff.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Advanced automatic differentiation</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#taking-gradients-part-2">Taking gradients (part 2)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#higher-order-derivatives">Higher-order derivatives</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#higher-order-optimization">Higher-order optimization</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stopping-gradients">Stopping gradients</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#straight-through-estimator-using-stop-gradient">Straight-through estimator using <code class="docutils literal notranslate"><span class="pre">stop_gradient</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#per-example-gradients">Per-example gradients</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hessian-vector-products-with-jax-grad-of-jax-grad">Hessian-vector products with <code class="docutils literal notranslate"><span class="pre">jax.grad</span></code>-of-<code class="docutils literal notranslate"><span class="pre">jax.grad</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#jacobians-and-hessians-using-jax-jacfwd-and-jax-jacrev">Jacobians and Hessians using <code class="docutils literal notranslate"><span class="pre">jax.jacfwd</span></code> and <code class="docutils literal notranslate"><span class="pre">jax.jacrev</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-it-s-made-two-foundational-autodiff-functions">How it‚Äôs made: Two foundational autodiff functions</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#jacobian-vector-products-jvps-a-k-a-forward-mode-autodiff">Jacobian-Vector products (JVPs, a.k.a. forward-mode autodiff)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#jvps-in-math">JVPs in math</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#jvps-in-jax-code">JVPs in JAX code</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vector-jacobian-products-vjps-a-k-a-reverse-mode-autodiff">Vector-Jacobian products (VJPs, a.k.a. reverse-mode autodiff)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#vjps-in-math">VJPs in math</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#vjps-in-jax-code">VJPs in JAX code</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vector-valued-gradients-with-vjps">Vector-valued gradients with VJPs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hessian-vector-products-using-both-forward-and-reverse-mode">Hessian-vector products using both forward- and reverse-mode</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#composing-vjps-jvps-and-jax-vmap">Composing VJPs, JVPs, and <code class="docutils literal notranslate"><span class="pre">jax.vmap</span></code></a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#jacobian-matrix-and-matrix-jacobian-products">Jacobian-Matrix and Matrix-Jacobian products</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-implementation-of-jax-jacfwd-and-jax-jacrev">The implementation of <code class="docutils literal notranslate"><span class="pre">jax.jacfwd</span></code> and <code class="docutils literal notranslate"><span class="pre">jax.jacrev</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#complex-numbers-and-differentiation">Complex numbers and differentiation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#custom-derivative-rules-for-jax-transformable-python-functions">Custom derivative rules for JAX-transformable Python functions</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tl-dr-custom-jvps-with-jax-custom-jvp">TL;DR: Custom JVPs with <code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_jvp()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tl-dr-custom-vjps-with-jax-custom-vjp">TL;DR: Custom VJPs with <code class="docutils literal notranslate"><span class="pre">jax.custom_vjp</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-problems">Example problems</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-numerical-stability">Example: Numerical stability</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-enforcing-a-differentiation-convention">Example: Enforcing a differentiation convention</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-gradient-clipping">Example: Gradient clipping</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-python-debugging">Example: Python debugging</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-implicit-function-differentiation-of-iterative-implementations">Example: Implicit function differentiation of iterative implementations</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-usage-of-jax-custom-jvp-and-jax-custom-vjp-apis">Basic usage of <code class="docutils literal notranslate"><span class="pre">jax.custom_jvp</span></code> and <code class="docutils literal notranslate"><span class="pre">jax.custom_vjp</span></code> APIs</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#use-jax-custom-jvp-to-define-forward-mode-and-indirectly-reverse-mode-rules">Use <code class="docutils literal notranslate"><span class="pre">jax.custom_jvp</span></code> to define forward-mode (and, indirectly, reverse-mode) rules</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#use-jax-custom-vjp-to-define-custom-reverse-mode-only-rules">Use <code class="docutils literal notranslate"><span class="pre">jax.custom_vjp</span></code> to define custom reverse-mode-only rules</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#more-features-and-details">More features and details</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#working-with-list-tuple-dict-containers-and-other-pytrees">Working with <code class="docutils literal notranslate"><span class="pre">list</span></code> / <code class="docutils literal notranslate"><span class="pre">tuple</span></code> / <code class="docutils literal notranslate"><span class="pre">dict</span></code> containers (and other pytrees)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#handling-non-differentiable-arguments">Handling  non-differentiable arguments</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#jax-custom-jvp-with-nondiff-argnums"><code class="docutils literal notranslate"><span class="pre">jax.custom_jvp</span></code> with <code class="docutils literal notranslate"><span class="pre">nondiff_argnums</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#jax-custom-vjp-with-nondiff-argnums"><code class="docutils literal notranslate"><span class="pre">jax.custom_vjp</span></code> with <code class="docutils literal notranslate"><span class="pre">nondiff_argnums</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#next-steps">Next steps</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="advanced-automatic-differentiation">
<span id="advanced-autodiff"></span><h1>Advanced automatic differentiation<a class="headerlink" href="#advanced-automatic-differentiation" title="Link to this heading">#</a></h1>
<!--* freshness: { reviewed: '2024-05-14' } *-->
<p>In this tutorial, you will learn about complex applications of automatic differentiation (autodiff) in JAX and gain a better understanding of how taking derivatives in JAX can be both easy and powerful.</p>
<p>Make sure to check out the <a class="reference internal" href="automatic-differentiation.html#automatic-differentiation"><span class="std std-ref">Automatic differentiation</span></a> tutorial to go over the JAX autodiff basics, if you haven‚Äôt already.</p>
<section id="setup">
<h2>Setup<a class="headerlink" href="#setup" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">jax</span>
<span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">jnp</span>
<span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">grad</span><span class="p">,</span> <span class="n">jit</span><span class="p">,</span> <span class="n">vmap</span>
<span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">random</span>

<span class="n">key</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">key</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="taking-gradients-part-2">
<h2>Taking gradients (part 2)<a class="headerlink" href="#taking-gradients-part-2" title="Link to this heading">#</a></h2>
<section id="higher-order-derivatives">
<h3>Higher-order derivatives<a class="headerlink" href="#higher-order-derivatives" title="Link to this heading">#</a></h3>
<p>JAX‚Äôs autodiff makes it easy to compute higher-order derivatives, because the functions that compute derivatives are themselves differentiable. Thus, higher-order derivatives are as easy as stacking transformations.</p>
<p>The single-variable case was covered in the <a class="reference internal" href="automatic-differentiation.html#automatic-differentiation"><span class="std std-ref">Automatic differentiation</span></a> tutorial, where the example showed how to use <a class="reference internal" href="_autosummary/jax.grad.html#jax.grad" title="jax.grad"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.grad()</span></code></a> to compute the the derivative of <span class="math notranslate nohighlight">\(f(x) = x^3 + 2x^2 - 3x + 1\)</span>.</p>
<p>In the multivariable case, higher-order derivatives are more complicated. The second-order derivative of a function is represented by its <a class="reference external" href="https://en.wikipedia.org/wiki/Hessian_matrix">Hessian matrix</a>, defined according to:</p>
<div class="math notranslate nohighlight">
\[(\mathbf{H}f)_{i,j} = \frac{\partial^2 f}{\partial_i\partial_j}.\]</div>
<p>The Hessian of a real-valued function of several variables, <span class="math notranslate nohighlight">\(f: \mathbb R^n\to\mathbb R\)</span>, can be identified with the <a class="reference external" href="https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant">Jacobian</a> of its gradient.</p>
<p>JAX provides two transformations for computing the Jacobian of a function, <a class="reference internal" href="_autosummary/jax.jacfwd.html#jax.jacfwd" title="jax.jacfwd"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jacfwd()</span></code></a> and <a class="reference internal" href="_autosummary/jax.jacrev.html#jax.jacrev" title="jax.jacrev"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jacrev()</span></code></a>, corresponding to forward- and reverse-mode autodiff. They give the same answer, but one can be more efficient than the other in different circumstances ‚Äì refer to the <a class="reference external" href="https://www.youtube.com/watch?v=wG_nF1awSSY">video about autodiff</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">hessian</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">jax</span><span class="o">.</span><span class="n">jacfwd</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs double check this is correct on the dot-product <span class="math notranslate nohighlight">\(f: \mathbf{x} \mapsto \mathbf{x} ^\top \mathbf{x}\)</span>.</p>
<p>if <span class="math notranslate nohighlight">\(i=j\)</span>, <span class="math notranslate nohighlight">\(\frac{\partial^2 f}{\partial_i\partial_j}(\mathbf{x}) = 2\)</span>. Otherwise, <span class="math notranslate nohighlight">\(\frac{\partial^2 f}{\partial_i\partial_j}(\mathbf{x}) = 0\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

<span class="n">hessian</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Array([[2., 0., 0.],
       [0., 2., 0.],
       [0., 0., 2.]], dtype=float32)
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="higher-order-optimization">
<h2>Higher-order optimization<a class="headerlink" href="#higher-order-optimization" title="Link to this heading">#</a></h2>
<p>Some meta-learning techniques, such as Model-Agnostic Meta-Learning (<a class="reference external" href="https://arxiv.org/abs/1703.03400">MAML</a>), require differentiating through gradient updates. In other frameworks this can be quite cumbersome, but in JAX it‚Äôs much easier:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">meta_loss_fn</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Computes the loss after one step of SGD.&quot;&quot;&quot;</span>
  <span class="n">grads</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">)(</span><span class="n">params</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">params</span> <span class="o">-</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">grads</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>

<span class="n">meta_grads</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">meta_loss_fn</span><span class="p">)(</span><span class="n">params</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<section id="stopping-gradients">
<span id="id1"></span><h3>Stopping gradients<a class="headerlink" href="#stopping-gradients" title="Link to this heading">#</a></h3>
<p>Autodiff enables automatic computation of the gradient of a function with respect to its inputs. Sometimes, however, you might want some additional control: for instance, you might want to avoid backpropagating gradients through some subset of the computational graph.</p>
<p>Consider for instance the TD(0) (<a class="reference external" href="https://en.wikipedia.org/wiki/Temporal_difference_learning">temporal difference</a>) reinforcement learning update. This is used to learn to estimate the <em>value</em> of a state in an environment from experience of interacting with the environment. Let‚Äôs assume the value estimate <span class="math notranslate nohighlight">\(v_{\theta}(s_{t-1}\)</span>) in a state <span class="math notranslate nohighlight">\(s_{t-1}\)</span> is parameterised by a linear function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Value function and initial parameters</span>
<span class="n">value_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">theta</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Consider a transition from a state <span class="math notranslate nohighlight">\(s_{t-1}\)</span> to a state <span class="math notranslate nohighlight">\(s_t\)</span> during which you observed the reward <span class="math notranslate nohighlight">\(r_t\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># An example transition.</span>
<span class="n">s_tm1</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">])</span>
<span class="n">r_t</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mf">1.</span><span class="p">)</span>
<span class="n">s_t</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>The TD(0) update to the network parameters is:</p>
<div class="math notranslate nohighlight">
\[
\Delta \theta = (r_t + v_{\theta}(s_t) - v_{\theta}(s_{t-1})) \nabla v_{\theta}(s_{t-1})
\]</div>
<p>This update is not the gradient of any loss function.</p>
<p>However, it can be <strong>written</strong> as the gradient of the pseudo loss function</p>
<div class="math notranslate nohighlight">
\[
L(\theta) = - \frac{1}{2} [r_t + v_{\theta}(s_t) - v_{\theta}(s_{t-1})]^2
\]</div>
<p>if the dependency of the target <span class="math notranslate nohighlight">\(r_t + v_{\theta}(s_t)\)</span> on the parameter <span class="math notranslate nohighlight">\(\theta\)</span> is ignored.</p>
<p>How can you implement this in JAX? If you write the pseudo loss naively, you get:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">td_loss</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">s_tm1</span><span class="p">,</span> <span class="n">r_t</span><span class="p">,</span> <span class="n">s_t</span><span class="p">):</span>
  <span class="n">v_tm1</span> <span class="o">=</span> <span class="n">value_fn</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">s_tm1</span><span class="p">)</span>
  <span class="n">target</span> <span class="o">=</span> <span class="n">r_t</span> <span class="o">+</span> <span class="n">value_fn</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">s_t</span><span class="p">)</span>
  <span class="k">return</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">target</span> <span class="o">-</span> <span class="n">v_tm1</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">td_update</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">td_loss</span><span class="p">)</span>
<span class="n">delta_theta</span> <span class="o">=</span> <span class="n">td_update</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">s_tm1</span><span class="p">,</span> <span class="n">r_t</span><span class="p">,</span> <span class="n">s_t</span><span class="p">)</span>

<span class="n">delta_theta</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Array([-1.2,  1.2, -1.2], dtype=float32)
</pre></div>
</div>
</div>
</div>
<p>But <code class="docutils literal notranslate"><span class="pre">td_update</span></code> will <strong>not</strong> compute a TD(0) update, because the gradient computation will include the dependency of <code class="docutils literal notranslate"><span class="pre">target</span></code> on <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
<p>You can use <a class="reference internal" href="_autosummary/jax.lax.stop_gradient.html#jax.lax.stop_gradient" title="jax.lax.stop_gradient"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.lax.stop_gradient()</span></code></a> to force JAX to ignore the dependency of the target on <span class="math notranslate nohighlight">\(\theta\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">td_loss</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">s_tm1</span><span class="p">,</span> <span class="n">r_t</span><span class="p">,</span> <span class="n">s_t</span><span class="p">):</span>
  <span class="n">v_tm1</span> <span class="o">=</span> <span class="n">value_fn</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">s_tm1</span><span class="p">)</span>
  <span class="n">target</span> <span class="o">=</span> <span class="n">r_t</span> <span class="o">+</span> <span class="n">value_fn</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">s_t</span><span class="p">)</span>
  <span class="k">return</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">((</span><span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">stop_gradient</span><span class="p">(</span><span class="n">target</span><span class="p">)</span> <span class="o">-</span> <span class="n">v_tm1</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">td_update</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">td_loss</span><span class="p">)</span>
<span class="n">delta_theta</span> <span class="o">=</span> <span class="n">td_update</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">s_tm1</span><span class="p">,</span> <span class="n">r_t</span><span class="p">,</span> <span class="n">s_t</span><span class="p">)</span>

<span class="n">delta_theta</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Array([ 1.2,  2.4, -1.2], dtype=float32)
</pre></div>
</div>
</div>
</div>
<p>This will treat <code class="docutils literal notranslate"><span class="pre">target</span></code> as if it did <strong>not</strong> depend on the parameters <span class="math notranslate nohighlight">\(\theta\)</span> and compute the correct update to the parameters.</p>
<p>Now, let‚Äôs also calculate <span class="math notranslate nohighlight">\(\Delta \theta\)</span> using the original TD(0) update expression, to cross-check our work. You may wish to try and implement this yourself using <a class="reference internal" href="_autosummary/jax.grad.html#jax.grad" title="jax.grad"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.grad()</span></code></a> and your knowledge so far. Here‚Äôs our solution:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">s_grad</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">value_fn</span><span class="p">)(</span><span class="n">theta</span><span class="p">,</span> <span class="n">s_tm1</span><span class="p">)</span>
<span class="n">delta_theta_original_calculation</span> <span class="o">=</span> <span class="p">(</span><span class="n">r_t</span> <span class="o">+</span> <span class="n">value_fn</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">s_t</span><span class="p">)</span> <span class="o">-</span> <span class="n">value_fn</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">s_tm1</span><span class="p">))</span> <span class="o">*</span> <span class="n">s_grad</span>

<span class="n">delta_theta_original_calculation</span> <span class="c1"># [1.2, 2.4, -1.2], same as `delta_theta`</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Array([ 1.2,  2.4, -1.2], dtype=float32)
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">jax.lax.stop_gradient</span></code> may also be useful in other settings, for instance if you want the gradient from some loss to only affect a subset of the parameters of the neural network (because, for instance, the other parameters are trained using a different loss).</p>
</section>
<section id="straight-through-estimator-using-stop-gradient">
<h3>Straight-through estimator using <code class="docutils literal notranslate"><span class="pre">stop_gradient</span></code><a class="headerlink" href="#straight-through-estimator-using-stop-gradient" title="Link to this heading">#</a></h3>
<p>The straight-through estimator is a trick for defining a ‚Äògradient‚Äô of a function that is otherwise non-differentiable. Given a non-differentiable function <span class="math notranslate nohighlight">\(f : \mathbb{R}^n \to \mathbb{R}^n\)</span> that is used as part of a larger function that we wish to find a gradient of, we simply pretend during the backward pass that <span class="math notranslate nohighlight">\(f\)</span> is the identity function. This can be implemented neatly using <code class="docutils literal notranslate"><span class="pre">jax.lax.stop_gradient</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># non-differentiable</span>

<span class="k">def</span> <span class="nf">straight_through_f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="c1"># Create an exactly-zero expression with Sterbenz lemma that has</span>
  <span class="c1"># an exactly-one gradient.</span>
  <span class="n">zero</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">stop_gradient</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">zero</span> <span class="o">+</span> <span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">stop_gradient</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;f(x): &quot;</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="mf">3.2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;straight_through_f(x):&quot;</span><span class="p">,</span> <span class="n">straight_through_f</span><span class="p">(</span><span class="mf">3.2</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;grad(f)(x):&quot;</span><span class="p">,</span> <span class="n">jax</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="mf">3.2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;grad(straight_through_f)(x):&quot;</span><span class="p">,</span> <span class="n">jax</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">straight_through_f</span><span class="p">)(</span><span class="mf">3.2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>f(x):  3.0
straight_through_f(x): 3.0
grad(f)(x): 0.0
grad(straight_through_f)(x): 1.0
</pre></div>
</div>
</div>
</div>
</section>
<section id="per-example-gradients">
<h3>Per-example gradients<a class="headerlink" href="#per-example-gradients" title="Link to this heading">#</a></h3>
<p>While most ML systems compute gradients and updates from batches of data, for reasons of computational efficiency and/or variance reduction, it is sometimes necessary to have access to the gradient/update associated with each specific sample in the batch.</p>
<p>For instance, this is needed to prioritize data based on gradient magnitude, or to apply clipping / normalisations on a sample by sample basis.</p>
<p>In many frameworks (PyTorch, TF, Theano) it is often not trivial to compute per-example gradients, because the library directly accumulates the gradient over the batch. Naive workarounds, such as computing a separate loss per example and then aggregating the resulting gradients are typically very inefficient.</p>
<p>In JAX, you can define the code to compute the gradient per-sample in an easy but efficient way.</p>
<p>Just combine the <a class="reference internal" href="_autosummary/jax.jit.html#jax.jit" title="jax.jit"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jit()</span></code></a>, <a class="reference internal" href="_autosummary/jax.vmap.html#jax.vmap" title="jax.vmap"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.vmap()</span></code></a> and <a class="reference internal" href="_autosummary/jax.grad.html#jax.grad" title="jax.grad"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.grad()</span></code></a> transformations together:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">perex_grads</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">td_loss</span><span class="p">),</span> <span class="n">in_axes</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)))</span>

<span class="c1"># Test it:</span>
<span class="n">batched_s_tm1</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">s_tm1</span><span class="p">,</span> <span class="n">s_tm1</span><span class="p">])</span>
<span class="n">batched_r_t</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">r_t</span><span class="p">,</span> <span class="n">r_t</span><span class="p">])</span>
<span class="n">batched_s_t</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">s_t</span><span class="p">,</span> <span class="n">s_t</span><span class="p">])</span>

<span class="n">perex_grads</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">batched_s_tm1</span><span class="p">,</span> <span class="n">batched_r_t</span><span class="p">,</span> <span class="n">batched_s_t</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Array([[ 1.2,  2.4, -1.2],
       [ 1.2,  2.4, -1.2]], dtype=float32)
</pre></div>
</div>
</div>
</div>
<p>Let‚Äôs go through this one transformation at a time.</p>
<p>First, you apply <a class="reference internal" href="_autosummary/jax.grad.html#jax.grad" title="jax.grad"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.grad()</span></code></a> to <code class="docutils literal notranslate"><span class="pre">td_loss</span></code> to obtain a function that computes the gradient of the loss w.r.t. the parameters on single (unbatched) inputs:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dtdloss_dtheta</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">td_loss</span><span class="p">)</span>

<span class="n">dtdloss_dtheta</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">s_tm1</span><span class="p">,</span> <span class="n">r_t</span><span class="p">,</span> <span class="n">s_t</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Array([ 1.2,  2.4, -1.2], dtype=float32)
</pre></div>
</div>
</div>
</div>
<p>This function computes one row of the array above.</p>
<p>Then, you vectorise this function using <a class="reference internal" href="_autosummary/jax.vmap.html#jax.vmap" title="jax.vmap"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.vmap()</span></code></a>. This adds a batch dimension to all inputs and outputs. Now, given a batch of inputs, you produce a batch of outputs ‚Äî each output in the batch corresponds to the gradient for the corresponding member of the input batch.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">almost_perex_grads</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">dtdloss_dtheta</span><span class="p">)</span>

<span class="n">batched_theta</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">theta</span><span class="p">,</span> <span class="n">theta</span><span class="p">])</span>
<span class="n">almost_perex_grads</span><span class="p">(</span><span class="n">batched_theta</span><span class="p">,</span> <span class="n">batched_s_tm1</span><span class="p">,</span> <span class="n">batched_r_t</span><span class="p">,</span> <span class="n">batched_s_t</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Array([[ 1.2,  2.4, -1.2],
       [ 1.2,  2.4, -1.2]], dtype=float32)
</pre></div>
</div>
</div>
</div>
<p>This isn‚Äôt quite what we want, because we have to manually feed this function a batch of <code class="docutils literal notranslate"><span class="pre">theta</span></code>s, whereas we actually want to use a single <code class="docutils literal notranslate"><span class="pre">theta</span></code>. We fix this by adding <code class="docutils literal notranslate"><span class="pre">in_axes</span></code> to the <a class="reference internal" href="_autosummary/jax.vmap.html#jax.vmap" title="jax.vmap"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.vmap()</span></code></a>, specifying theta as <code class="docutils literal notranslate"><span class="pre">None</span></code>, and the other args as <code class="docutils literal notranslate"><span class="pre">0</span></code>. This makes the resulting function add an extra axis only to the other arguments, leaving <code class="docutils literal notranslate"><span class="pre">theta</span></code> unbatched, as we want:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inefficient_perex_grads</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">dtdloss_dtheta</span><span class="p">,</span> <span class="n">in_axes</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>

<span class="n">inefficient_perex_grads</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">batched_s_tm1</span><span class="p">,</span> <span class="n">batched_r_t</span><span class="p">,</span> <span class="n">batched_s_t</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Array([[ 1.2,  2.4, -1.2],
       [ 1.2,  2.4, -1.2]], dtype=float32)
</pre></div>
</div>
</div>
</div>
<p>This does what we want, but is slower than it has to be. Now, you wrap the whole thing in a <a class="reference internal" href="_autosummary/jax.jit.html#jax.jit" title="jax.jit"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jit()</span></code></a> to get the compiled, efficient version of the same function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">perex_grads</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">inefficient_perex_grads</span><span class="p">)</span>

<span class="n">perex_grads</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">batched_s_tm1</span><span class="p">,</span> <span class="n">batched_r_t</span><span class="p">,</span> <span class="n">batched_s_t</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Array([[ 1.2,  2.4, -1.2],
       [ 1.2,  2.4, -1.2]], dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">timeit</span> inefficient_perex_grads(theta, batched_s_tm1, batched_r_t, batched_s_t).block_until_ready()
<span class="o">%</span><span class="k">timeit</span> perex_grads(theta, batched_s_tm1, batched_r_t, batched_s_t).block_until_ready()
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>13.9 ms ¬± 1.83 ms per loop (mean ¬± std. dev. of 7 runs, 100 loops each)
8.82 Œºs ¬± 913 ns per loop (mean ¬± std. dev. of 7 runs, 100,000 loops each)
</pre></div>
</div>
</div>
</div>
</section>
<section id="hessian-vector-products-with-jax-grad-of-jax-grad">
<h3>Hessian-vector products with <code class="docutils literal notranslate"><span class="pre">jax.grad</span></code>-of-<code class="docutils literal notranslate"><span class="pre">jax.grad</span></code><a class="headerlink" href="#hessian-vector-products-with-jax-grad-of-jax-grad" title="Link to this heading">#</a></h3>
<p>One thing you can do with higher-order <a class="reference internal" href="_autosummary/jax.grad.html#jax.grad" title="jax.grad"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.grad()</span></code></a> is build a Hessian-vector product function. (Later on you‚Äôll write an even more efficient implementation that mixes both forward- and reverse-mode, but this one will use pure reverse-mode.)</p>
<p>A Hessian-vector product function can be useful in a <a class="reference external" href="https://en.wikipedia.org/wiki/Truncated_Newton_method">truncated Newton Conjugate-Gradient algorithm</a> for minimizing smooth convex functions, or for studying the curvature of neural network training objectives (e.g. <a class="reference external" href="https://arxiv.org/abs/1406.2572">1</a>, <a class="reference external" href="https://arxiv.org/abs/1811.07062">2</a>, <a class="reference external" href="https://arxiv.org/abs/1706.04454">3</a>, <a class="reference external" href="https://arxiv.org/abs/1802.03451">4</a>).</p>
<p>For a scalar-valued function <span class="math notranslate nohighlight">\(f : \mathbb{R}^n \to \mathbb{R}\)</span> with continuous second derivatives (so that the Hessian matrix is symmetric), the Hessian at a point <span class="math notranslate nohighlight">\(x \in \mathbb{R}^n\)</span> is written as <span class="math notranslate nohighlight">\(\partial^2 f(x)\)</span>. A Hessian-vector product function is then able to evaluate</p>
<p><span class="math notranslate nohighlight">\(\qquad v \mapsto \partial^2 f(x) \cdot v\)</span></p>
<p>for any <span class="math notranslate nohighlight">\(v \in \mathbb{R}^n\)</span>.</p>
<p>The trick is not to instantiate the full Hessian matrix: if <span class="math notranslate nohighlight">\(n\)</span> is large, perhaps in the millions or billions in the context of neural networks, then that might be impossible to store.</p>
<p>Luckily, <a class="reference internal" href="_autosummary/jax.grad.html#jax.grad" title="jax.grad"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.grad()</span></code></a> already gives us a way to write an efficient Hessian-vector product function. You just have to use the identity:</p>
<p><span class="math notranslate nohighlight">\(\qquad \partial^2 f (x) v = \partial [x \mapsto \partial f(x) \cdot v] = \partial g(x)\)</span>,</p>
<p>where <span class="math notranslate nohighlight">\(g(x) = \partial f(x) \cdot v\)</span> is a new scalar-valued function that dots the gradient of <span class="math notranslate nohighlight">\(f\)</span> at <span class="math notranslate nohighlight">\(x\)</span> with the vector <span class="math notranslate nohighlight">\(v\)</span>. Notice that you‚Äôre only ever differentiating scalar-valued functions of vector-valued arguments, which is exactly where you know <a class="reference internal" href="_autosummary/jax.grad.html#jax.grad" title="jax.grad"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.grad()</span></code></a> is efficient.</p>
<p>In JAX code, you can just write this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">hvp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">grad</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">vdot</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="n">x</span><span class="p">),</span> <span class="n">v</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This example shows that you can freely use lexical closure, and JAX will never get perturbed or confused.</p>
<p>You will check this implementation a few cells down, once you learn how to compute dense Hessian matrices. You‚Äôll also write an even better version that uses both forward-mode and reverse-mode.</p>
</section>
<section id="jacobians-and-hessians-using-jax-jacfwd-and-jax-jacrev">
<h3>Jacobians and Hessians using <code class="docutils literal notranslate"><span class="pre">jax.jacfwd</span></code> and <code class="docutils literal notranslate"><span class="pre">jax.jacrev</span></code><a class="headerlink" href="#jacobians-and-hessians-using-jax-jacfwd-and-jax-jacrev" title="Link to this heading">#</a></h3>
<p>You can compute full Jacobian matrices using the <a class="reference internal" href="_autosummary/jax.jacfwd.html#jax.jacfwd" title="jax.jacfwd"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jacfwd()</span></code></a> and <a class="reference internal" href="_autosummary/jax.jacrev.html#jax.jacrev" title="jax.jacrev"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jacrev()</span></code></a> functions:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">jacfwd</span><span class="p">,</span> <span class="n">jacrev</span>

<span class="c1"># Define a sigmoid function.</span>
<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Outputs probability of a label being true.</span>
<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>

<span class="c1"># Build a toy dataset.</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.52</span><span class="p">,</span> <span class="mf">1.12</span><span class="p">,</span>  <span class="mf">0.77</span><span class="p">],</span>
                   <span class="p">[</span><span class="mf">0.88</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.08</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">],</span>
                   <span class="p">[</span><span class="mf">0.52</span><span class="p">,</span> <span class="mf">0.06</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.30</span><span class="p">],</span>
                   <span class="p">[</span><span class="mf">0.74</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.49</span><span class="p">,</span> <span class="mf">1.39</span><span class="p">]])</span>

<span class="c1"># Initialize random model coefficients</span>
<span class="n">key</span><span class="p">,</span> <span class="n">W_key</span><span class="p">,</span> <span class="n">b_key</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">W_key</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,))</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">b_key</span><span class="p">,</span> <span class="p">())</span>

<span class="c1"># Isolate the function from the weight matrix to the predictions</span>
<span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">W</span><span class="p">:</span> <span class="n">predict</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>

<span class="n">J</span> <span class="o">=</span> <span class="n">jacfwd</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="n">W</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;jacfwd result, with shape&quot;</span><span class="p">,</span> <span class="n">J</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">J</span><span class="p">)</span>

<span class="n">J</span> <span class="o">=</span> <span class="n">jacrev</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="n">W</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;jacrev result, with shape&quot;</span><span class="p">,</span> <span class="n">J</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">J</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>jacfwd result, with shape (4, 3)
[[ 0.05069415  0.1091874   0.07506633]
 [ 0.14170025 -0.17390487  0.02415345]
 [ 0.12579198  0.01451446 -0.31447992]
 [ 0.00574409 -0.0193281   0.01078958]]
jacrev result, with shape (4, 3)
[[ 0.05069415  0.10918739  0.07506634]
 [ 0.14170025 -0.17390487  0.02415345]
 [ 0.12579198  0.01451446 -0.31447995]
 [ 0.00574409 -0.0193281   0.01078958]]
</pre></div>
</div>
</div>
</div>
<p>These two functions compute the same values (up to machine numerics), but differ in their implementation: <a class="reference internal" href="_autosummary/jax.jacfwd.html#jax.jacfwd" title="jax.jacfwd"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jacfwd()</span></code></a> uses forward-mode automatic differentiation, which is more efficient for ‚Äútall‚Äù Jacobian matrices (more outputs than inputs), while <a class="reference internal" href="_autosummary/jax.jacrev.html#jax.jacrev" title="jax.jacrev"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jacrev()</span></code></a> uses reverse-mode, which is more efficient for ‚Äúwide‚Äù Jacobian matrices (more inputs than outputs). For matrices that are near-square, <a class="reference internal" href="_autosummary/jax.jacfwd.html#jax.jacfwd" title="jax.jacfwd"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jacfwd()</span></code></a> probably has an edge over <a class="reference internal" href="_autosummary/jax.jacrev.html#jax.jacrev" title="jax.jacrev"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jacrev()</span></code></a>.</p>
<p>You can also use <a class="reference internal" href="_autosummary/jax.jacfwd.html#jax.jacfwd" title="jax.jacfwd"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jacfwd()</span></code></a> and <a class="reference internal" href="_autosummary/jax.jacrev.html#jax.jacrev" title="jax.jacrev"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jacrev()</span></code></a> with container types:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">predict_dict</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">predict</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;W&#39;</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">],</span> <span class="n">inputs</span><span class="p">)</span>

<span class="n">J_dict</span> <span class="o">=</span> <span class="n">jacrev</span><span class="p">(</span><span class="n">predict_dict</span><span class="p">)({</span><span class="s1">&#39;W&#39;</span><span class="p">:</span> <span class="n">W</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="n">b</span><span class="p">},</span> <span class="n">inputs</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">J_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jacobian from </span><span class="si">{}</span><span class="s2"> to logits is&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">k</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jacobian from W to logits is
[[ 0.05069415  0.10918739  0.07506634]
 [ 0.14170025 -0.17390487  0.02415345]
 [ 0.12579198  0.01451446 -0.31447995]
 [ 0.00574409 -0.0193281   0.01078958]]
Jacobian from b to logits is
[0.09748875 0.16102302 0.24190766 0.00776229]
</pre></div>
</div>
</div>
</div>
<p>For more details on forward- and reverse-mode, as well as how to implement <a class="reference internal" href="_autosummary/jax.jacfwd.html#jax.jacfwd" title="jax.jacfwd"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jacfwd()</span></code></a> and <a class="reference internal" href="_autosummary/jax.jacrev.html#jax.jacrev" title="jax.jacrev"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jacrev()</span></code></a> as efficiently as possible, read on!</p>
<p>Using a composition of two of these functions gives us a way to compute dense Hessian matrices:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">hessian</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">jacfwd</span><span class="p">(</span><span class="n">jacrev</span><span class="p">(</span><span class="n">f</span><span class="p">))</span>

<span class="n">H</span> <span class="o">=</span> <span class="n">hessian</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="n">W</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;hessian, with shape&quot;</span><span class="p">,</span> <span class="n">H</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">H</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>hessian, with shape (4, 3, 3)
[[[ 0.02058932  0.04434624  0.03048803]
  [ 0.04434623  0.09551499  0.06566654]
  [ 0.03048803  0.06566655  0.04514575]]

 [[-0.0743913   0.09129842 -0.01268033]
  [ 0.09129842 -0.11204806  0.01556223]
  [-0.01268034  0.01556223 -0.00216142]]

 [[ 0.01176856  0.00135791 -0.02942139]
  [ 0.00135791  0.00015668 -0.00339478]
  [-0.0294214  -0.00339478  0.07355348]]

 [[-0.00418412  0.014079   -0.00785936]
  [ 0.014079   -0.04737393  0.02644569]
  [-0.00785936  0.02644569 -0.01476286]]]
</pre></div>
</div>
</div>
</div>
<p>This shape makes sense: if you start with a function <span class="math notranslate nohighlight">\(f : \mathbb{R}^n \to \mathbb{R}^m\)</span>, then at a point <span class="math notranslate nohighlight">\(x \in \mathbb{R}^n\)</span> you expect to get the shapes:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(f(x) \in \mathbb{R}^m\)</span>, the value of <span class="math notranslate nohighlight">\(f\)</span> at <span class="math notranslate nohighlight">\(x\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\(\partial f(x) \in \mathbb{R}^{m \times n}\)</span>, the Jacobian matrix at <span class="math notranslate nohighlight">\(x\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\(\partial^2 f(x) \in \mathbb{R}^{m \times n \times n}\)</span>, the Hessian at <span class="math notranslate nohighlight">\(x\)</span>,</p></li>
</ul>
<p>and so on.</p>
<p>To implement <code class="docutils literal notranslate"><span class="pre">hessian</span></code>, you could have used <code class="docutils literal notranslate"><span class="pre">jacfwd(jacrev(f))</span></code> or <code class="docutils literal notranslate"><span class="pre">jacrev(jacfwd(f))</span></code> or any other composition of these two. But forward-over-reverse is typically the most efficient. That‚Äôs because in the inner Jacobian computation we‚Äôre often differentiating a function wide Jacobian (maybe like a loss function <span class="math notranslate nohighlight">\(f : \mathbb{R}^n \to \mathbb{R}\)</span>), while in the outer Jacobian computation we‚Äôre differentiating a function with a square Jacobian (since <span class="math notranslate nohighlight">\(\nabla f : \mathbb{R}^n \to \mathbb{R}^n\)</span>), which is where forward-mode wins out.</p>
</section>
</section>
<section id="how-it-s-made-two-foundational-autodiff-functions">
<h2>How it‚Äôs made: Two foundational autodiff functions<a class="headerlink" href="#how-it-s-made-two-foundational-autodiff-functions" title="Link to this heading">#</a></h2>
<section id="jacobian-vector-products-jvps-a-k-a-forward-mode-autodiff">
<h3>Jacobian-Vector products (JVPs, a.k.a. forward-mode autodiff)<a class="headerlink" href="#jacobian-vector-products-jvps-a-k-a-forward-mode-autodiff" title="Link to this heading">#</a></h3>
<p>JAX includes efficient and general implementations of both forward- and reverse-mode automatic differentiation. The familiar <a class="reference internal" href="_autosummary/jax.grad.html#jax.grad" title="jax.grad"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.grad()</span></code></a> function is built on reverse-mode, but to explain the difference between the two modes, and when each can be useful, you need a bit of math background.</p>
<section id="jvps-in-math">
<h4>JVPs in math<a class="headerlink" href="#jvps-in-math" title="Link to this heading">#</a></h4>
<p>Mathematically, given a function <span class="math notranslate nohighlight">\(f : \mathbb{R}^n \to \mathbb{R}^m\)</span>, the Jacobian of <span class="math notranslate nohighlight">\(f\)</span> evaluated at an input point <span class="math notranslate nohighlight">\(x \in \mathbb{R}^n\)</span>, denoted <span class="math notranslate nohighlight">\(\partial f(x)\)</span>, is often thought of as a matrix in <span class="math notranslate nohighlight">\(\mathbb{R}^m \times \mathbb{R}^n\)</span>:</p>
<p><span class="math notranslate nohighlight">\(\qquad \partial f(x) \in \mathbb{R}^{m \times n}\)</span>.</p>
<p>But you can also think of <span class="math notranslate nohighlight">\(\partial f(x)\)</span> as a linear map, which maps the tangent space of the domain of <span class="math notranslate nohighlight">\(f\)</span> at the point <span class="math notranslate nohighlight">\(x\)</span> (which is just another copy of <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span>) to the tangent space of the codomain of <span class="math notranslate nohighlight">\(f\)</span> at the point <span class="math notranslate nohighlight">\(f(x)\)</span> (a copy of <span class="math notranslate nohighlight">\(\mathbb{R}^m\)</span>):</p>
<p><span class="math notranslate nohighlight">\(\qquad \partial f(x) : \mathbb{R}^n \to \mathbb{R}^m\)</span>.</p>
<p>This map is called the <a class="reference external" href="https://en.wikipedia.org/wiki/Pushforward_(differential)">pushforward map</a> of <span class="math notranslate nohighlight">\(f\)</span> at <span class="math notranslate nohighlight">\(x\)</span>. The Jacobian matrix is just the matrix for this linear map on a standard basis.</p>
<p>If you don‚Äôt commit to one specific input point <span class="math notranslate nohighlight">\(x\)</span>, then you can think of the function <span class="math notranslate nohighlight">\(\partial f\)</span> as first taking an input point and returning the Jacobian linear map at that input point:</p>
<p><span class="math notranslate nohighlight">\(\qquad \partial f : \mathbb{R}^n \to \mathbb{R}^n \to \mathbb{R}^m\)</span>.</p>
<p>In particular, you can uncurry things so that given input point <span class="math notranslate nohighlight">\(x \in \mathbb{R}^n\)</span> and a tangent vector <span class="math notranslate nohighlight">\(v \in \mathbb{R}^n\)</span>, you get back an output tangent vector in <span class="math notranslate nohighlight">\(\mathbb{R}^m\)</span>. We call that mapping, from <span class="math notranslate nohighlight">\((x, v)\)</span> pairs to output tangent vectors, the <em>Jacobian-vector product</em>, and write it as:</p>
<p><span class="math notranslate nohighlight">\(\qquad (x, v) \mapsto \partial f(x) v\)</span></p>
</section>
<section id="jvps-in-jax-code">
<h4>JVPs in JAX code<a class="headerlink" href="#jvps-in-jax-code" title="Link to this heading">#</a></h4>
<p>Back in Python code, JAX‚Äôs <a class="reference internal" href="_autosummary/jax.jvp.html#jax.jvp" title="jax.jvp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jvp()</span></code></a> function models this transformation. Given a Python function that evaluates <span class="math notranslate nohighlight">\(f\)</span>, JAX‚Äôs <a class="reference internal" href="_autosummary/jax.jvp.html#jax.jvp" title="jax.jvp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jvp()</span></code></a> is a way to get a Python function for evaluating <span class="math notranslate nohighlight">\((x, v) \mapsto (f(x), \partial f(x) v)\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">jvp</span>

<span class="c1"># Isolate the function from the weight matrix to the predictions</span>
<span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">W</span><span class="p">:</span> <span class="n">predict</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>

<span class="n">key</span><span class="p">,</span> <span class="n">subkey</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">subkey</span><span class="p">,</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Push forward the vector `v` along `f` evaluated at `W`</span>
<span class="n">y</span><span class="p">,</span> <span class="n">u</span> <span class="o">=</span> <span class="n">jvp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">W</span><span class="p">,),</span> <span class="p">(</span><span class="n">v</span><span class="p">,))</span>
</pre></div>
</div>
</div>
</div>
<p>In terms of <a class="reference external" href="https://wiki.haskell.org/Type_signature">Haskell-like type signatures</a>, you could write:</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">jvp</span><span class="w"> </span><span class="ow">::</span><span class="w"> </span><span class="p">(</span><span class="n">a</span><span class="w"> </span><span class="ow">-&gt;</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="ow">-&gt;</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="ow">-&gt;</span><span class="w"> </span><span class="kt">T</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="ow">-&gt;</span><span class="w"> </span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="kt">T</span><span class="w"> </span><span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">T</span> <span class="pre">a</span></code> is used to denote the type of the tangent space for <code class="docutils literal notranslate"><span class="pre">a</span></code>.</p>
<p>In other words, <code class="docutils literal notranslate"><span class="pre">jvp</span></code> takes as arguments a function of type <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">-&gt;</span> <span class="pre">b</span></code>, a value of type <code class="docutils literal notranslate"><span class="pre">a</span></code>, and a tangent vector value of type <code class="docutils literal notranslate"><span class="pre">T</span> <span class="pre">a</span></code>. It gives back a pair consisting of a value of type <code class="docutils literal notranslate"><span class="pre">b</span></code> and an output tangent vector of type <code class="docutils literal notranslate"><span class="pre">T</span> <span class="pre">b</span></code>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">jvp</span></code>-transformed function is evaluated much like the original function, but paired up with each primal value of type <code class="docutils literal notranslate"><span class="pre">a</span></code> it pushes along tangent values of type <code class="docutils literal notranslate"><span class="pre">T</span> <span class="pre">a</span></code>. For each primitive numerical operation that the original function would have applied, the <code class="docutils literal notranslate"><span class="pre">jvp</span></code>-transformed function executes a ‚ÄúJVP rule‚Äù for that primitive that both evaluates the primitive on the primals and applies the primitive‚Äôs JVP at those primal values.</p>
<p>That evaluation strategy has some immediate implications about computational complexity. Since we evaluate JVPs as we go, we don‚Äôt need to store anything for later, and so the memory cost is independent of the depth of the computation. In addition, the FLOP cost of the <code class="docutils literal notranslate"><span class="pre">jvp</span></code>-transformed function is about 3x the cost of just evaluating the function (one unit of work for evaluating the original function, for example <code class="docutils literal notranslate"><span class="pre">sin(x)</span></code>; one unit for linearizing, like <code class="docutils literal notranslate"><span class="pre">cos(x)</span></code>; and one unit for applying the linearized function to a vector, like <code class="docutils literal notranslate"><span class="pre">cos_x</span> <span class="pre">*</span> <span class="pre">v</span></code>). Put another way, for a fixed primal point <span class="math notranslate nohighlight">\(x\)</span>, we can evaluate <span class="math notranslate nohighlight">\(v \mapsto \partial f(x) \cdot v\)</span> for about the same marginal cost as evaluating <span class="math notranslate nohighlight">\(f\)</span>.</p>
<p>That memory complexity sounds pretty compelling! So why don‚Äôt we see forward-mode very often in machine learning?</p>
<p>To answer that, first think about how you could use a JVP to build a full Jacobian matrix. If we apply a JVP to a one-hot tangent vector, it reveals one column of the Jacobian matrix, corresponding to the nonzero entry we fed in. So we can build a full Jacobian one column at a time, and to get each column costs about the same as one function evaluation. That will be efficient for functions with ‚Äútall‚Äù Jacobians, but inefficient for ‚Äúwide‚Äù Jacobians.</p>
<p>If you‚Äôre doing gradient-based optimization in machine learning, you probably want to minimize a loss function from parameters in <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span> to a scalar loss value in <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>. That means the Jacobian of this function is a very wide matrix: <span class="math notranslate nohighlight">\(\partial f(x) \in \mathbb{R}^{1 \times n}\)</span>, which we often identify with the Gradient vector <span class="math notranslate nohighlight">\(\nabla f(x) \in \mathbb{R}^n\)</span>. Building that matrix one column at a time, with each call taking a similar number of FLOPs to evaluate the original function, sure seems inefficient! In particular, for training neural networks, where <span class="math notranslate nohighlight">\(f\)</span> is a training loss function and <span class="math notranslate nohighlight">\(n\)</span> can be in the millions or billions, this approach just won‚Äôt scale.</p>
<p>To do better for functions like this, you just need to use reverse-mode.</p>
</section>
</section>
<section id="vector-jacobian-products-vjps-a-k-a-reverse-mode-autodiff">
<h3>Vector-Jacobian products (VJPs, a.k.a. reverse-mode autodiff)<a class="headerlink" href="#vector-jacobian-products-vjps-a-k-a-reverse-mode-autodiff" title="Link to this heading">#</a></h3>
<p>Where forward-mode gives us back a function for evaluating Jacobian-vector products, which we can then use to build Jacobian matrices one column at a time, reverse-mode is a way to get back a function for evaluating vector-Jacobian products (equivalently Jacobian-transpose-vector products), which we can use to build Jacobian matrices one row at a time.</p>
<section id="vjps-in-math">
<h4>VJPs in math<a class="headerlink" href="#vjps-in-math" title="Link to this heading">#</a></h4>
<p>Let‚Äôs again consider a function <span class="math notranslate nohighlight">\(f : \mathbb{R}^n \to \mathbb{R}^m\)</span>.
Starting from our notation for JVPs, the notation for VJPs is pretty simple:</p>
<p><span class="math notranslate nohighlight">\(\qquad (x, v) \mapsto v \partial f(x)\)</span>,</p>
<p>where <span class="math notranslate nohighlight">\(v\)</span> is an element of the cotangent space of <span class="math notranslate nohighlight">\(f\)</span> at <span class="math notranslate nohighlight">\(x\)</span> (isomorphic to another copy of <span class="math notranslate nohighlight">\(\mathbb{R}^m\)</span>). When being rigorous, we should think of <span class="math notranslate nohighlight">\(v\)</span> as a linear map <span class="math notranslate nohighlight">\(v : \mathbb{R}^m \to \mathbb{R}\)</span>, and when we write <span class="math notranslate nohighlight">\(v \partial f(x)\)</span> we mean function composition <span class="math notranslate nohighlight">\(v \circ \partial f(x)\)</span>, where the types work out because <span class="math notranslate nohighlight">\(\partial f(x) : \mathbb{R}^n \to \mathbb{R}^m\)</span>. But in the common case we can identify <span class="math notranslate nohighlight">\(v\)</span> with a vector in <span class="math notranslate nohighlight">\(\mathbb{R}^m\)</span> and use the two almost interchangeably, just like we might sometimes flip between ‚Äúcolumn vectors‚Äù and ‚Äúrow vectors‚Äù without much comment.</p>
<p>With that identification, we can alternatively think of the linear part of a VJP as the transpose (or adjoint conjugate) of the linear part of a JVP:</p>
<p><span class="math notranslate nohighlight">\(\qquad (x, v) \mapsto \partial f(x)^\mathsf{T} v\)</span>.</p>
<p>For a given point <span class="math notranslate nohighlight">\(x\)</span>, we can write the signature as</p>
<p><span class="math notranslate nohighlight">\(\qquad \partial f(x)^\mathsf{T} : \mathbb{R}^m \to \mathbb{R}^n\)</span>.</p>
<p>The corresponding map on cotangent spaces is often called the <a class="reference external" href="https://en.wikipedia.org/wiki/Pullback_(differential_geometry)">pullback</a>
of <span class="math notranslate nohighlight">\(f\)</span> at <span class="math notranslate nohighlight">\(x\)</span>. The key for our purposes is that it goes from something that looks like the output of <span class="math notranslate nohighlight">\(f\)</span> to something that looks like the input of <span class="math notranslate nohighlight">\(f\)</span>, just like we might expect from a transposed linear function.</p>
</section>
<section id="vjps-in-jax-code">
<h4>VJPs in JAX code<a class="headerlink" href="#vjps-in-jax-code" title="Link to this heading">#</a></h4>
<p>Switching from math back to Python, the JAX function <code class="docutils literal notranslate"><span class="pre">vjp</span></code> can take a Python function for evaluating <span class="math notranslate nohighlight">\(f\)</span> and give us back a Python function for evaluating the VJP <span class="math notranslate nohighlight">\((x, v) \mapsto (f(x), v^\mathsf{T} \partial f(x))\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">vjp</span>

<span class="c1"># Isolate the function from the weight matrix to the predictions</span>
<span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">W</span><span class="p">:</span> <span class="n">predict</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>

<span class="n">y</span><span class="p">,</span> <span class="n">vjp_fun</span> <span class="o">=</span> <span class="n">vjp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>

<span class="n">key</span><span class="p">,</span> <span class="n">subkey</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">subkey</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Pull back the covector `u` along `f` evaluated at `W`</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">vjp_fun</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In terms of <a class="reference external" href="https://wiki.haskell.org/Type_signature">Haskell-like type signatures</a>, we could write</p>
<div class="highlight-haskell notranslate"><div class="highlight"><pre><span></span><span class="nf">vjp</span><span class="w"> </span><span class="ow">::</span><span class="w"> </span><span class="p">(</span><span class="n">a</span><span class="w"> </span><span class="ow">-&gt;</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="ow">-&gt;</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="ow">-&gt;</span><span class="w"> </span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="kt">CT</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="ow">-&gt;</span><span class="w"> </span><span class="kt">CT</span><span class="w"> </span><span class="n">a</span><span class="p">)</span>
</pre></div>
</div>
<p>where we use <code class="docutils literal notranslate"><span class="pre">CT</span> <span class="pre">a</span></code> to denote the type for the cotangent space for <code class="docutils literal notranslate"><span class="pre">a</span></code>. In words, <code class="docutils literal notranslate"><span class="pre">vjp</span></code> takes as arguments a function of type <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">-&gt;</span> <span class="pre">b</span></code> and a point of type <code class="docutils literal notranslate"><span class="pre">a</span></code>, and gives back a pair consisting of a value of type <code class="docutils literal notranslate"><span class="pre">b</span></code> and a linear map of type <code class="docutils literal notranslate"><span class="pre">CT</span> <span class="pre">b</span> <span class="pre">-&gt;</span> <span class="pre">CT</span> <span class="pre">a</span></code>.</p>
<p>This is great because it lets us build Jacobian matrices one row at a time, and the FLOP cost for evaluating <span class="math notranslate nohighlight">\((x, v) \mapsto (f(x), v^\mathsf{T} \partial f(x))\)</span> is only about three times the cost of evaluating <span class="math notranslate nohighlight">\(f\)</span>. In particular, if we want the gradient of a function <span class="math notranslate nohighlight">\(f : \mathbb{R}^n \to \mathbb{R}\)</span>, we can do it in just one call. That‚Äôs how <a class="reference internal" href="_autosummary/jax.grad.html#jax.grad" title="jax.grad"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.grad()</span></code></a> is efficient for gradient-based optimization, even for objectives like neural network training loss functions on millions or billions of parameters.</p>
<p>There‚Äôs a cost, though the FLOPs are friendly, memory scales with the depth of the computation. Also, the implementation is traditionally more complex than that of forward-mode, though JAX has some tricks up its sleeve (that‚Äôs a story for a future notebook!).</p>
<p>For more on how reverse-mode works, check out <a class="reference external" href="http://videolectures.net/deeplearning2017_johnson_automatic_differentiation/">this tutorial video from the Deep Learning Summer School in 2017</a>.</p>
</section>
</section>
<section id="vector-valued-gradients-with-vjps">
<h3>Vector-valued gradients with VJPs<a class="headerlink" href="#vector-valued-gradients-with-vjps" title="Link to this heading">#</a></h3>
<p>If you‚Äôre interested in taking vector-valued gradients (like <code class="docutils literal notranslate"><span class="pre">tf.gradients</span></code>):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">vgrad</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
  <span class="n">y</span><span class="p">,</span> <span class="n">vjp_fn</span> <span class="o">=</span> <span class="n">vjp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">vjp_fn</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">vgrad</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">3</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[6. 6.]
 [6. 6.]]
</pre></div>
</div>
</div>
</div>
</section>
<section id="hessian-vector-products-using-both-forward-and-reverse-mode">
<h3>Hessian-vector products using both forward- and reverse-mode<a class="headerlink" href="#hessian-vector-products-using-both-forward-and-reverse-mode" title="Link to this heading">#</a></h3>
<p>In a previous section, you implemented a Hessian-vector product function just using reverse-mode (assuming continuous second derivatives):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">hvp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">grad</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">vdot</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="n">x</span><span class="p">),</span> <span class="n">v</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>That‚Äôs efficient, but you can do even better and save some memory by using forward-mode together with reverse-mode.</p>
<p>Mathematically, given a function <span class="math notranslate nohighlight">\(f : \mathbb{R}^n \to \mathbb{R}\)</span> to differentiate, a point <span class="math notranslate nohighlight">\(x \in \mathbb{R}^n\)</span> at which to linearize the function, and a vector <span class="math notranslate nohighlight">\(v \in \mathbb{R}^n\)</span>, the Hessian-vector product function we want is:</p>
<p><span class="math notranslate nohighlight">\((x, v) \mapsto \partial^2 f(x) v\)</span></p>
<p>Consider the helper function <span class="math notranslate nohighlight">\(g : \mathbb{R}^n \to \mathbb{R}^n\)</span> defined to be the derivative (or gradient) of <span class="math notranslate nohighlight">\(f\)</span>, namely <span class="math notranslate nohighlight">\(g(x) = \partial f(x)\)</span>. All you need is its JVP, since that will give us:</p>
<p><span class="math notranslate nohighlight">\((x, v) \mapsto \partial g(x) v = \partial^2 f(x) v\)</span>.</p>
<p>We can translate that almost directly into code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># forward-over-reverse</span>
<span class="k">def</span> <span class="nf">hvp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">primals</span><span class="p">,</span> <span class="n">tangents</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">jvp</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">),</span> <span class="n">primals</span><span class="p">,</span> <span class="n">tangents</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Even better, since you didn‚Äôt have to call <code class="xref py py-func docutils literal notranslate"><span class="pre">jnp.dot()</span></code> directly, this <code class="docutils literal notranslate"><span class="pre">hvp</span></code> function works with arrays of any shape and with arbitrary container types (like vectors stored as nested lists/dicts/tuples), and doesn‚Äôt even have a dependence on <a class="reference internal" href="jax.numpy.html#module-jax.numpy" title="jax.numpy"><code class="xref py py-mod docutils literal notranslate"><span class="pre">jax.numpy</span></code></a>.</p>
<p>Here‚Äôs an example of how to use it:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">key</span><span class="p">,</span> <span class="n">subkey1</span><span class="p">,</span> <span class="n">subkey2</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">subkey1</span><span class="p">,</span> <span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">))</span>
<span class="n">V</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">subkey2</span><span class="p">,</span> <span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">))</span>

<span class="n">ans1</span> <span class="o">=</span> <span class="n">hvp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="p">,),</span> <span class="p">(</span><span class="n">V</span><span class="p">,))</span>
<span class="n">ans2</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">tensordot</span><span class="p">(</span><span class="n">hessian</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="n">X</span><span class="p">),</span> <span class="n">V</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">ans1</span><span class="p">,</span> <span class="n">ans2</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<p>Another way you might consider writing this is using reverse-over-forward:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Reverse-over-forward</span>
<span class="k">def</span> <span class="nf">hvp_revfwd</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">primals</span><span class="p">,</span> <span class="n">tangents</span><span class="p">):</span>
  <span class="n">g</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">primals</span><span class="p">:</span> <span class="n">jvp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">primals</span><span class="p">,</span> <span class="n">tangents</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
  <span class="k">return</span> <span class="n">grad</span><span class="p">(</span><span class="n">g</span><span class="p">)(</span><span class="n">primals</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>That‚Äôs not quite as good, though, because forward-mode has less overhead than reverse-mode, and since the outer differentiation operator here has to differentiate a larger computation than the inner one, keeping forward-mode on the outside works best:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Reverse-over-reverse, only works for single arguments</span>
<span class="k">def</span> <span class="nf">hvp_revrev</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">primals</span><span class="p">,</span> <span class="n">tangents</span><span class="p">):</span>
  <span class="n">x</span><span class="p">,</span> <span class="o">=</span> <span class="n">primals</span>
  <span class="n">v</span><span class="p">,</span> <span class="o">=</span> <span class="n">tangents</span>
  <span class="k">return</span> <span class="n">grad</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">vdot</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="n">x</span><span class="p">),</span> <span class="n">v</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Forward over reverse&quot;</span><span class="p">)</span>
<span class="o">%</span><span class="k">timeit</span> -n10 -r3 hvp(f, (X,), (V,))
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reverse over forward&quot;</span><span class="p">)</span>
<span class="o">%</span><span class="k">timeit</span> -n10 -r3 hvp_revfwd(f, (X,), (V,))
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reverse over reverse&quot;</span><span class="p">)</span>
<span class="o">%</span><span class="k">timeit</span> -n10 -r3 hvp_revrev(f, (X,), (V,))

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Naive full Hessian materialization&quot;</span><span class="p">)</span>
<span class="o">%</span><span class="k">timeit</span> -n10 -r3 jnp.tensordot(hessian(f)(X), V, 2)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Forward over reverse
3.31 ms ¬± 35.6 Œºs per loop (mean ¬± std. dev. of 3 runs, 10 loops each)
Reverse over forward
The slowest run took 6.60 times longer than the fastest. This could mean that an intermediate result is being cached.
14.7 ms ¬± 11.9 ms per loop (mean ¬± std. dev. of 3 runs, 10 loops each)
Reverse over reverse
The slowest run took 6.76 times longer than the fastest. This could mean that an intermediate result is being cached.
24 ms ¬± 21.5 ms per loop (mean ¬± std. dev. of 3 runs, 10 loops each)
Naive full Hessian materialization
29.5 ms ¬± 689 Œºs per loop (mean ¬± std. dev. of 3 runs, 10 loops each)
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="composing-vjps-jvps-and-jax-vmap">
<h2>Composing VJPs, JVPs, and <code class="docutils literal notranslate"><span class="pre">jax.vmap</span></code><a class="headerlink" href="#composing-vjps-jvps-and-jax-vmap" title="Link to this heading">#</a></h2>
<section id="jacobian-matrix-and-matrix-jacobian-products">
<h3>Jacobian-Matrix and Matrix-Jacobian products<a class="headerlink" href="#jacobian-matrix-and-matrix-jacobian-products" title="Link to this heading">#</a></h3>
<p>Now that you have <a class="reference internal" href="_autosummary/jax.jvp.html#jax.jvp" title="jax.jvp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jvp()</span></code></a> and <a class="reference internal" href="_autosummary/jax.vjp.html#jax.vjp" title="jax.vjp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.vjp()</span></code></a> transformations that give you functions to push-forward or pull-back single vectors at a time, you can use JAX‚Äôs <a class="reference internal" href="_autosummary/jax.vmap.html#jax.vmap" title="jax.vmap"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.vmap()</span></code></a> <a class="reference external" href="https://github.com/jax-ml/jax#auto-vectorization-with-vmap">transformation</a> to push and pull entire bases at once. In particular, you can use that to write fast matrix-Jacobian and Jacobian-matrix products:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Isolate the function from the weight matrix to the predictions</span>
<span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">W</span><span class="p">:</span> <span class="n">predict</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>

<span class="c1"># Pull back the covectors `m_i` along `f`, evaluated at `W`, for all `i`.</span>
<span class="c1"># First, use a list comprehension to loop over rows in the matrix M.</span>
<span class="k">def</span> <span class="nf">loop_mjp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">M</span><span class="p">):</span>
    <span class="n">y</span><span class="p">,</span> <span class="n">vjp_fun</span> <span class="o">=</span> <span class="n">vjp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">vjp_fun</span><span class="p">(</span><span class="n">mi</span><span class="p">)</span> <span class="k">for</span> <span class="n">mi</span> <span class="ow">in</span> <span class="n">M</span><span class="p">])</span>

<span class="c1"># Now, use vmap to build a computation that does a single fast matrix-matrix</span>
<span class="c1"># multiply, rather than an outer loop over vector-matrix multiplies.</span>
<span class="k">def</span> <span class="nf">vmap_mjp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">M</span><span class="p">):</span>
    <span class="n">y</span><span class="p">,</span> <span class="n">vjp_fun</span> <span class="o">=</span> <span class="n">vjp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">outs</span><span class="p">,</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">vjp_fun</span><span class="p">)(</span><span class="n">M</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">outs</span>

<span class="n">key</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">key</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">num_covecs</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">U</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="p">(</span><span class="n">num_covecs</span><span class="p">,)</span> <span class="o">+</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">loop_vs</span> <span class="o">=</span> <span class="n">loop_mjp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="n">U</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Non-vmapped Matrix-Jacobian product&#39;</span><span class="p">)</span>
<span class="o">%</span><span class="k">timeit</span> -n10 -r3 loop_mjp(f, W, M=U)

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Vmapped Matrix-Jacobian product&#39;</span><span class="p">)</span>
<span class="n">vmap_vs</span> <span class="o">=</span> <span class="n">vmap_mjp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="n">U</span><span class="p">)</span>
<span class="o">%</span><span class="k">timeit</span> -n10 -r3 vmap_mjp(f, W, M=U)

<span class="k">assert</span> <span class="n">jnp</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">loop_vs</span><span class="p">,</span> <span class="n">vmap_vs</span><span class="p">),</span> <span class="s1">&#39;Vmap and non-vmapped Matrix-Jacobian Products should be identical&#39;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Non-vmapped Matrix-Jacobian product
70.8 ms ¬± 5.28 ms per loop (mean ¬± std. dev. of 3 runs, 10 loops each)

Vmapped Matrix-Jacobian product
3.37 ms ¬± 43 Œºs per loop (mean ¬± std. dev. of 3 runs, 10 loops each)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/tmp/ipykernel_228667/3769736790.py:8: DeprecationWarning: vstack requires ndarray or scalar arguments, got &lt;class &#39;tuple&#39;&gt; at position 0. In a future JAX release this will be an error.
  return jnp.vstack([vjp_fun(mi) for mi in M])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">loop_jmp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">M</span><span class="p">):</span>
    <span class="c1"># jvp immediately returns the primal and tangent values as a tuple,</span>
    <span class="c1"># so we&#39;ll compute and select the tangents in a list comprehension</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">jvp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">W</span><span class="p">,),</span> <span class="p">(</span><span class="n">mi</span><span class="p">,))[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">mi</span> <span class="ow">in</span> <span class="n">M</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">vmap_jmp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">M</span><span class="p">):</span>
    <span class="n">_jvp</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="n">jvp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">W</span><span class="p">,),</span> <span class="p">(</span><span class="n">s</span><span class="p">,))[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">vmap</span><span class="p">(</span><span class="n">_jvp</span><span class="p">)(</span><span class="n">M</span><span class="p">)</span>

<span class="n">num_vecs</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">S</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="p">(</span><span class="n">num_vecs</span><span class="p">,)</span> <span class="o">+</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">loop_vs</span> <span class="o">=</span> <span class="n">loop_jmp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="n">S</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Non-vmapped Jacobian-Matrix product&#39;</span><span class="p">)</span>
<span class="o">%</span><span class="k">timeit</span> -n10 -r3 loop_jmp(f, W, M=S)
<span class="n">vmap_vs</span> <span class="o">=</span> <span class="n">vmap_jmp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="n">S</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Vmapped Jacobian-Matrix product&#39;</span><span class="p">)</span>
<span class="o">%</span><span class="k">timeit</span> -n10 -r3 vmap_jmp(f, W, M=S)

<span class="k">assert</span> <span class="n">jnp</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">loop_vs</span><span class="p">,</span> <span class="n">vmap_vs</span><span class="p">),</span> <span class="s1">&#39;Vmap and non-vmapped Jacobian-Matrix products should be identical&#39;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Non-vmapped Jacobian-Matrix product
157 ms ¬± 6.35 ms per loop (mean ¬± std. dev. of 3 runs, 10 loops each)

Vmapped Jacobian-Matrix product
2.05 ms ¬± 63 Œºs per loop (mean ¬± std. dev. of 3 runs, 10 loops each)
</pre></div>
</div>
</div>
</div>
</section>
<section id="the-implementation-of-jax-jacfwd-and-jax-jacrev">
<h3>The implementation of <code class="docutils literal notranslate"><span class="pre">jax.jacfwd</span></code> and <code class="docutils literal notranslate"><span class="pre">jax.jacrev</span></code><a class="headerlink" href="#the-implementation-of-jax-jacfwd-and-jax-jacrev" title="Link to this heading">#</a></h3>
<p>Now that we‚Äôve seen fast Jacobian-matrix and matrix-Jacobian products, it‚Äôs not hard to guess how to write <a class="reference internal" href="_autosummary/jax.jacfwd.html#jax.jacfwd" title="jax.jacfwd"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jacfwd()</span></code></a> and <a class="reference internal" href="_autosummary/jax.jacrev.html#jax.jacrev" title="jax.jacrev"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jacrev()</span></code></a>. We just use the same technique to push-forward or pull-back an entire standard basis (isomorphic to an identity matrix) at once.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">jacrev</span> <span class="k">as</span> <span class="n">builtin_jacrev</span>

<span class="k">def</span> <span class="nf">our_jacrev</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">jacfun</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">vjp_fun</span> <span class="o">=</span> <span class="n">vjp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="c1"># Use vmap to do a matrix-Jacobian product.</span>
        <span class="c1"># Here, the matrix is the Euclidean basis, so we get all</span>
        <span class="c1"># entries in the Jacobian at once.</span>
        <span class="n">J</span><span class="p">,</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">vjp_fun</span><span class="p">,</span> <span class="n">in_axes</span><span class="o">=</span><span class="mi">0</span><span class="p">)(</span><span class="n">jnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">J</span>
    <span class="k">return</span> <span class="n">jacfun</span>

<span class="k">assert</span> <span class="n">jnp</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">builtin_jacrev</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="n">W</span><span class="p">),</span> <span class="n">our_jacrev</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="n">W</span><span class="p">)),</span> <span class="s1">&#39;Incorrect reverse-mode Jacobian results!&#39;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">jacfwd</span> <span class="k">as</span> <span class="n">builtin_jacfwd</span>

<span class="k">def</span> <span class="nf">our_jacfwd</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">jacfun</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="n">_jvp</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="n">jvp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,),</span> <span class="p">(</span><span class="n">s</span><span class="p">,))[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">Jt</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">_jvp</span><span class="p">,</span> <span class="n">in_axes</span><span class="o">=</span><span class="mi">1</span><span class="p">)(</span><span class="n">jnp</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">Jt</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">jacfun</span>

<span class="k">assert</span> <span class="n">jnp</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">builtin_jacfwd</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="n">W</span><span class="p">),</span> <span class="n">our_jacfwd</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="n">W</span><span class="p">)),</span> <span class="s1">&#39;Incorrect forward-mode Jacobian results!&#39;</span>
</pre></div>
</div>
</div>
</div>
<p>Interestingly, the <a class="reference external" href="https://github.com/hips/autograd">Autograd</a> library couldn‚Äôt do this. The <a class="reference external" href="https://github.com/HIPS/autograd/blob/96a03f44da43cd7044c61ac945c483955deba957/autograd/differential_operators.py#L60">implementation</a> of reverse-mode <code class="docutils literal notranslate"><span class="pre">jacobian</span></code> in Autograd had to pull back one vector at a time with an outer-loop <code class="docutils literal notranslate"><span class="pre">map</span></code>. Pushing one vector at a time through the computation is much less efficient than batching it all together with <a class="reference internal" href="_autosummary/jax.vmap.html#jax.vmap" title="jax.vmap"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.vmap()</span></code></a>.</p>
<p>Another thing that Autograd couldn‚Äôt do is <a class="reference internal" href="_autosummary/jax.jit.html#jax.jit" title="jax.jit"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jit()</span></code></a>. Interestingly, no matter how much Python dynamism you use in your function to be differentiated, we could always use <a class="reference internal" href="_autosummary/jax.jit.html#jax.jit" title="jax.jit"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jit()</span></code></a> on the linear part of the computation. For example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">3</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span>
    <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">x</span>

<span class="n">y</span><span class="p">,</span> <span class="n">f_vjp</span> <span class="o">=</span> <span class="n">vjp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="mf">4.</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">jit</span><span class="p">(</span><span class="n">f_vjp</span><span class="p">)(</span><span class="mf">1.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(Array(3.1415927, dtype=float32, weak_type=True),)
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="complex-numbers-and-differentiation">
<h2>Complex numbers and differentiation<a class="headerlink" href="#complex-numbers-and-differentiation" title="Link to this heading">#</a></h2>
<p>JAX is great at complex numbers and differentiation. To support both <a class="reference external" href="https://en.wikipedia.org/wiki/Holomorphic_function">holomorphic and non-holomorphic differentiation</a>, it helps to think in terms of JVPs and VJPs.</p>
<p>Consider a complex-to-complex function <span class="math notranslate nohighlight">\(f: \mathbb{C} \to \mathbb{C}\)</span> and identify it with a corresponding function <span class="math notranslate nohighlight">\(g: \mathbb{R}^2 \to \mathbb{R}^2\)</span>,</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
  <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">imag</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">u</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="n">v</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1</span><span class="n">j</span>

<span class="k">def</span> <span class="nf">g</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="k">return</span> <span class="p">(</span><span class="n">u</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">v</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>That is, we‚Äôve decomposed <span class="math notranslate nohighlight">\(f(z) = u(x, y) + v(x, y) i\)</span> where <span class="math notranslate nohighlight">\(z = x + y i\)</span>, and identified <span class="math notranslate nohighlight">\(\mathbb{C}\)</span> with <span class="math notranslate nohighlight">\(\mathbb{R}^2\)</span> to get <span class="math notranslate nohighlight">\(g\)</span>.</p>
<p>Since <span class="math notranslate nohighlight">\(g\)</span> only involves real inputs and outputs, we already know how to write a Jacobian-vector product for it, say given a tangent vector <span class="math notranslate nohighlight">\((c, d) \in \mathbb{R}^2\)</span>, namely:</p>
<p><span class="math notranslate nohighlight">\(\begin{bmatrix} \partial_0 u(x, y) &amp; \partial_1 u(x, y) \\ \partial_0 v(x, y) &amp; \partial_1 v(x, y) \end{bmatrix}
\begin{bmatrix} c \\ d \end{bmatrix}\)</span>.</p>
<p>To get a JVP for the original function <span class="math notranslate nohighlight">\(f\)</span> applied to a tangent vector <span class="math notranslate nohighlight">\(c + di \in \mathbb{C}\)</span>, we just use the same definition and identify the result as another complex number,</p>
<p><span class="math notranslate nohighlight">\(\partial f(x + y i)(c + d i) =
\begin{matrix} \begin{bmatrix} 1 &amp; i \end{bmatrix} \\ ~ \end{matrix}
\begin{bmatrix} \partial_0 u(x, y) &amp; \partial_1 u(x, y) \\ \partial_0 v(x, y) &amp; \partial_1 v(x, y) \end{bmatrix}
\begin{bmatrix} c \\ d \end{bmatrix}\)</span>.</p>
<p>That‚Äôs our definition of the JVP of a <span class="math notranslate nohighlight">\(\mathbb{C} \to \mathbb{C}\)</span> function! Notice it doesn‚Äôt matter whether or not <span class="math notranslate nohighlight">\(f\)</span> is holomorphic: the JVP is unambiguous.</p>
<p>Here‚Äôs a check:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">check</span><span class="p">(</span><span class="n">seed</span><span class="p">):</span>
  <span class="n">key</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">key</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

  <span class="c1"># random coeffs for u and v</span>
  <span class="n">key</span><span class="p">,</span> <span class="n">subkey</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
  <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">subkey</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,))</span>

  <span class="k">def</span> <span class="nf">fun</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">imag</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">u</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="n">v</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1</span><span class="n">j</span>

  <span class="k">def</span> <span class="nf">u</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">a</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span> <span class="o">*</span> <span class="n">y</span>

  <span class="k">def</span> <span class="nf">v</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">c</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">d</span> <span class="o">*</span> <span class="n">y</span>

  <span class="c1"># primal point</span>
  <span class="n">key</span><span class="p">,</span> <span class="n">subkey</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
  <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">subkey</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,))</span>
  <span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span> <span class="o">*</span> <span class="mi">1</span><span class="n">j</span>

  <span class="c1"># tangent vector</span>
  <span class="n">key</span><span class="p">,</span> <span class="n">subkey</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
  <span class="n">c</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">subkey</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,))</span>
  <span class="n">z_dot</span> <span class="o">=</span> <span class="n">c</span> <span class="o">+</span> <span class="n">d</span> <span class="o">*</span> <span class="mi">1</span><span class="n">j</span>

  <span class="c1"># check jvp</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">ans</span> <span class="o">=</span> <span class="n">jvp</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="p">(</span><span class="n">z</span><span class="p">,),</span> <span class="p">(</span><span class="n">z_dot</span><span class="p">,))</span>
  <span class="n">expected</span> <span class="o">=</span> <span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="mi">0</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">c</span> <span class="o">+</span>
              <span class="n">grad</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">d</span> <span class="o">+</span>
              <span class="n">grad</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="mi">0</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">c</span> <span class="o">*</span> <span class="mi">1</span><span class="n">j</span><span class="o">+</span>
              <span class="n">grad</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">d</span> <span class="o">*</span> <span class="mi">1</span><span class="n">j</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">ans</span><span class="p">,</span> <span class="n">expected</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">check</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">check</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">check</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
True
True
</pre></div>
</div>
</div>
</div>
<p>What about VJPs? We do something pretty similar: for a cotangent vector <span class="math notranslate nohighlight">\(c + di \in \mathbb{C}\)</span> we define the VJP of <span class="math notranslate nohighlight">\(f\)</span> as</p>
<p><span class="math notranslate nohighlight">\((c + di)^* \; \partial f(x + y i) =
\begin{matrix} \begin{bmatrix} c &amp; -d \end{bmatrix} \\ ~ \end{matrix}
\begin{bmatrix} \partial_0 u(x, y) &amp; \partial_1 u(x, y) \\ \partial_0 v(x, y) &amp; \partial_1 v(x, y) \end{bmatrix}
\begin{bmatrix} 1 \\ -i \end{bmatrix}\)</span>.</p>
<p>What‚Äôs with the negatives? They‚Äôre just to take care of complex conjugation, and the fact that we‚Äôre working with covectors.</p>
<p>Here‚Äôs a check of the VJP rules:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">check</span><span class="p">(</span><span class="n">seed</span><span class="p">):</span>
  <span class="n">key</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">key</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

  <span class="c1"># random coeffs for u and v</span>
  <span class="n">key</span><span class="p">,</span> <span class="n">subkey</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
  <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">subkey</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,))</span>

  <span class="k">def</span> <span class="nf">fun</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">imag</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">u</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="n">v</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1</span><span class="n">j</span>

  <span class="k">def</span> <span class="nf">u</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">a</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span> <span class="o">*</span> <span class="n">y</span>

  <span class="k">def</span> <span class="nf">v</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">c</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">d</span> <span class="o">*</span> <span class="n">y</span>

  <span class="c1"># primal point</span>
  <span class="n">key</span><span class="p">,</span> <span class="n">subkey</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
  <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">subkey</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,))</span>
  <span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span> <span class="o">*</span> <span class="mi">1</span><span class="n">j</span>

  <span class="c1"># cotangent vector</span>
  <span class="n">key</span><span class="p">,</span> <span class="n">subkey</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
  <span class="n">c</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">subkey</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,))</span>
  <span class="n">z_bar</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">c</span> <span class="o">+</span> <span class="n">d</span> <span class="o">*</span> <span class="mi">1</span><span class="n">j</span><span class="p">)</span>  <span class="c1"># for dtype control</span>

  <span class="c1"># check vjp</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">fun_vjp</span> <span class="o">=</span> <span class="n">vjp</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>
  <span class="n">ans</span><span class="p">,</span> <span class="o">=</span> <span class="n">fun_vjp</span><span class="p">(</span><span class="n">z_bar</span><span class="p">)</span>
  <span class="n">expected</span> <span class="o">=</span> <span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="mi">0</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">c</span> <span class="o">+</span>
              <span class="n">grad</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="mi">0</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">d</span><span class="p">)</span> <span class="o">+</span>
              <span class="n">grad</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">c</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="n">j</span><span class="p">)</span> <span class="o">+</span>
              <span class="n">grad</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">d</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="n">j</span><span class="p">))</span>
  <span class="k">assert</span> <span class="n">jnp</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">ans</span><span class="p">,</span> <span class="n">expected</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">check</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">check</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">check</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>What about convenience wrappers like <a class="reference internal" href="_autosummary/jax.grad.html#jax.grad" title="jax.grad"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.grad()</span></code></a>, <a class="reference internal" href="_autosummary/jax.jacfwd.html#jax.jacfwd" title="jax.jacfwd"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jacfwd()</span></code></a>, and <a class="reference internal" href="_autosummary/jax.jacrev.html#jax.jacrev" title="jax.jacrev"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jacrev()</span></code></a>?</p>
<p>For <span class="math notranslate nohighlight">\(\mathbb{R} \to \mathbb{R}\)</span> functions, recall we defined <code class="docutils literal notranslate"><span class="pre">grad(f)(x)</span></code> as being <code class="docutils literal notranslate"><span class="pre">vjp(f,</span> <span class="pre">x)[1](1.0)</span></code>, which works because applying a VJP to a <code class="docutils literal notranslate"><span class="pre">1.0</span></code> value reveals the gradient (i.e. Jacobian, or derivative). We can do the same thing for <span class="math notranslate nohighlight">\(\mathbb{C} \to \mathbb{R}\)</span> functions: we can still use <code class="docutils literal notranslate"><span class="pre">1.0</span></code> as the cotangent vector, and we just get out a complex number result summarizing the full Jacobian:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
  <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">real</span><span class="p">(</span><span class="n">z</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">imag</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">y</span><span class="o">**</span><span class="mi">2</span>

<span class="n">z</span> <span class="o">=</span> <span class="mf">3.</span> <span class="o">+</span> <span class="mi">4</span><span class="n">j</span>
<span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="n">z</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Array(6.-8.j, dtype=complex64)
</pre></div>
</div>
</div>
</div>
<p>For general <span class="math notranslate nohighlight">\(\mathbb{C} \to \mathbb{C}\)</span> functions, the Jacobian has 4 real-valued degrees of freedom (as in the 2x2 Jacobian matrices above), so we can‚Äôt hope to represent all of them within a complex number. But we can for holomorphic functions! A holomorphic function is precisely a <span class="math notranslate nohighlight">\(\mathbb{C} \to \mathbb{C}\)</span> function with the special property that its derivative can be represented as a single complex number. (The <a class="reference external" href="https://en.wikipedia.org/wiki/Cauchy%E2%80%93Riemann_equations">Cauchy-Riemann equations</a> ensure that the above 2x2 Jacobians have the special form of a scale-and-rotate matrix in the complex plane, i.e. the action of a single complex number under multiplication.) And we can reveal that one complex number using a single call to <code class="docutils literal notranslate"><span class="pre">vjp</span></code> with a covector of <code class="docutils literal notranslate"><span class="pre">1.0</span></code>.</p>
<p>Because this only works for holomorphic functions, to use this trick we need to promise JAX that our function is holomorphic; otherwise, JAX will raise an error when <a class="reference internal" href="_autosummary/jax.grad.html#jax.grad" title="jax.grad"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.grad()</span></code></a> is used for a complex-output function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

<span class="n">z</span> <span class="o">=</span> <span class="mf">3.</span> <span class="o">+</span> <span class="mi">4</span><span class="n">j</span>
<span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">holomorphic</span><span class="o">=</span><span class="kc">True</span><span class="p">)(</span><span class="n">z</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Array(-27.034946-3.8511534j, dtype=complex64, weak_type=True)
</pre></div>
</div>
</div>
</div>
<p>All the <code class="docutils literal notranslate"><span class="pre">holomorphic=True</span></code> promise does is disable the error when the output is complex-valued. We can still write <code class="docutils literal notranslate"><span class="pre">holomorphic=True</span></code> when the function isn‚Äôt holomorphic, but the answer we get out won‚Äôt represent the full Jacobian. Instead, it‚Äôll be the Jacobian of the function where we just discard the imaginary part of the output:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">conjugate</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

<span class="n">z</span> <span class="o">=</span> <span class="mf">3.</span> <span class="o">+</span> <span class="mi">4</span><span class="n">j</span>
<span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">holomorphic</span><span class="o">=</span><span class="kc">True</span><span class="p">)(</span><span class="n">z</span><span class="p">)</span>  <span class="c1"># f is not actually holomorphic!</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Array(1.-0.j, dtype=complex64, weak_type=True)
</pre></div>
</div>
</div>
</div>
<p>There are some useful upshots for how <a class="reference internal" href="_autosummary/jax.grad.html#jax.grad" title="jax.grad"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.grad()</span></code></a> works here:</p>
<ol class="arabic simple">
<li><p>We can use <a class="reference internal" href="_autosummary/jax.grad.html#jax.grad" title="jax.grad"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.grad()</span></code></a> on holomorphic <span class="math notranslate nohighlight">\(\mathbb{C} \to \mathbb{C}\)</span> functions.</p></li>
<li><p>We can use <a class="reference internal" href="_autosummary/jax.grad.html#jax.grad" title="jax.grad"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.grad()</span></code></a> to optimize <span class="math notranslate nohighlight">\(f : \mathbb{C} \to \mathbb{R}\)</span> functions, like real-valued loss functions of complex parameters <code class="docutils literal notranslate"><span class="pre">x</span></code>, by taking steps in the direction of the conjugate of <code class="docutils literal notranslate"><span class="pre">grad(f)(x)</span></code>.</p></li>
<li><p>If we have an <span class="math notranslate nohighlight">\(\mathbb{R} \to \mathbb{R}\)</span> function that just happens to use some complex-valued operations internally (some of which must be non-holomorphic, e.g. FFTs used in convolutions) then <a class="reference internal" href="_autosummary/jax.grad.html#jax.grad" title="jax.grad"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.grad()</span></code></a> still works and we get the same result that an implementation using only real values would have given.</p></li>
</ol>
<p>In any case, JVPs and VJPs are always unambiguous. And if we wanted to compute the full Jacobian matrix of a non-holomorphic <span class="math notranslate nohighlight">\(\mathbb{C} \to \mathbb{C}\)</span> function, we can do it with JVPs or VJPs!</p>
<p>You should expect complex numbers to work everywhere in JAX. Here‚Äôs differentiating through a Cholesky decomposition of a complex matrix:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">5.</span><span class="p">,</span>    <span class="mf">2.</span><span class="o">+</span><span class="mi">3</span><span class="n">j</span><span class="p">,</span>    <span class="mi">5</span><span class="n">j</span><span class="p">],</span>
              <span class="p">[</span><span class="mf">2.</span><span class="o">-</span><span class="mi">3</span><span class="n">j</span><span class="p">,</span>   <span class="mf">7.</span><span class="p">,</span>  <span class="mf">1.</span><span class="o">+</span><span class="mi">7</span><span class="n">j</span><span class="p">],</span>
              <span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="n">j</span><span class="p">,</span>  <span class="mf">1.</span><span class="o">-</span><span class="mi">7</span><span class="n">j</span><span class="p">,</span>    <span class="mf">12.</span><span class="p">]])</span>

<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="n">L</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">L</span> <span class="o">-</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">L</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">holomorphic</span><span class="o">=</span><span class="kc">True</span><span class="p">)(</span><span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Array([[-0.75341904 +0.j       , -3.0509028 -10.940545j ,
         5.9896846  +3.5423026j],
       [-3.0509028 +10.940545j , -8.904491   +0.j       ,
        -5.1351523  -6.559373j ],
       [ 5.9896846  -3.5423026j, -5.1351523  +6.559373j ,
         0.01320427 +0.j       ]], dtype=complex64)
</pre></div>
</div>
</div>
</div>
</section>
<section id="custom-derivative-rules-for-jax-transformable-python-functions">
<span id="advanced-autodiff-custom-derivative-rules"></span><h2>Custom derivative rules for JAX-transformable Python functions<a class="headerlink" href="#custom-derivative-rules-for-jax-transformable-python-functions" title="Link to this heading">#</a></h2>
<p>There are two ways to define differentiation rules in JAX:</p>
<ol class="arabic simple">
<li><p>Using <a class="reference internal" href="_autosummary/jax.custom_jvp.html#jax.custom_jvp" title="jax.custom_jvp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_jvp()</span></code></a> and <a class="reference internal" href="_autosummary/jax.custom_vjp.html#jax.custom_vjp" title="jax.custom_vjp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_vjp()</span></code></a> to define custom differentiation rules for Python functions that are already JAX-transformable; and</p></li>
<li><p>Defining new <code class="docutils literal notranslate"><span class="pre">core.Primitive</span></code> instances along with all their transformation rules, for example to call into functions from other systems like solvers, simulators, or general numerical computing systems.</p></li>
</ol>
<p>This notebook is about #1. To read instead about #2, refer to the <a class="reference external" href="https://docs.jax.dev/en/latest/notebooks/How_JAX_primitives_work.html">notebook on adding primitives</a>.</p>
<section id="tl-dr-custom-jvps-with-jax-custom-jvp">
<h3>TL;DR: Custom JVPs with <a class="reference internal" href="_autosummary/jax.custom_jvp.html#jax.custom_jvp" title="jax.custom_jvp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_jvp()</span></code></a><a class="headerlink" href="#tl-dr-custom-jvps-with-jax-custom-jvp" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">custom_jvp</span>

<span class="nd">@custom_jvp</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">y</span>

<span class="nd">@f</span><span class="o">.</span><span class="n">defjvp</span>
<span class="k">def</span> <span class="nf">f_jvp</span><span class="p">(</span><span class="n">primals</span><span class="p">,</span> <span class="n">tangents</span><span class="p">):</span>
  <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">primals</span>
  <span class="n">x_dot</span><span class="p">,</span> <span class="n">y_dot</span> <span class="o">=</span> <span class="n">tangents</span>
  <span class="n">primal_out</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
  <span class="n">tangent_out</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_dot</span> <span class="o">*</span> <span class="n">y</span> <span class="o">+</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">y_dot</span>
  <span class="k">return</span> <span class="n">primal_out</span><span class="p">,</span> <span class="n">tangent_out</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">))</span>
<span class="n">y</span><span class="p">,</span> <span class="n">y_dot</span> <span class="o">=</span> <span class="n">jvp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">),</span> <span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_dot</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2.7278922
2.7278922
-1.2484405
-1.2484405
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Equivalent alternative using the `defjvps` convenience wrapper</span>

<span class="nd">@custom_jvp</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">y</span>

<span class="n">f</span><span class="o">.</span><span class="n">defjvps</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x_dot</span><span class="p">,</span> <span class="n">primal_out</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_dot</span> <span class="o">*</span> <span class="n">y</span><span class="p">,</span>
          <span class="k">lambda</span> <span class="n">y_dot</span><span class="p">,</span> <span class="n">primal_out</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">y_dot</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">))</span>
<span class="n">y</span><span class="p">,</span> <span class="n">y_dot</span> <span class="o">=</span> <span class="n">jvp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">),</span> <span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_dot</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2.7278922
2.7278922
-1.2484405
-1.2484405
</pre></div>
</div>
</div>
</div>
</section>
<section id="tl-dr-custom-vjps-with-jax-custom-vjp">
<h3>TL;DR: Custom VJPs with <code class="docutils literal notranslate"><span class="pre">jax.custom_vjp</span></code><a class="headerlink" href="#tl-dr-custom-vjps-with-jax-custom-vjp" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">custom_vjp</span>

<span class="nd">@custom_vjp</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">y</span>

<span class="k">def</span> <span class="nf">f_fwd</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="c1"># Returns primal output and residuals to be used in backward pass by `f_bwd`.</span>
  <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">f_bwd</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
  <span class="n">cos_x</span><span class="p">,</span> <span class="n">sin_x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">res</span> <span class="c1"># Gets residuals computed in `f_fwd`</span>
  <span class="k">return</span> <span class="p">(</span><span class="n">cos_x</span> <span class="o">*</span> <span class="n">g</span> <span class="o">*</span> <span class="n">y</span><span class="p">,</span> <span class="n">sin_x</span> <span class="o">*</span> <span class="n">g</span><span class="p">)</span>

<span class="n">f</span><span class="o">.</span><span class="n">defvjp</span><span class="p">(</span><span class="n">f_fwd</span><span class="p">,</span> <span class="n">f_bwd</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-1.2484405
</pre></div>
</div>
</div>
</div>
</section>
<section id="example-problems">
<h3>Example problems<a class="headerlink" href="#example-problems" title="Link to this heading">#</a></h3>
<p>To get an idea of what problems <a class="reference internal" href="_autosummary/jax.custom_jvp.html#jax.custom_jvp" title="jax.custom_jvp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_jvp()</span></code></a> and <a class="reference internal" href="_autosummary/jax.custom_vjp.html#jax.custom_vjp" title="jax.custom_vjp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_vjp()</span></code></a> are meant to solve, let‚Äôs go over a few examples. A more thorough introduction to the <a class="reference internal" href="_autosummary/jax.custom_jvp.html#jax.custom_jvp" title="jax.custom_jvp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_jvp()</span></code></a> and <a class="reference internal" href="_autosummary/jax.custom_vjp.html#jax.custom_vjp" title="jax.custom_vjp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_vjp()</span></code></a> APIs is in the next section.</p>
<section id="example-numerical-stability">
<h4>Example: Numerical stability<a class="headerlink" href="#example-numerical-stability" title="Link to this heading">#</a></h4>
<p>One application of <a class="reference internal" href="_autosummary/jax.custom_jvp.html#jax.custom_jvp" title="jax.custom_jvp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_jvp()</span></code></a> is to improve the numerical stability of differentiation.</p>
<p>Say we want to write a function called <code class="docutils literal notranslate"><span class="pre">log1pexp</span></code>, which computes <span class="math notranslate nohighlight">\(x \mapsto \log ( 1 + e^x )\)</span>. We can write that using <code class="docutils literal notranslate"><span class="pre">jax.numpy</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">log1pexp</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.</span> <span class="o">+</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="n">log1pexp</span><span class="p">(</span><span class="mf">3.</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Array(3.0485873, dtype=float32, weak_type=True)
</pre></div>
</div>
</div>
</div>
<p>Since it‚Äôs written in terms of <code class="docutils literal notranslate"><span class="pre">jax.numpy</span></code>, it‚Äôs JAX-transformable:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">jit</span><span class="p">(</span><span class="n">log1pexp</span><span class="p">)(</span><span class="mf">3.</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">jit</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">log1pexp</span><span class="p">))(</span><span class="mf">3.</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vmap</span><span class="p">(</span><span class="n">jit</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">log1pexp</span><span class="p">)))(</span><span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">3.</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3.0485873
0.95257413
[0.5       0.7310586 0.8807971]
</pre></div>
</div>
</div>
</div>
<p>But there‚Äôs a numerical stability problem lurking here:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">log1pexp</span><span class="p">)(</span><span class="mf">100.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>nan
</pre></div>
</div>
</div>
</div>
<p>That doesn‚Äôt seem right! After all, the derivative of <span class="math notranslate nohighlight">\(x \mapsto \log (1 + e^x)\)</span> is <span class="math notranslate nohighlight">\(x \mapsto \frac{e^x}{1 + e^x}\)</span>, and so for large values of <span class="math notranslate nohighlight">\(x\)</span> we‚Äôd expect the value to be about 1.</p>
<p>We can get a bit more insight into what‚Äôs going on by looking at the jaxpr for the gradient computation:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">make_jaxpr</span>

<span class="n">make_jaxpr</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">log1pexp</span><span class="p">))(</span><span class="mf">100.</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{ <span class=" -Color -Color-Bold -Color-Bold-Blue">lambda </span>; a<span class=" -Color -Color-Magenta">:f32[]</span>. <span class=" -Color -Color-Bold -Color-Bold-Blue">let</span>
<span class=" -Color -Color-Bold -Color-Bold-Blue">    </span>b<span class=" -Color -Color-Magenta">:f32[]</span> = exp a
    c<span class=" -Color -Color-Magenta">:f32[]</span> = add 1.0:f32[] b
    _<span class=" -Color -Color-Magenta">:f32[]</span> = log c
    d<span class=" -Color -Color-Magenta">:f32[]</span> = div 1.0:f32[] c
    e<span class=" -Color -Color-Magenta">:f32[]</span> = mul d b
  <span class=" -Color -Color-Bold -Color-Bold-Blue">in </span>(e,) }
</pre></div>
</div>
</div>
</div>
<p>Stepping through how the jaxpr would be evaluated, notice that the last line would involve multiplying values that floating point math will round to 0 and <span class="math notranslate nohighlight">\(\infty\)</span>, respectively, which is never a good idea. That is, we‚Äôre effectively evaluating <code class="docutils literal notranslate"><span class="pre">lambda</span> <span class="pre">x:</span> <span class="pre">(1</span> <span class="pre">/</span> <span class="pre">(1</span> <span class="pre">+</span> <span class="pre">jnp.exp(x)))</span> <span class="pre">*</span> <span class="pre">jnp.exp(x)</span></code> for large <code class="docutils literal notranslate"><span class="pre">x</span></code>, which effectively turns into <code class="docutils literal notranslate"><span class="pre">0.</span> <span class="pre">*</span> <span class="pre">jnp.inf</span></code>.</p>
<p>Instead of generating such large and small values, hoping for a cancellation that floats can‚Äôt always provide, we‚Äôd rather just express the derivative function as a more numerically stable program. In particular, we can write a program that more closely evaluates the equal mathematical expression <span class="math notranslate nohighlight">\(1 - \frac{1}{1 + e^x}\)</span>, with no cancellation in sight.</p>
<p>This problem is interesting because even though our definition of <code class="docutils literal notranslate"><span class="pre">log1pexp</span></code> could already be JAX-differentiated (and transformed with <a class="reference internal" href="_autosummary/jax.jit.html#jax.jit" title="jax.jit"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jit()</span></code></a>, <a class="reference internal" href="_autosummary/jax.vmap.html#jax.vmap" title="jax.vmap"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.vmap()</span></code></a>, ‚Ä¶), we‚Äôre not happy with the result of applying standard autodiff rules to the primitives comprising <code class="docutils literal notranslate"><span class="pre">log1pexp</span></code> and composing the result. Instead, we‚Äôd like to specify how the whole function <code class="docutils literal notranslate"><span class="pre">log1pexp</span></code> should be differentiated, as a unit, and thus arrange those exponentials better.</p>
<p>This is one application of custom derivative rules for Python functions that are already JAX transformable: specifying how a composite function should be differentiated, while still using its original Python definition for other transformations (like <a class="reference internal" href="_autosummary/jax.jit.html#jax.jit" title="jax.jit"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jit()</span></code></a>, <a class="reference internal" href="_autosummary/jax.vmap.html#jax.vmap" title="jax.vmap"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.vmap()</span></code></a>, ‚Ä¶).</p>
<p>Here‚Äôs a solution using <a class="reference internal" href="_autosummary/jax.custom_jvp.html#jax.custom_jvp" title="jax.custom_jvp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_jvp()</span></code></a>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@custom_jvp</span>
<span class="k">def</span> <span class="nf">log1pexp</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.</span> <span class="o">+</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="nd">@log1pexp</span><span class="o">.</span><span class="n">defjvp</span>
<span class="k">def</span> <span class="nf">log1pexp_jvp</span><span class="p">(</span><span class="n">primals</span><span class="p">,</span> <span class="n">tangents</span><span class="p">):</span>
  <span class="n">x</span><span class="p">,</span> <span class="o">=</span> <span class="n">primals</span>
  <span class="n">x_dot</span><span class="p">,</span> <span class="o">=</span> <span class="n">tangents</span>
  <span class="n">ans</span> <span class="o">=</span> <span class="n">log1pexp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="n">ans_dot</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span> <span class="o">*</span> <span class="n">x_dot</span>
  <span class="k">return</span> <span class="n">ans</span><span class="p">,</span> <span class="n">ans_dot</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">log1pexp</span><span class="p">)(</span><span class="mf">100.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.0
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">jit</span><span class="p">(</span><span class="n">log1pexp</span><span class="p">)(</span><span class="mf">3.</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">jit</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">log1pexp</span><span class="p">))(</span><span class="mf">3.</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vmap</span><span class="p">(</span><span class="n">jit</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">log1pexp</span><span class="p">)))(</span><span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">3.</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3.0485873
0.95257413
[0.5       0.7310586 0.8807971]
</pre></div>
</div>
</div>
</div>
<p>Here‚Äôs a <code class="docutils literal notranslate"><span class="pre">defjvps</span></code> convenience wrapper to express the same thing:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@custom_jvp</span>
<span class="k">def</span> <span class="nf">log1pexp</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.</span> <span class="o">+</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="n">log1pexp</span><span class="o">.</span><span class="n">defjvps</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">,</span> <span class="n">ans</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span> <span class="o">*</span> <span class="n">t</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">log1pexp</span><span class="p">)(</span><span class="mf">100.</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">jit</span><span class="p">(</span><span class="n">log1pexp</span><span class="p">)(</span><span class="mf">3.</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">jit</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">log1pexp</span><span class="p">))(</span><span class="mf">3.</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">vmap</span><span class="p">(</span><span class="n">jit</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">log1pexp</span><span class="p">)))(</span><span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">3.</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.0
3.0485873
0.95257413
[0.5       0.7310586 0.8807971]
</pre></div>
</div>
</div>
</div>
</section>
<section id="example-enforcing-a-differentiation-convention">
<h4>Example: Enforcing a differentiation convention<a class="headerlink" href="#example-enforcing-a-differentiation-convention" title="Link to this heading">#</a></h4>
<p>A related application is to enforce a differentiation convention, perhaps at a boundary.</p>
<p>Consider the function <span class="math notranslate nohighlight">\(f : \mathbb{R}_+ \to \mathbb{R}_+\)</span> with <span class="math notranslate nohighlight">\(f(x) = \frac{x}{1 + \sqrt{x}}\)</span>, where we take <span class="math notranslate nohighlight">\(\mathbb{R}_+ = [0, \infty)\)</span>. We might implement <span class="math notranslate nohighlight">\(f\)</span> as a program like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">x</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>As a mathematical function on <span class="math notranslate nohighlight">\(\mathbb{R}\)</span> (the full real line), <span class="math notranslate nohighlight">\(f\)</span> is not differentiable at zero (because the limit defining the derivative doesn‚Äôt exist from the left). Correspondingly, autodiff produces a <code class="docutils literal notranslate"><span class="pre">nan</span></code> value:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="mf">0.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>nan
</pre></div>
</div>
</div>
</div>
<p>But mathematically if we think of <span class="math notranslate nohighlight">\(f\)</span> as a function on <span class="math notranslate nohighlight">\(\mathbb{R}_+\)</span> then it is differentiable at 0 [Rudin‚Äôs Principles of Mathematical Analysis Definition 5.1, or Tao‚Äôs Analysis I 3rd ed. Definition 10.1.1 and Example 10.1.6]. Alternatively, we might say as a convention we want to consider the directional derivative from the right. So there is a sensible value for the Python function <code class="docutils literal notranslate"><span class="pre">grad(f)</span></code> to return at <code class="docutils literal notranslate"><span class="pre">0.0</span></code>, namely <code class="docutils literal notranslate"><span class="pre">1.0</span></code>. By default, JAX‚Äôs machinery for differentiation assumes all functions are defined over <span class="math notranslate nohighlight">\(\mathbb{R}\)</span> and thus doesn‚Äôt produce <code class="docutils literal notranslate"><span class="pre">1.0</span></code> here.</p>
<p>We can use a custom JVP rule! In particular, we can define the JVP rule in terms of the derivative function <span class="math notranslate nohighlight">\(x \mapsto \frac{\sqrt{x} + 2}{2(\sqrt{x} + 1)^2}\)</span> on <span class="math notranslate nohighlight">\(\mathbb{R}_+\)</span>,</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@custom_jvp</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">x</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="nd">@f</span><span class="o">.</span><span class="n">defjvp</span>
<span class="k">def</span> <span class="nf">f_jvp</span><span class="p">(</span><span class="n">primals</span><span class="p">,</span> <span class="n">tangents</span><span class="p">):</span>
  <span class="n">x</span><span class="p">,</span> <span class="o">=</span> <span class="n">primals</span>
  <span class="n">x_dot</span><span class="p">,</span> <span class="o">=</span> <span class="n">tangents</span>
  <span class="n">ans</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="n">ans_dot</span> <span class="o">=</span> <span class="p">((</span><span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span> <span class="o">*</span> <span class="n">x_dot</span>
  <span class="k">return</span> <span class="n">ans</span><span class="p">,</span> <span class="n">ans_dot</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="mf">0.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.0
</pre></div>
</div>
</div>
</div>
<p>Here‚Äôs the convenience wrapper version:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@custom_jvp</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">x</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="n">f</span><span class="o">.</span><span class="n">defjvps</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">,</span> <span class="n">ans</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="p">((</span><span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span> <span class="o">*</span> <span class="n">t</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="mf">0.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.0
</pre></div>
</div>
</div>
</div>
</section>
<section id="example-gradient-clipping">
<h4>Example: Gradient clipping<a class="headerlink" href="#example-gradient-clipping" title="Link to this heading">#</a></h4>
<p>While in some cases we want to express a mathematical differentiation computation, in other cases we may even want to take a step away from mathematics to adjust the computation autodiff performs. One canonical example is reverse-mode gradient clipping.</p>
<p>For gradient clipping, we can use <code class="xref py py-func docutils literal notranslate"><span class="pre">jnp.clip()</span></code> together with a <a class="reference internal" href="_autosummary/jax.custom_vjp.html#jax.custom_vjp" title="jax.custom_vjp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_vjp()</span></code></a> reverse-mode-only rule:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="nd">@custom_vjp</span>
<span class="k">def</span> <span class="nf">clip_gradient</span><span class="p">(</span><span class="n">lo</span><span class="p">,</span> <span class="n">hi</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">x</span>  <span class="c1"># identity function</span>

<span class="k">def</span> <span class="nf">clip_gradient_fwd</span><span class="p">(</span><span class="n">lo</span><span class="p">,</span> <span class="n">hi</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">lo</span><span class="p">,</span> <span class="n">hi</span><span class="p">)</span>  <span class="c1"># save bounds as residuals</span>

<span class="k">def</span> <span class="nf">clip_gradient_bwd</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
  <span class="n">lo</span><span class="p">,</span> <span class="n">hi</span> <span class="o">=</span> <span class="n">res</span>
  <span class="k">return</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">lo</span><span class="p">,</span> <span class="n">hi</span><span class="p">))</span>  <span class="c1"># use None to indicate zero cotangents for lo and hi</span>

<span class="n">clip_gradient</span><span class="o">.</span><span class="n">defvjp</span><span class="p">(</span><span class="n">clip_gradient_fwd</span><span class="p">,</span> <span class="n">clip_gradient_bwd</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">t</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">t</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">vmap</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">))(</span><span class="n">t</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&lt;matplotlib.lines.Line2D at 0x7fe796195e90&gt;]
</pre></div>
</div>
<img alt="_images/dadc02cd462ff7229974fd9db4f3a9b2a65a351dbdefdc4d8d21b6706c856ce4.png" src="_images/dadc02cd462ff7229974fd9db4f3a9b2a65a351dbdefdc4d8d21b6706c856ce4.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">clip_sin</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">clip_gradient</span><span class="p">(</span><span class="o">-</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">clip_sin</span><span class="p">(</span><span class="n">t</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">vmap</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">clip_sin</span><span class="p">))(</span><span class="n">t</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&lt;matplotlib.lines.Line2D at 0x7fe79622d350&gt;]
</pre></div>
</div>
<img alt="_images/f9f8473d27c57ea9f1c64cf15e97164587ab232e63bbc4c836fedf65bf391166.png" src="_images/f9f8473d27c57ea9f1c64cf15e97164587ab232e63bbc4c836fedf65bf391166.png" />
</div>
</div>
</section>
<section id="example-python-debugging">
<h4>Example: Python debugging<a class="headerlink" href="#example-python-debugging" title="Link to this heading">#</a></h4>
<p>Another application that is motivated by development workflow rather than numerics is to set a <code class="docutils literal notranslate"><span class="pre">pdb</span></code> debugger trace in the backward pass of reverse-mode autodiff.</p>
<p>When trying to track down the source of a <code class="docutils literal notranslate"><span class="pre">nan</span></code> runtime error, or just examine carefully the cotangent (gradient) values being propagated, it can be useful to insert a debugger at a point in the backward pass that corresponds to a specific point in the primal computation. You can do that with <a class="reference internal" href="_autosummary/jax.custom_vjp.html#jax.custom_vjp" title="jax.custom_vjp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_vjp()</span></code></a>.</p>
<p>We‚Äôll defer an example until the next section.</p>
</section>
<section id="example-implicit-function-differentiation-of-iterative-implementations">
<h4>Example: Implicit function differentiation of iterative implementations<a class="headerlink" href="#example-implicit-function-differentiation-of-iterative-implementations" title="Link to this heading">#</a></h4>
<p>This example gets pretty deep in the mathematical weeds!</p>
<p>Another application for <a class="reference internal" href="_autosummary/jax.custom_vjp.html#jax.custom_vjp" title="jax.custom_vjp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_vjp()</span></code></a> is reverse-mode differentiation of functions that are JAX-transformable (by <a class="reference internal" href="_autosummary/jax.jit.html#jax.jit" title="jax.jit"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jit()</span></code></a>, <a class="reference internal" href="_autosummary/jax.vmap.html#jax.vmap" title="jax.vmap"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.vmap()</span></code></a>, ‚Ä¶) but not efficiently JAX-differentiable for some reason, perhaps because they involve <a class="reference internal" href="_autosummary/jax.lax.while_loop.html#jax.lax.while_loop" title="jax.lax.while_loop"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.lax.while_loop()</span></code></a>. (It‚Äôs not possible to produce an XLA HLO program that efficiently computes the reverse-mode derivative of an XLA HLO While loop because that would require a program with unbounded memory use, which isn‚Äôt possible to express in XLA HLO, at least without ‚Äúside-effecting‚Äù interactions through infeed/outfeed.)</p>
<p>For example, consider this <code class="docutils literal notranslate"><span class="pre">fixed_point</span></code> routine which computes a fixed point by iteratively applying a function in a <code class="docutils literal notranslate"><span class="pre">while_loop</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">jax.lax</span> <span class="kn">import</span> <span class="n">while_loop</span>

<span class="k">def</span> <span class="nf">fixed_point</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">x_guess</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">cond_fun</span><span class="p">(</span><span class="n">carry</span><span class="p">):</span>
    <span class="n">x_prev</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">carry</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x_prev</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">1e-6</span>

  <span class="k">def</span> <span class="nf">body_fun</span><span class="p">(</span><span class="n">carry</span><span class="p">):</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">carry</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

  <span class="n">_</span><span class="p">,</span> <span class="n">x_star</span> <span class="o">=</span> <span class="n">while_loop</span><span class="p">(</span><span class="n">cond_fun</span><span class="p">,</span> <span class="n">body_fun</span><span class="p">,</span> <span class="p">(</span><span class="n">x_guess</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">x_guess</span><span class="p">)))</span>
  <span class="k">return</span> <span class="n">x_star</span>
</pre></div>
</div>
</div>
</div>
<p>This is an iterative procedure for numerically solving the equation <span class="math notranslate nohighlight">\(x = f(a, x)\)</span> for <span class="math notranslate nohighlight">\(x\)</span>, by iterating <span class="math notranslate nohighlight">\(x_{t+1} = f(a, x_t)\)</span> until <span class="math notranslate nohighlight">\(x_{t+1}\)</span> is sufficiently close to <span class="math notranslate nohighlight">\(x_t\)</span>. The result <span class="math notranslate nohighlight">\(x^*\)</span> depends on the parameters <span class="math notranslate nohighlight">\(a\)</span>, and so we can think of there being a function <span class="math notranslate nohighlight">\(a \mapsto x^*(a)\)</span> that is implicitly defined by equation <span class="math notranslate nohighlight">\(x = f(a, x)\)</span>.</p>
<p>We can use <code class="docutils literal notranslate"><span class="pre">fixed_point</span></code> to run iterative procedures to convergence, for example running Newton‚Äôs method to calculate square roots while only executing adds, multiplies, and divides:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">newton_sqrt</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
  <span class="n">update</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">a</span> <span class="o">/</span> <span class="n">x</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">fixed_point</span><span class="p">(</span><span class="n">update</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">newton_sqrt</span><span class="p">(</span><span class="mf">2.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.4142135
</pre></div>
</div>
</div>
</div>
<p>We can <a class="reference internal" href="_autosummary/jax.vmap.html#jax.vmap" title="jax.vmap"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.vmap()</span></code></a> or <a class="reference internal" href="_autosummary/jax.jit.html#jax.jit" title="jax.jit"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jit()</span></code></a> the function as well:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">jit</span><span class="p">(</span><span class="n">vmap</span><span class="p">(</span><span class="n">newton_sqrt</span><span class="p">))(</span><span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">])))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1.        1.4142135 1.7320509 2.       ]
</pre></div>
</div>
</div>
</div>
<p>We can‚Äôt apply reverse-mode automatic differentiation because of the <code class="docutils literal notranslate"><span class="pre">while_loop</span></code>, but it turns out we wouldn‚Äôt want to anyway: instead of differentiating through the implementation of <code class="docutils literal notranslate"><span class="pre">fixed_point</span></code> and all its iterations, we can exploit the mathematical structure to do something that is much more memory-efficient (and FLOP-efficient in this case, too!). We can instead use the implicit function theorem [Prop A.25 of Bertsekas‚Äôs Nonlinear Programming, 2nd ed.], which guarantees (under some conditions) the existence of the mathematical objects we‚Äôre about to use. In essence, we linearize the solution and solve those linear equations iteratively to compute the derivatives we want.</p>
<p>Consider again the equation <span class="math notranslate nohighlight">\(x = f(a, x)\)</span> and the function <span class="math notranslate nohighlight">\(x^*\)</span>. We want to evaluate vector-Jacobian products like <span class="math notranslate nohighlight">\(v^\mathsf{T} \mapsto v^\mathsf{T} \partial x^*(a_0)\)</span>.</p>
<p>At least in an open neighborhood around the point <span class="math notranslate nohighlight">\(a_0\)</span> at which we want to differentiate, let‚Äôs assume that the equation <span class="math notranslate nohighlight">\(x^*(a) = f(a, x^*(a))\)</span> holds for all <span class="math notranslate nohighlight">\(a\)</span>. Since the two sides are equal as functions of <span class="math notranslate nohighlight">\(a\)</span>, their derivatives must be equal as well, so let‚Äôs differentiate both sides:</p>
<p><span class="math notranslate nohighlight">\(\qquad \partial x^*(a) = \partial_0 f(a, x^*(a)) + \partial_1 f(a, x^*(a))  \partial x^*(a)\)</span>.</p>
<p>Setting <span class="math notranslate nohighlight">\(A = \partial_1 f(a_0, x^*(a_0))\)</span> and <span class="math notranslate nohighlight">\(B = \partial_0 f(a_0, x^*(a_0))\)</span>, we can write the quantity we‚Äôre after more simply as:</p>
<p><span class="math notranslate nohighlight">\(\qquad \partial x^*(a_0) = B + A \partial x^*(a_0)\)</span>,</p>
<p>or, by rearranging,</p>
<p><span class="math notranslate nohighlight">\(\qquad \partial x^*(a_0) = (I - A)^{-1} B\)</span>.</p>
<p>That means we can evaluate vector-Jacobian products, such as:</p>
<p><span class="math notranslate nohighlight">\(\qquad v^\mathsf{T} \partial x^*(a_0) = v^\mathsf{T} (I - A)^{-1} B = w^\mathsf{T} B\)</span>,</p>
<p>where <span class="math notranslate nohighlight">\(w^\mathsf{T} = v^\mathsf{T} (I - A)^{-1}\)</span>, or equivalently <span class="math notranslate nohighlight">\(w^\mathsf{T} = v^\mathsf{T} + w^\mathsf{T} A\)</span>, or equivalently <span class="math notranslate nohighlight">\(w^\mathsf{T}\)</span> is the fixed point of the map <span class="math notranslate nohighlight">\(u^\mathsf{T} \mapsto v^\mathsf{T} + u^\mathsf{T} A\)</span>. That last characterization gives us a way to write the VJP for <code class="docutils literal notranslate"><span class="pre">fixed_point</span></code> in terms of a call to <code class="docutils literal notranslate"><span class="pre">fixed_point</span></code>! Moreover, after expanding <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> back out, you can conclude you need only to evaluate VJPs of <span class="math notranslate nohighlight">\(f\)</span> at <span class="math notranslate nohighlight">\((a_0, x^*(a_0))\)</span>.</p>
<p>Here‚Äôs the upshot:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@partial</span><span class="p">(</span><span class="n">custom_vjp</span><span class="p">,</span> <span class="n">nondiff_argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,))</span>
<span class="k">def</span> <span class="nf">fixed_point</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">x_guess</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">cond_fun</span><span class="p">(</span><span class="n">carry</span><span class="p">):</span>
    <span class="n">x_prev</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">carry</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x_prev</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">1e-6</span>

  <span class="k">def</span> <span class="nf">body_fun</span><span class="p">(</span><span class="n">carry</span><span class="p">):</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">carry</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

  <span class="n">_</span><span class="p">,</span> <span class="n">x_star</span> <span class="o">=</span> <span class="n">while_loop</span><span class="p">(</span><span class="n">cond_fun</span><span class="p">,</span> <span class="n">body_fun</span><span class="p">,</span> <span class="p">(</span><span class="n">x_guess</span><span class="p">,</span> <span class="n">f</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">x_guess</span><span class="p">)))</span>
  <span class="k">return</span> <span class="n">x_star</span>

<span class="k">def</span> <span class="nf">fixed_point_fwd</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">x_init</span><span class="p">):</span>
  <span class="n">x_star</span> <span class="o">=</span> <span class="n">fixed_point</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">x_init</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">x_star</span><span class="p">,</span> <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">x_star</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">fixed_point_rev</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">x_star_bar</span><span class="p">):</span>
  <span class="n">a</span><span class="p">,</span> <span class="n">x_star</span> <span class="o">=</span> <span class="n">res</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">vjp_a</span> <span class="o">=</span> <span class="n">vjp</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">:</span> <span class="n">f</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">x_star</span><span class="p">),</span> <span class="n">a</span><span class="p">)</span>
  <span class="n">a_bar</span><span class="p">,</span> <span class="o">=</span> <span class="n">vjp_a</span><span class="p">(</span><span class="n">fixed_point</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="n">rev_iter</span><span class="p">,</span> <span class="n">f</span><span class="p">),</span>
                             <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">x_star</span><span class="p">,</span> <span class="n">x_star_bar</span><span class="p">),</span>
                             <span class="n">x_star_bar</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">a_bar</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x_star</span><span class="p">)</span>
  
<span class="k">def</span> <span class="nf">rev_iter</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">packed</span><span class="p">,</span> <span class="n">u</span><span class="p">):</span>
  <span class="n">a</span><span class="p">,</span> <span class="n">x_star</span><span class="p">,</span> <span class="n">x_star_bar</span> <span class="o">=</span> <span class="n">packed</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">vjp_x</span> <span class="o">=</span> <span class="n">vjp</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">f</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="n">x_star</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">x_star_bar</span> <span class="o">+</span> <span class="n">vjp_x</span><span class="p">(</span><span class="n">u</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">fixed_point</span><span class="o">.</span><span class="n">defvjp</span><span class="p">(</span><span class="n">fixed_point_fwd</span><span class="p">,</span> <span class="n">fixed_point_rev</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">newton_sqrt</span><span class="p">(</span><span class="mf">2.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.4142135
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">newton_sqrt</span><span class="p">)(</span><span class="mf">2.</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">newton_sqrt</span><span class="p">))(</span><span class="mf">2.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.35355338
-0.088388346
</pre></div>
</div>
</div>
</div>
<p>We can check our answers by differentiating <code class="xref py py-func docutils literal notranslate"><span class="pre">jnp.sqrt()</span></code>, which uses a totally different implementation:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">)(</span><span class="mf">2.</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">))(</span><span class="mf">2.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.35355338
-0.08838835
</pre></div>
</div>
</div>
</div>
<p>A limitation to this approach is that the argument <code class="docutils literal notranslate"><span class="pre">f</span></code> can‚Äôt close over any values involved in differentiation. That is, you might notice that we kept the parameter <code class="docutils literal notranslate"><span class="pre">a</span></code> explicit in the argument list of <code class="docutils literal notranslate"><span class="pre">fixed_point</span></code>. For this use case, consider using the low-level primitive <code class="docutils literal notranslate"><span class="pre">lax.custom_root</span></code>, which allows for derivatives in closed-over variables with custom root-finding functions.</p>
</section>
</section>
<section id="basic-usage-of-jax-custom-jvp-and-jax-custom-vjp-apis">
<h3>Basic usage of <code class="docutils literal notranslate"><span class="pre">jax.custom_jvp</span></code> and <code class="docutils literal notranslate"><span class="pre">jax.custom_vjp</span></code> APIs<a class="headerlink" href="#basic-usage-of-jax-custom-jvp-and-jax-custom-vjp-apis" title="Link to this heading">#</a></h3>
<section id="use-jax-custom-jvp-to-define-forward-mode-and-indirectly-reverse-mode-rules">
<h4>Use <code class="docutils literal notranslate"><span class="pre">jax.custom_jvp</span></code> to define forward-mode (and, indirectly, reverse-mode) rules<a class="headerlink" href="#use-jax-custom-jvp-to-define-forward-mode-and-indirectly-reverse-mode-rules" title="Link to this heading">#</a></h4>
<p>Here‚Äôs a canonical basic example of using <a class="reference internal" href="_autosummary/jax.custom_jvp.html#jax.custom_jvp" title="jax.custom_jvp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_jvp()</span></code></a>, where the comments use
<a class="reference external" href="https://wiki.haskell.org/Type_signature">Haskell-like type signatures</a>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># f :: a -&gt; b</span>
<span class="nd">@custom_jvp</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># f_jvp :: (a, T a) -&gt; (b, T b)</span>
<span class="k">def</span> <span class="nf">f_jvp</span><span class="p">(</span><span class="n">primals</span><span class="p">,</span> <span class="n">tangents</span><span class="p">):</span>
  <span class="n">x</span><span class="p">,</span> <span class="o">=</span> <span class="n">primals</span>
  <span class="n">t</span><span class="p">,</span> <span class="o">=</span> <span class="n">tangents</span>
  <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">t</span>

<span class="n">f</span><span class="o">.</span><span class="n">defjvp</span><span class="p">(</span><span class="n">f_jvp</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;function __main__.f_jvp(primals, tangents)&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="mf">3.</span><span class="p">))</span>

<span class="n">y</span><span class="p">,</span> <span class="n">y_dot</span> <span class="o">=</span> <span class="n">jvp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="mf">3.</span><span class="p">,),</span> <span class="p">(</span><span class="mf">1.</span><span class="p">,))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_dot</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.14112
0.14112
-0.9899925
</pre></div>
</div>
</div>
</div>
<p>In other words, we start with a primal function <code class="docutils literal notranslate"><span class="pre">f</span></code> that takes inputs of type <code class="docutils literal notranslate"><span class="pre">a</span></code> and produces outputs of type <code class="docutils literal notranslate"><span class="pre">b</span></code>. We associate with it a JVP rule function <code class="docutils literal notranslate"><span class="pre">f_jvp</span></code> that takes a pair of inputs representing the primal inputs of type <code class="docutils literal notranslate"><span class="pre">a</span></code> and the corresponding tangent inputs of type <code class="docutils literal notranslate"><span class="pre">T</span> <span class="pre">a</span></code>, and produces a pair of outputs representing the primal outputs of type <code class="docutils literal notranslate"><span class="pre">b</span></code> and tangent outputs of type <code class="docutils literal notranslate"><span class="pre">T</span> <span class="pre">b</span></code>. The tangent outputs should be a linear function of the tangent inputs.</p>
<p>You can also use <code class="docutils literal notranslate"><span class="pre">f.defjvp</span></code> as a decorator, as in</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@custom_jvp</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="o">...</span>

<span class="nd">@f</span><span class="o">.</span><span class="n">defjvp</span>
<span class="k">def</span> <span class="nf">f_jvp</span><span class="p">(</span><span class="n">primals</span><span class="p">,</span> <span class="n">tangents</span><span class="p">):</span>
  <span class="o">...</span>
</pre></div>
</div>
<p>Even though we defined only a JVP rule and no VJP rule, we can use both forward- and reverse-mode differentiation on <code class="docutils literal notranslate"><span class="pre">f</span></code>. JAX will automatically transpose the linear computation on tangent values from our custom JVP rule, computing the VJP as efficiently as if we had written the rule by hand:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="mf">3.</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">))(</span><span class="mf">3.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.9899925
-0.14112
</pre></div>
</div>
</div>
</div>
<p>For automatic transposition to work, the JVP rule‚Äôs output tangents must be linear as a function of the input tangents. Otherwise a transposition error is raised.</p>
<p>Multiple arguments work like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@custom_jvp</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">y</span>

<span class="nd">@f</span><span class="o">.</span><span class="n">defjvp</span>
<span class="k">def</span> <span class="nf">f_jvp</span><span class="p">(</span><span class="n">primals</span><span class="p">,</span> <span class="n">tangents</span><span class="p">):</span>
  <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">primals</span>
  <span class="n">x_dot</span><span class="p">,</span> <span class="n">y_dot</span> <span class="o">=</span> <span class="n">tangents</span>
  <span class="n">primal_out</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
  <span class="n">tangent_out</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span> <span class="o">*</span> <span class="n">x_dot</span> <span class="o">+</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">y_dot</span>
  <span class="k">return</span> <span class="n">primal_out</span><span class="p">,</span> <span class="n">tangent_out</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>12.0
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">defjvps</span></code> convenience wrapper lets us define a JVP for each argument separately, and the results are computed separately then summed:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@custom_jvp</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">f</span><span class="o">.</span><span class="n">defjvps</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">,</span> <span class="n">ans</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">jnp</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">t</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="mf">3.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.9899925
</pre></div>
</div>
</div>
</div>
<p>Here‚Äôs a <code class="docutils literal notranslate"><span class="pre">defjvps</span></code> example with multiple arguments:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@custom_jvp</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">y</span>

<span class="n">f</span><span class="o">.</span><span class="n">defjvps</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x_dot</span><span class="p">,</span> <span class="n">primal_out</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span> <span class="o">*</span> <span class="n">x_dot</span><span class="p">,</span>
          <span class="k">lambda</span> <span class="n">y_dot</span><span class="p">,</span> <span class="n">primal_out</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">y_dot</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="mi">0</span><span class="p">)(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">))</span>  <span class="c1"># same as above</span>
<span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="mi">1</span><span class="p">)(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>12.0
12.0
4.0
</pre></div>
</div>
</div>
</div>
<p>As a shorthand, with <code class="docutils literal notranslate"><span class="pre">defjvps</span></code> you can pass a <code class="docutils literal notranslate"><span class="pre">None</span></code> value to indicate that the JVP for a particular argument is zero:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@custom_jvp</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">y</span>

<span class="n">f</span><span class="o">.</span><span class="n">defjvps</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x_dot</span><span class="p">,</span> <span class="n">primal_out</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span> <span class="o">*</span> <span class="n">x_dot</span><span class="p">,</span>
          <span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="mi">0</span><span class="p">)(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">))</span>  <span class="c1"># same as above</span>
<span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="mi">1</span><span class="p">)(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>12.0
12.0
0.0
</pre></div>
</div>
</div>
</div>
<p>Calling a <a class="reference internal" href="_autosummary/jax.custom_jvp.html#jax.custom_jvp" title="jax.custom_jvp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_jvp()</span></code></a> function with keyword arguments, or writing a <a class="reference internal" href="_autosummary/jax.custom_jvp.html#jax.custom_jvp" title="jax.custom_jvp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_jvp()</span></code></a> function definition with default arguments, are both allowed so long as they can be unambiguously mapped to positional arguments based on the function signature retrieved by the standard library <code class="docutils literal notranslate"><span class="pre">inspect.signature</span></code> mechanism.</p>
<p>When you‚Äôre not performing differentiation, the function <code class="docutils literal notranslate"><span class="pre">f</span></code> is called just as if it weren‚Äôt decorated by <a class="reference internal" href="_autosummary/jax.custom_jvp.html#jax.custom_jvp" title="jax.custom_jvp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_jvp()</span></code></a>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@custom_jvp</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;called f!&#39;</span><span class="p">)</span>  <span class="c1"># a harmless side-effect</span>
  <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="nd">@f</span><span class="o">.</span><span class="n">defjvp</span>
<span class="k">def</span> <span class="nf">f_jvp</span><span class="p">(</span><span class="n">primals</span><span class="p">,</span> <span class="n">tangents</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;called f_jvp!&#39;</span><span class="p">)</span>  <span class="c1"># a harmless side-effect</span>
  <span class="n">x</span><span class="p">,</span> <span class="o">=</span> <span class="n">primals</span>
  <span class="n">t</span><span class="p">,</span> <span class="o">=</span> <span class="n">tangents</span>
  <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">t</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="mf">3.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>called f!
0.14112
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">vmap</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">3.</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">jit</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="mf">3.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>called f!
[0.         0.84147096 0.9092974 ]
called f!
0.14112
</pre></div>
</div>
</div>
</div>
<p>The custom JVP rule is invoked during differentiation, whether forward or reverse:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="p">,</span> <span class="n">y_dot</span> <span class="o">=</span> <span class="n">jvp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="mf">3.</span><span class="p">,),</span> <span class="p">(</span><span class="mf">1.</span><span class="p">,))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_dot</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>called f_jvp!
called f!
-0.9899925
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="mf">3.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>called f_jvp!
called f!
-0.9899925
</pre></div>
</div>
</div>
</div>
<p>Notice that <code class="docutils literal notranslate"><span class="pre">f_jvp</span></code> calls <code class="docutils literal notranslate"><span class="pre">f</span></code> to compute the primal outputs. In the context of higher-order differentiation, each application of a differentiation transform will use the custom JVP rule if and only if the rule calls the original <code class="docutils literal notranslate"><span class="pre">f</span></code> to compute the primal outputs. (This represents a kind of fundamental tradeoff, where we can‚Äôt make use of intermediate values from the evaluation of <code class="docutils literal notranslate"><span class="pre">f</span></code> in our rule <em>and also</em> have the rule apply in all orders of higher-order differentiation.)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grad</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">))(</span><span class="mf">3.</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>called f_jvp!
called f_jvp!
called f!
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Array(-0.14112, dtype=float32, weak_type=True)
</pre></div>
</div>
</div>
</div>
<p>You can use Python control flow with <a class="reference internal" href="_autosummary/jax.custom_jvp.html#jax.custom_jvp" title="jax.custom_jvp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_jvp()</span></code></a>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@custom_jvp</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="nd">@f</span><span class="o">.</span><span class="n">defjvp</span>
<span class="k">def</span> <span class="nf">f_jvp</span><span class="p">(</span><span class="n">primals</span><span class="p">,</span> <span class="n">tangents</span><span class="p">):</span>
  <span class="n">x</span><span class="p">,</span> <span class="o">=</span> <span class="n">primals</span>
  <span class="n">x_dot</span><span class="p">,</span> <span class="o">=</span> <span class="n">tangents</span>
  <span class="n">ans</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">ans</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x_dot</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">ans</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">x_dot</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="mf">1.</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="o">-</span><span class="mf">1.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2.0
3.0
</pre></div>
</div>
</div>
</div>
</section>
<section id="use-jax-custom-vjp-to-define-custom-reverse-mode-only-rules">
<h4>Use <code class="docutils literal notranslate"><span class="pre">jax.custom_vjp</span></code> to define custom reverse-mode-only rules<a class="headerlink" href="#use-jax-custom-vjp-to-define-custom-reverse-mode-only-rules" title="Link to this heading">#</a></h4>
<p>While <a class="reference internal" href="_autosummary/jax.custom_jvp.html#jax.custom_jvp" title="jax.custom_jvp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_jvp()</span></code></a> suffices for controlling both forward- and, via JAX‚Äôs automatic transposition, reverse-mode differentiation behavior, in some cases we may want to directly control a VJP rule, for example in the latter two example problems presented above. We can do that with <a class="reference internal" href="_autosummary/jax.custom_vjp.html#jax.custom_vjp" title="jax.custom_vjp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_vjp()</span></code></a>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">custom_vjp</span>

<span class="c1"># f :: a -&gt; b</span>
<span class="nd">@custom_vjp</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># f_fwd :: a -&gt; (b, c)</span>
<span class="k">def</span> <span class="nf">f_fwd</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># f_bwd :: (c, CT b) -&gt; CT a</span>
<span class="k">def</span> <span class="nf">f_bwd</span><span class="p">(</span><span class="n">cos_x</span><span class="p">,</span> <span class="n">y_bar</span><span class="p">):</span>
  <span class="k">return</span> <span class="p">(</span><span class="n">cos_x</span> <span class="o">*</span> <span class="n">y_bar</span><span class="p">,)</span>

<span class="n">f</span><span class="o">.</span><span class="n">defvjp</span><span class="p">(</span><span class="n">f_fwd</span><span class="p">,</span> <span class="n">f_bwd</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="mf">3.</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="mf">3.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.14112
-0.9899925
</pre></div>
</div>
</div>
</div>
<p>In other words, we again start with a primal function <code class="docutils literal notranslate"><span class="pre">f</span></code> that takes inputs of type <code class="docutils literal notranslate"><span class="pre">a</span></code> and produces outputs of type <code class="docutils literal notranslate"><span class="pre">b</span></code>. We associate with it two functions, <code class="docutils literal notranslate"><span class="pre">f_fwd</span></code> and <code class="docutils literal notranslate"><span class="pre">f_bwd</span></code>, which describe how to perform the forward- and backward-passes of reverse-mode autodiff, respectively.</p>
<p>The function <code class="docutils literal notranslate"><span class="pre">f_fwd</span></code> describes the forward pass, not only the primal computation but also what values to save for use on the backward pass. Its input signature is just like that of the primal function <code class="docutils literal notranslate"><span class="pre">f</span></code>, in that it takes a primal input of type <code class="docutils literal notranslate"><span class="pre">a</span></code>. But as output it produces a pair, where the first element is the primal output <code class="docutils literal notranslate"><span class="pre">b</span></code> and the second element is any ‚Äúresidual‚Äù data of type <code class="docutils literal notranslate"><span class="pre">c</span></code> to be stored for use by the backward pass. (This second output is analogous to <a class="reference external" href="https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html">PyTorch‚Äôs save_for_backward mechanism</a>.)</p>
<p>The function <code class="docutils literal notranslate"><span class="pre">f_bwd</span></code> describes the backward pass. It takes two inputs, where the first is the residual data of type <code class="docutils literal notranslate"><span class="pre">c</span></code> produced by <code class="docutils literal notranslate"><span class="pre">f_fwd</span></code> and the second is the output cotangents of type <code class="docutils literal notranslate"><span class="pre">CT</span> <span class="pre">b</span></code> corresponding to the output of the primal function. It produces an output of type <code class="docutils literal notranslate"><span class="pre">CT</span> <span class="pre">a</span></code> representing the cotangents corresponding to the input of the primal function. In particular, the output of <code class="docutils literal notranslate"><span class="pre">f_bwd</span></code> must be a sequence (e.g. a tuple) of length equal to the number of arguments to the primal function.</p>
<p>So multiple arguments work like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@custom_vjp</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">y</span>

<span class="k">def</span> <span class="nf">f_fwd</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">f_bwd</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
  <span class="n">cos_x</span><span class="p">,</span> <span class="n">sin_x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">res</span>
  <span class="k">return</span> <span class="p">(</span><span class="n">cos_x</span> <span class="o">*</span> <span class="n">g</span> <span class="o">*</span> <span class="n">y</span><span class="p">,</span> <span class="n">sin_x</span> <span class="o">*</span> <span class="n">g</span><span class="p">)</span>

<span class="n">f</span><span class="o">.</span><span class="n">defvjp</span><span class="p">(</span><span class="n">f_fwd</span><span class="p">,</span> <span class="n">f_bwd</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-1.2484405
</pre></div>
</div>
</div>
</div>
<p>Calling a <a class="reference internal" href="_autosummary/jax.custom_vjp.html#jax.custom_vjp" title="jax.custom_vjp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_vjp()</span></code></a> function with keyword arguments, or writing a <a class="reference internal" href="_autosummary/jax.custom_vjp.html#jax.custom_vjp" title="jax.custom_vjp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_vjp()</span></code></a> function definition with default arguments, are both allowed so long as they can be unambiguously mapped to positional arguments based on the function signature retrieved by the standard library <code class="docutils literal notranslate"><span class="pre">inspect.signature</span></code> mechanism.</p>
<p>As with <a class="reference internal" href="_autosummary/jax.custom_jvp.html#jax.custom_jvp" title="jax.custom_jvp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_jvp()</span></code></a>, the custom VJP rule composed of <code class="docutils literal notranslate"><span class="pre">f_fwd</span></code> and <code class="docutils literal notranslate"><span class="pre">f_bwd</span></code> is not invoked if differentiation is not applied. If the function is evaluated, or transformed with <a class="reference internal" href="_autosummary/jax.jit.html#jax.jit" title="jax.jit"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jit()</span></code></a>, <a class="reference internal" href="_autosummary/jax.vmap.html#jax.vmap" title="jax.vmap"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.vmap()</span></code></a>, or other non-differentiation transformations, then only <code class="docutils literal notranslate"><span class="pre">f</span></code> is called.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@custom_vjp</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;called f!&quot;</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">f_fwd</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;called f_fwd!&quot;</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">f_bwd</span><span class="p">(</span><span class="n">cos_x</span><span class="p">,</span> <span class="n">y_bar</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;called f_bwd!&quot;</span><span class="p">)</span>
  <span class="k">return</span> <span class="p">(</span><span class="n">cos_x</span> <span class="o">*</span> <span class="n">y_bar</span><span class="p">,)</span>

<span class="n">f</span><span class="o">.</span><span class="n">defvjp</span><span class="p">(</span><span class="n">f_fwd</span><span class="p">,</span> <span class="n">f_bwd</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="mf">3.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>called f!
0.14112
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">)(</span><span class="mf">3.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>called f_fwd!
called f!
called f_bwd!
-0.9899925
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="p">,</span> <span class="n">f_vjp</span> <span class="o">=</span> <span class="n">vjp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="mf">3.</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>called f_fwd!
called f!
0.14112
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">f_vjp</span><span class="p">(</span><span class="mf">1.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>called f_bwd!
(Array(-0.9899925, dtype=float32, weak_type=True),)
</pre></div>
</div>
</div>
</div>
<p><strong>Forward-mode autodiff cannot be used on the</strong> <a class="reference internal" href="_autosummary/jax.custom_vjp.html#jax.custom_vjp" title="jax.custom_vjp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_vjp()</span></code></a> <strong>function</strong> and will raise an error:</p>
<div class="cell tag_raises-exception docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">jvp</span>

<span class="k">try</span><span class="p">:</span>
  <span class="n">jvp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="mf">3.</span><span class="p">,),</span> <span class="p">(</span><span class="mf">1.</span><span class="p">,))</span>
<span class="k">except</span> <span class="ne">TypeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;ERROR! </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">e</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>called f_fwd!
called f!
ERROR! can&#39;t apply forward-mode autodiff (jvp) to a custom_vjp function.
</pre></div>
</div>
</div>
</div>
<p>If you want to use both forward- and reverse-mode, use <a class="reference internal" href="_autosummary/jax.custom_jvp.html#jax.custom_jvp" title="jax.custom_jvp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_jvp()</span></code></a> instead.</p>
<p>We can use <a class="reference internal" href="_autosummary/jax.custom_vjp.html#jax.custom_vjp" title="jax.custom_vjp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_vjp()</span></code></a> together with <code class="docutils literal notranslate"><span class="pre">pdb</span></code> to insert a debugger trace in the backward pass:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pdb</span>

<span class="nd">@custom_vjp</span>
<span class="k">def</span> <span class="nf">debug</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">x</span>  <span class="c1"># acts like identity</span>

<span class="k">def</span> <span class="nf">debug_fwd</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">debug_bwd</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
  <span class="kn">import</span> <span class="nn">pdb</span><span class="p">;</span> <span class="n">pdb</span><span class="o">.</span><span class="n">set_trace</span><span class="p">()</span>
  <span class="k">return</span> <span class="n">g</span>

<span class="n">debug</span><span class="o">.</span><span class="n">defvjp</span><span class="p">(</span><span class="n">debug_fwd</span><span class="p">,</span> <span class="n">debug_bwd</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">foo</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">debug</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>  <span class="c1"># insert pdb in corresponding backward pass step</span>
  <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">jax</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">foo</span><span class="p">)(</span><span class="mf">3.</span><span class="p">)</span>

<span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">113</span><span class="o">-</span><span class="n">b19a2dc1abf7</span><span class="o">&gt;</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span><span class="n">debug_bwd</span><span class="p">()</span>
<span class="o">-&gt;</span> <span class="k">return</span> <span class="n">g</span>
<span class="p">(</span><span class="n">Pdb</span><span class="p">)</span> <span class="n">p</span> <span class="n">x</span>
<span class="n">Array</span><span class="p">(</span><span class="mf">9.</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
<span class="p">(</span><span class="n">Pdb</span><span class="p">)</span> <span class="n">p</span> <span class="n">g</span>
<span class="n">Array</span><span class="p">(</span><span class="o">-</span><span class="mf">0.91113025</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
<span class="p">(</span><span class="n">Pdb</span><span class="p">)</span> <span class="n">q</span>
</pre></div>
</div>
</section>
</section>
<section id="more-features-and-details">
<h3>More features and details<a class="headerlink" href="#more-features-and-details" title="Link to this heading">#</a></h3>
<section id="working-with-list-tuple-dict-containers-and-other-pytrees">
<h4>Working with <code class="docutils literal notranslate"><span class="pre">list</span></code> / <code class="docutils literal notranslate"><span class="pre">tuple</span></code> / <code class="docutils literal notranslate"><span class="pre">dict</span></code> containers (and other pytrees)<a class="headerlink" href="#working-with-list-tuple-dict-containers-and-other-pytrees" title="Link to this heading">#</a></h4>
<p>You should expect standard Python containers like lists, tuples, namedtuples, and dicts to just work, along with nested versions of those. In general, any <a class="reference external" href="https://docs.jax.dev/en/latest/pytrees.html">pytrees</a> are permissible, so long as their structures are consistent according to the type constraints.</p>
<p>Here‚Äôs a contrived example with <a class="reference internal" href="_autosummary/jax.custom_jvp.html#jax.custom_jvp" title="jax.custom_jvp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_jvp()</span></code></a>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>
<span class="n">Point</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">&quot;Point&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">])</span>

<span class="nd">@custom_jvp</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">pt</span><span class="p">):</span>
  <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pt</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">pt</span><span class="o">.</span><span class="n">y</span>
  <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span>
          <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">y</span><span class="p">))}</span>

<span class="nd">@f</span><span class="o">.</span><span class="n">defjvp</span>
<span class="k">def</span> <span class="nf">f_jvp</span><span class="p">(</span><span class="n">primals</span><span class="p">,</span> <span class="n">tangents</span><span class="p">):</span>
  <span class="n">pt</span><span class="p">,</span> <span class="o">=</span> <span class="n">primals</span>
  <span class="n">pt_dot</span><span class="p">,</span> <span class="o">=</span>  <span class="n">tangents</span>
  <span class="n">ans</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">pt</span><span class="p">)</span>
  <span class="n">ans_dot</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">pt</span><span class="o">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">pt_dot</span><span class="o">.</span><span class="n">x</span><span class="p">,</span>
             <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">pt_dot</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">pt_dot</span><span class="o">.</span><span class="n">y</span><span class="p">)}</span>
  <span class="k">return</span> <span class="n">ans</span><span class="p">,</span> <span class="n">ans_dot</span>

<span class="k">def</span> <span class="nf">fun</span><span class="p">(</span><span class="n">pt</span><span class="p">):</span>
  <span class="n">dct</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">pt</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">dct</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">dct</span><span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pt</span> <span class="o">=</span> <span class="n">Point</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">pt</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;a&#39;: 1.0, &#39;b&#39;: (Array(0.84147096, dtype=float32, weak_type=True), Array(-0.41614684, dtype=float32, weak_type=True))}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">fun</span><span class="p">)(</span><span class="n">pt</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Point(x=Array(2.5403023, dtype=float32, weak_type=True), y=Array(0., dtype=float32, weak_type=True))
</pre></div>
</div>
</div>
</div>
<p>And an analogous contrived example with <a class="reference internal" href="_autosummary/jax.custom_vjp.html#jax.custom_vjp" title="jax.custom_vjp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_vjp()</span></code></a>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@custom_vjp</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">pt</span><span class="p">):</span>
  <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">pt</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">pt</span><span class="o">.</span><span class="n">y</span>
  <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span>
          <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">y</span><span class="p">))}</span>

<span class="k">def</span> <span class="nf">f_fwd</span><span class="p">(</span><span class="n">pt</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="n">pt</span><span class="p">),</span> <span class="n">pt</span>

<span class="k">def</span> <span class="nf">f_bwd</span><span class="p">(</span><span class="n">pt</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
  <span class="n">a_bar</span><span class="p">,</span> <span class="p">(</span><span class="n">b0_bar</span><span class="p">,</span> <span class="n">b1_bar</span><span class="p">)</span> <span class="o">=</span> <span class="n">g</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">],</span> <span class="n">g</span><span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">]</span>
  <span class="n">x_bar</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">pt</span><span class="o">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">a_bar</span> <span class="o">+</span> <span class="n">jnp</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">b0_bar</span>
  <span class="n">y_bar</span> <span class="o">=</span> <span class="o">-</span><span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="n">b1_bar</span>
  <span class="k">return</span> <span class="p">(</span><span class="n">Point</span><span class="p">(</span><span class="n">x_bar</span><span class="p">,</span> <span class="n">y_bar</span><span class="p">),)</span>

<span class="n">f</span><span class="o">.</span><span class="n">defvjp</span><span class="p">(</span><span class="n">f_fwd</span><span class="p">,</span> <span class="n">f_bwd</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">fun</span><span class="p">(</span><span class="n">pt</span><span class="p">):</span>
  <span class="n">dct</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">pt</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">dct</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">dct</span><span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pt</span> <span class="o">=</span> <span class="n">Point</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">pt</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;a&#39;: 1.0, &#39;b&#39;: (Array(0.84147096, dtype=float32, weak_type=True), Array(-0.41614684, dtype=float32, weak_type=True))}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">fun</span><span class="p">)(</span><span class="n">pt</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Point(x=Array(2.5403023, dtype=float32, weak_type=True), y=Array(-0., dtype=float32, weak_type=True))
</pre></div>
</div>
</div>
</div>
</section>
<section id="handling-non-differentiable-arguments">
<h4>Handling  non-differentiable arguments<a class="headerlink" href="#handling-non-differentiable-arguments" title="Link to this heading">#</a></h4>
<p>Some use cases, like the final example problem, call for non-differentiable arguments like function-valued arguments to be passed to functions with custom differentiation rules, and for those arguments to also be passed to the rules themselves. In the case of <code class="docutils literal notranslate"><span class="pre">fixed_point</span></code>, the function argument <code class="docutils literal notranslate"><span class="pre">f</span></code> was such a non-differentiable argument. A similar situation arises with <code class="docutils literal notranslate"><span class="pre">jax.experimental.odeint</span></code>.</p>
<section id="jax-custom-jvp-with-nondiff-argnums">
<h5><code class="docutils literal notranslate"><span class="pre">jax.custom_jvp</span></code> with <code class="docutils literal notranslate"><span class="pre">nondiff_argnums</span></code><a class="headerlink" href="#jax-custom-jvp-with-nondiff-argnums" title="Link to this heading">#</a></h5>
<p>Use the optional <code class="docutils literal notranslate"><span class="pre">nondiff_argnums</span></code> parameter to <a class="reference internal" href="_autosummary/jax.custom_jvp.html#jax.custom_jvp" title="jax.custom_jvp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_jvp()</span></code></a> to indicate arguments like these. Here‚Äôs an example with <a class="reference internal" href="_autosummary/jax.custom_jvp.html#jax.custom_jvp" title="jax.custom_jvp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_jvp()</span></code></a>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="nd">@partial</span><span class="p">(</span><span class="n">custom_jvp</span><span class="p">,</span> <span class="n">nondiff_argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,))</span>
<span class="k">def</span> <span class="nf">app</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="nd">@app</span><span class="o">.</span><span class="n">defjvp</span>
<span class="k">def</span> <span class="nf">app_jvp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">primals</span><span class="p">,</span> <span class="n">tangents</span><span class="p">):</span>
  <span class="n">x</span><span class="p">,</span> <span class="o">=</span> <span class="n">primals</span>
  <span class="n">x_dot</span><span class="p">,</span> <span class="o">=</span> <span class="n">tangents</span>
  <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="mf">2.</span> <span class="o">*</span> <span class="n">x_dot</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">app</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">3</span><span class="p">,</span> <span class="mf">3.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>27.0
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="mi">1</span><span class="p">)(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">3</span><span class="p">,</span> <span class="mf">3.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2.0
</pre></div>
</div>
</div>
</div>
<p>Notice the gotcha here: no matter where in the argument list these parameters appear, they‚Äôre placed at the <em>start</em> of the signature of the corresponding JVP rule. Here‚Äôs another example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@partial</span><span class="p">(</span><span class="n">custom_jvp</span><span class="p">,</span> <span class="n">nondiff_argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">app2</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="n">g</span><span class="p">((</span><span class="n">x</span><span class="p">)))</span>

<span class="nd">@app2</span><span class="o">.</span><span class="n">defjvp</span>
<span class="k">def</span> <span class="nf">app2_jvp</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">primals</span><span class="p">,</span> <span class="n">tangents</span><span class="p">):</span>
  <span class="n">x</span><span class="p">,</span> <span class="o">=</span> <span class="n">primals</span>
  <span class="n">x_dot</span><span class="p">,</span> <span class="o">=</span> <span class="n">tangents</span>
  <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="n">g</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span> <span class="mf">3.</span> <span class="o">*</span> <span class="n">x_dot</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">app2</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">3</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">y</span><span class="p">:</span> <span class="mi">5</span> <span class="o">*</span> <span class="n">y</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3375.0
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">app2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">3</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">y</span><span class="p">:</span> <span class="mi">5</span> <span class="o">*</span> <span class="n">y</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3.0
</pre></div>
</div>
</div>
</div>
</section>
<section id="jax-custom-vjp-with-nondiff-argnums">
<h5><code class="docutils literal notranslate"><span class="pre">jax.custom_vjp</span></code> with <code class="docutils literal notranslate"><span class="pre">nondiff_argnums</span></code><a class="headerlink" href="#jax-custom-vjp-with-nondiff-argnums" title="Link to this heading">#</a></h5>
<p>A similar option exists for <a class="reference internal" href="_autosummary/jax.custom_vjp.html#jax.custom_vjp" title="jax.custom_vjp"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_vjp()</span></code></a>, and, similarly, the convention is that the non-differentiable arguments are passed as the first arguments to the <code class="docutils literal notranslate"><span class="pre">_bwd</span></code> rule, no matter where they appear in the signature of the original function. The signature of the <code class="docutils literal notranslate"><span class="pre">_fwd</span></code> rule remains unchanged - it is the same as the signature of the primal function. Here‚Äôs an example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@partial</span><span class="p">(</span><span class="n">custom_vjp</span><span class="p">,</span> <span class="n">nondiff_argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,))</span>
<span class="k">def</span> <span class="nf">app</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">app_fwd</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">app_bwd</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
  <span class="k">return</span> <span class="p">(</span><span class="mi">5</span> <span class="o">*</span> <span class="n">g</span><span class="p">,)</span>

<span class="n">app</span><span class="o">.</span><span class="n">defvjp</span><span class="p">(</span><span class="n">app_fwd</span><span class="p">,</span> <span class="n">app_bwd</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">app</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">4.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>16.0
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="mi">1</span><span class="p">)(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">4.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5.0
</pre></div>
</div>
</div>
</div>
<p>Refer to <code class="docutils literal notranslate"><span class="pre">fixed_point</span></code> above for another usage example.</p>
<p><strong>You don‚Äôt need to use</strong> <code class="docutils literal notranslate"><span class="pre">nondiff_argnums</span></code> <strong>with array-valued arguments</strong>, such as, for example, ones with the integer dtype. Instead, <code class="docutils literal notranslate"><span class="pre">nondiff_argnums</span></code> should only be used for argument values that don‚Äôt correspond to JAX types (essentially don‚Äôt correspond to array types), like Python callables or strings. If JAX detects that an argument indicated by <code class="docutils literal notranslate"><span class="pre">nondiff_argnums</span></code> contains a JAX Tracer, then an error is raised. The <code class="docutils literal notranslate"><span class="pre">clip_gradient</span></code> function above is a good example of not using <code class="docutils literal notranslate"><span class="pre">nondiff_argnums</span></code> for integer-dtype array arguments.</p>
</section>
</section>
</section>
</section>
<section id="next-steps">
<h2>Next steps<a class="headerlink" href="#next-steps" title="Link to this heading">#</a></h2>
<p>There‚Äôs a whole world of other autodiff tricks and functionality out there. Topics that weren‚Äôt covered in this tutorial but can be worth pursuing include:</p>
<ul class="simple">
<li><p>Gauss-Newton Vector Products, linearizing once</p></li>
<li><p>Custom VJPs and JVPs</p></li>
<li><p>Efficient derivatives at fixed-points</p></li>
<li><p>Estimating the trace of a Hessian using random Hessian-vector products</p></li>
<li><p>Forward-mode autodiff using only reverse-mode autodiff</p></li>
<li><p>Taking derivatives with respect to custom data types</p></li>
<li><p>Checkpointing (binomial checkpointing for efficient reverse-mode, not model snapshotting)</p></li>
<li><p>Optimizing VJPs with Jacobian pre-accumulation</p></li>
</ul>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="notebooks/autodiff_remat.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Control autodiff‚Äôs saved values with <code class="docutils literal notranslate"><span class="pre">jax.checkpoint</span></code> (aka <code class="docutils literal notranslate"><span class="pre">jax.remat</span></code>)</p>
      </div>
    </a>
    <a class="right-next"
       href="custom_pytrees.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Custom pytrees and initialization with unexpected values</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#taking-gradients-part-2">Taking gradients (part 2)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#higher-order-derivatives">Higher-order derivatives</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#higher-order-optimization">Higher-order optimization</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stopping-gradients">Stopping gradients</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#straight-through-estimator-using-stop-gradient">Straight-through estimator using <code class="docutils literal notranslate"><span class="pre">stop_gradient</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#per-example-gradients">Per-example gradients</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hessian-vector-products-with-jax-grad-of-jax-grad">Hessian-vector products with <code class="docutils literal notranslate"><span class="pre">jax.grad</span></code>-of-<code class="docutils literal notranslate"><span class="pre">jax.grad</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#jacobians-and-hessians-using-jax-jacfwd-and-jax-jacrev">Jacobians and Hessians using <code class="docutils literal notranslate"><span class="pre">jax.jacfwd</span></code> and <code class="docutils literal notranslate"><span class="pre">jax.jacrev</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-it-s-made-two-foundational-autodiff-functions">How it‚Äôs made: Two foundational autodiff functions</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#jacobian-vector-products-jvps-a-k-a-forward-mode-autodiff">Jacobian-Vector products (JVPs, a.k.a. forward-mode autodiff)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#jvps-in-math">JVPs in math</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#jvps-in-jax-code">JVPs in JAX code</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vector-jacobian-products-vjps-a-k-a-reverse-mode-autodiff">Vector-Jacobian products (VJPs, a.k.a. reverse-mode autodiff)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#vjps-in-math">VJPs in math</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#vjps-in-jax-code">VJPs in JAX code</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vector-valued-gradients-with-vjps">Vector-valued gradients with VJPs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hessian-vector-products-using-both-forward-and-reverse-mode">Hessian-vector products using both forward- and reverse-mode</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#composing-vjps-jvps-and-jax-vmap">Composing VJPs, JVPs, and <code class="docutils literal notranslate"><span class="pre">jax.vmap</span></code></a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#jacobian-matrix-and-matrix-jacobian-products">Jacobian-Matrix and Matrix-Jacobian products</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-implementation-of-jax-jacfwd-and-jax-jacrev">The implementation of <code class="docutils literal notranslate"><span class="pre">jax.jacfwd</span></code> and <code class="docutils literal notranslate"><span class="pre">jax.jacrev</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#complex-numbers-and-differentiation">Complex numbers and differentiation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#custom-derivative-rules-for-jax-transformable-python-functions">Custom derivative rules for JAX-transformable Python functions</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tl-dr-custom-jvps-with-jax-custom-jvp">TL;DR: Custom JVPs with <code class="xref py py-func docutils literal notranslate"><span class="pre">jax.custom_jvp()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tl-dr-custom-vjps-with-jax-custom-vjp">TL;DR: Custom VJPs with <code class="docutils literal notranslate"><span class="pre">jax.custom_vjp</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-problems">Example problems</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-numerical-stability">Example: Numerical stability</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-enforcing-a-differentiation-convention">Example: Enforcing a differentiation convention</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-gradient-clipping">Example: Gradient clipping</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-python-debugging">Example: Python debugging</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-implicit-function-differentiation-of-iterative-implementations">Example: Implicit function differentiation of iterative implementations</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#basic-usage-of-jax-custom-jvp-and-jax-custom-vjp-apis">Basic usage of <code class="docutils literal notranslate"><span class="pre">jax.custom_jvp</span></code> and <code class="docutils literal notranslate"><span class="pre">jax.custom_vjp</span></code> APIs</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#use-jax-custom-jvp-to-define-forward-mode-and-indirectly-reverse-mode-rules">Use <code class="docutils literal notranslate"><span class="pre">jax.custom_jvp</span></code> to define forward-mode (and, indirectly, reverse-mode) rules</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#use-jax-custom-vjp-to-define-custom-reverse-mode-only-rules">Use <code class="docutils literal notranslate"><span class="pre">jax.custom_vjp</span></code> to define custom reverse-mode-only rules</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#more-features-and-details">More features and details</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#working-with-list-tuple-dict-containers-and-other-pytrees">Working with <code class="docutils literal notranslate"><span class="pre">list</span></code> / <code class="docutils literal notranslate"><span class="pre">tuple</span></code> / <code class="docutils literal notranslate"><span class="pre">dict</span></code> containers (and other pytrees)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#handling-non-differentiable-arguments">Handling  non-differentiable arguments</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#jax-custom-jvp-with-nondiff-argnums"><code class="docutils literal notranslate"><span class="pre">jax.custom_jvp</span></code> with <code class="docutils literal notranslate"><span class="pre">nondiff_argnums</span></code></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#jax-custom-vjp-with-nondiff-argnums"><code class="docutils literal notranslate"><span class="pre">jax.custom_vjp</span></code> with <code class="docutils literal notranslate"><span class="pre">nondiff_argnums</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#next-steps">Next steps</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The JAX authors
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright 2024, The JAX Authors.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>