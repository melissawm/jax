
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>JAX Internals: primitives &#8212; JAX  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/style.css?v=537c1ddb" />
    <link rel="stylesheet" href="_static/style.css" type="text/css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=30646c52"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'jax-primitives';</script>
    <link rel="icon" href="_static/favicon.png"/>
    <link rel="author" title="About these documents" href="about.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="JAX internals: The jaxpr language" href="jaxpr.html" />
    <link rel="prev" title="Introduction to parallel programming" href="sharded-computation.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/jax_logo_250px.png" class="logo__image only-light" alt="JAX  documentation - Home"/>
    <script>document.write(`<img src="_static/jax_logo_250px.png" class="logo__image only-dark" alt="JAX  documentation - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/thinking_in_jax.html">Quickstart: How to think in JAX</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="notebooks/Common_Gotchas_in_JAX.html">üî™ JAX - The Sharp Bits üî™</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="tutorials.html">Tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="jit-compilation.html">Just-in-time compilation</a></li>
<li class="toctree-l2"><a class="reference internal" href="automatic-vectorization.html">Automatic vectorization</a></li>
<li class="toctree-l2"><a class="reference internal" href="automatic-differentiation.html">Automatic differentiation</a></li>
<li class="toctree-l2"><a class="reference internal" href="tracing.html">Tracing</a></li>
<li class="toctree-l2"><a class="reference internal" href="random-numbers.html">Pseudorandom numbers</a></li>
<li class="toctree-l2"><a class="reference internal" href="stateful-computations.html">Stateful computations</a></li>
<li class="toctree-l2"><a class="reference internal" href="control-flow.html">Control flow and logical operators with JIT</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytrees.html">Pytrees</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro_parallel.html">Introduction to Parallel Programming with JAX</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Resources and Advanced Guides</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="key-concepts.html">Key concepts</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="advanced_guide.html">Resources and Advanced Guides</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="notebooks/autodiff_cookbook.html">The Autodiff Cookbook</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/Custom_derivative_rules_for_Python_code.html">Custom derivative rules</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/autodiff_remat.html">Control autodiff‚Äôs saved values with <code class="docutils literal notranslate"><span class="pre">jax.checkpoint</span></code> (aka <code class="docutils literal notranslate"><span class="pre">jax.remat</span></code>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="advanced-autodiff.html">Advanced automatic differentiation</a></li>
<li class="toctree-l2"><a class="reference internal" href="custom_pytrees.html">Custom pytrees and initialization with unexpected values</a></li>
<li class="toctree-l2"><a class="reference internal" href="errors.html">Errors</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="debugging.html">Introduction to debugging</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="debugging/print_breakpoint.html">Compiled prints and breakpoints</a></li>
<li class="toctree-l3"><a class="reference internal" href="debugging/checkify_guide.html">The <code class="docutils literal notranslate"><span class="pre">checkify</span></code> transformation</a></li>
<li class="toctree-l3"><a class="reference internal" href="debugging/flags.html">JAX debugging flags</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="debugging/flags.html">JAX debugging flags</a></li>
<li class="toctree-l2"><a class="reference internal" href="transfer_guard.html">Transfer guard</a></li>
<li class="toctree-l2"><a class="reference internal" href="persistent_compilation_cache.html">Persistent compilation cache</a></li>
<li class="toctree-l2"><a class="reference internal" href="buffer_donation.html">Buffer donation</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu_performance_tips.html">GPU performance tips</a></li>
<li class="toctree-l2"><a class="reference internal" href="benchmarking.html">Benchmarking JAX code</a></li>
<li class="toctree-l2"><a class="reference internal" href="profiling.html">Profiling computation</a></li>
<li class="toctree-l2"><a class="reference internal" href="device_memory_profiling.html">Profiling device memory</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/Distributed_arrays_and_automatic_parallelization.html">Distributed arrays and automatic parallelization</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/explicit-sharding.html">Explicit sharding (a.k.a. ‚Äúsharding in types‚Äù)</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/shard_map.html">Manual parallelism with <code class="docutils literal notranslate"><span class="pre">shard_map</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/host-offloading.html">JAX Memories and Host Offloading</a></li>
<li class="toctree-l2"><a class="reference internal" href="multi_process.html">Introduction to multi-controller JAX (aka multi-process/multi-host JAX)</a></li>
<li class="toctree-l2"><a class="reference internal" href="distributed_data_loading.html">Distributed data loading</a></li>
<li class="toctree-l2"><a class="reference internal" href="external-callbacks.html">External callbacks</a></li>
<li class="toctree-l2"><a class="reference internal" href="ffi.html">Foreign function interface (FFI)</a></li>
<li class="toctree-l2"><a class="reference internal" href="gradient-checkpointing.html">Gradient checkpointing with <code class="docutils literal notranslate"><span class="pre">jax.checkpoint</span></code> (<code class="docutils literal notranslate"><span class="pre">jax.remat</span></code>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="aot.html">Ahead-of-time lowering and compilation</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="export/index.html">Exporting and serialization</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="export/export.html">Exporting and serializing staged-out computations</a></li>
<li class="toctree-l3"><a class="reference internal" href="export/shape_poly.html">Shape polymorphism</a></li>
<li class="toctree-l3"><a class="reference internal" href="export/jax2tf.html">Interoperation with TensorFlow</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="type_promotion.html">Type promotion semantics</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="pallas/index.html">Pallas: a JAX kernel language</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="pallas/quickstart.html">Pallas Quickstart</a></li>
<li class="toctree-l3"><a class="reference internal" href="pallas/pipelining.html">Software Pipelining</a></li>
<li class="toctree-l3"><a class="reference internal" href="pallas/grid_blockspec.html">Grids and BlockSpecs</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pallas/tpu/index.html">Pallas TPU</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="pallas/tpu/details.html">Writing TPU kernels with Pallas</a></li>
<li class="toctree-l4"><a class="reference internal" href="pallas/tpu/pipelining.html">TPU Pipelining</a></li>
<li class="toctree-l4"><a class="reference internal" href="pallas/tpu/matmul.html">Matrix Multiplication</a></li>
<li class="toctree-l4"><a class="reference internal" href="pallas/tpu/sparse.html">Scalar Prefetch and Block-Sparse Computation</a></li>
<li class="toctree-l4"><a class="reference internal" href="pallas/tpu/distributed.html">Distributed Computing in Pallas for TPUs</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pallas/gpu/index.html">Pallas:Mosaic GPU</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="pallas/gpu/reference.html">Writing Mosaic GPU kernels with Pallas</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="pallas/design/index.html">Pallas Design Notes</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="pallas/design/design.html">Pallas Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="pallas/design/async_note.html">Pallas Async Operations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pallas/CHANGELOG.html">Pallas Changelog</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/neural_network_with_tfds_data.html">Training a simple neural network, with tensorflow/datasets data loading</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/Neural_Network_and_Data_Loading.html">Training a simple neural network, with PyTorch data loading</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/vmapped_log_probs.html">Autobatching for Bayesian inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="notebooks/convolutions.html">Generalized convolutions in JAX</a></li>
<li class="toctree-l2"><a class="reference internal" href="xla_flags.html">List of XLA compiler flags</a></li>
<li class="toctree-l2"><a class="reference internal" href="sharded-computation.html">Introduction to parallel programming</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">JAX Internals: primitives</a></li>
<li class="toctree-l2"><a class="reference internal" href="jaxpr.html">JAX internals: The jaxpr language</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="contributor_guide.html">Developer notes</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="contributing.html">Contributing to JAX</a></li>
<li class="toctree-l2"><a class="reference internal" href="developer.html">Building from source</a></li>
<li class="toctree-l2"><a class="reference internal" href="investigating_a_regression.html">Investigating a regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="autodidax.html">Autodidax: JAX core from scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="autodidax2_part1.html">Autodidax2, part 1: JAX from scratch, again</a></li>

<li class="toctree-l2 has-children"><a class="reference internal" href="jep/index.html">JAX Enhancement Proposals (JEPs)</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="jep/263-prng.html">263: JAX PRNG Design</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/2026-custom-derivatives.html">2026: Custom JVP/VJP rules for JAX-transformable functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/4008-custom-vjp-update.html">4008: Custom VJP and `nondiff_argnums` update</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/4410-omnistaging.html">4410: Omnistaging</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/9263-typed-keys.html">9263: Typed keys &amp; pluggable RNGs</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/9407-type-promotion.html">9407: Design of Type Promotion Semantics for JAX</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/9419-jax-versioning.html">9419: Jax and Jaxlib versioning</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/10657-sequencing-effects.html">10657: Sequencing side-effects in JAX</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/11830-new-remat-checkpoint.html">11830: `jax.remat` / `jax.checkpoint` new implementation</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/12049-type-annotations.html">12049: Type Annotation Roadmap for JAX</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/14273-shard-map.html">14273: `shard_map` (`shmap`) for simple per-device code</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/15856-jex.html">15856: `jax.extend`, an extensions module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/17111-shmap-transpose.html">17111: Efficient transposition of `shard_map` (and other maps)</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/18137-numpy-scipy-scope.html">18137: Scope of JAX NumPy &amp; SciPy Wrappers</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/25516-effver.html">25516: Effort-based versioning</a></li>
<li class="toctree-l3"><a class="reference internal" href="jep/28661-jax-array-protocol.html">28661: Supporting the `__jax_array__` protocol</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="extensions.html">Extension guides</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="notebooks/Writing_custom_interpreters_in_Jax.html">Writing custom Jaxpr interpreters in JAX</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="jax.extend.html"><code class="docutils literal notranslate"><span class="pre">jax.extend</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="jax.extend.core.html"><code class="docutils literal notranslate"><span class="pre">jax.extend.core</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.extend.linear_util.html"><code class="docutils literal notranslate"><span class="pre">jax.extend.linear_util</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.extend.mlir.html"><code class="docutils literal notranslate"><span class="pre">jax.extend.mlir</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.extend.random.html"><code class="docutils literal notranslate"><span class="pre">jax.extend.random</span></code> module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="building_on_jax.html">Building on JAX</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="notes.html">Notes</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="api_compatibility.html">API compatibility</a></li>
<li class="toctree-l2"><a class="reference internal" href="deprecation.html">Python and NumPy version support policy</a></li>
<li class="toctree-l2"><a class="reference internal" href="async_dispatch.html">Asynchronous dispatch</a></li>
<li class="toctree-l2"><a class="reference internal" href="concurrency.html">Concurrency</a></li>
<li class="toctree-l2"><a class="reference internal" href="gpu_memory_allocation.html">GPU memory allocation</a></li>
<li class="toctree-l2"><a class="reference internal" href="rank_promotion_warning.html">Rank promotion warning</a></li>
<li class="toctree-l2"><a class="reference internal" href="default_dtypes.html">Default dtypes and the X64 flag</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="jax.html">Public API: <code class="docutils literal notranslate"><span class="pre">jax</span></code> package</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="jax.numpy.html"><code class="docutils literal notranslate"><span class="pre">jax.numpy</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.fft.html">jax.numpy.fft.fft</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.fft2.html">jax.numpy.fft.fft2</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.fftfreq.html">jax.numpy.fft.fftfreq</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.fftn.html">jax.numpy.fft.fftn</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.fftshift.html">jax.numpy.fft.fftshift</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.hfft.html">jax.numpy.fft.hfft</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.ifft.html">jax.numpy.fft.ifft</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.ifft2.html">jax.numpy.fft.ifft2</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.ifftn.html">jax.numpy.fft.ifftn</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.ifftshift.html">jax.numpy.fft.ifftshift</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.ihfft.html">jax.numpy.fft.ihfft</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.irfft.html">jax.numpy.fft.irfft</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.irfft2.html">jax.numpy.fft.irfft2</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.irfftn.html">jax.numpy.fft.irfftn</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.rfft.html">jax.numpy.fft.rfft</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.rfft2.html">jax.numpy.fft.rfft2</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.rfftfreq.html">jax.numpy.fft.rfftfreq</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.numpy.fft.rfftn.html">jax.numpy.fft.rfftn</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="jax.scipy.html"><code class="docutils literal notranslate"><span class="pre">jax.scipy</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.scipy.stats.bernoulli.logpmf.html">jax.scipy.stats.bernoulli.logpmf</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.scipy.stats.bernoulli.pmf.html">jax.scipy.stats.bernoulli.pmf</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.scipy.stats.bernoulli.cdf.html">jax.scipy.stats.bernoulli.cdf</a></li>
<li class="toctree-l3"><a class="reference internal" href="_autosummary/jax.scipy.stats.bernoulli.ppf.html">jax.scipy.stats.bernoulli.ppf</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="jax.lax.html"><code class="docutils literal notranslate"><span class="pre">jax.lax</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.random.html"><code class="docutils literal notranslate"><span class="pre">jax.random</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.sharding.html"><code class="docutils literal notranslate"><span class="pre">jax.sharding</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.debug.html"><code class="docutils literal notranslate"><span class="pre">jax.debug</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.dlpack.html"><code class="docutils literal notranslate"><span class="pre">jax.dlpack</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.distributed.html"><code class="docutils literal notranslate"><span class="pre">jax.distributed</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.dtypes.html"><code class="docutils literal notranslate"><span class="pre">jax.dtypes</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.ffi.html"><code class="docutils literal notranslate"><span class="pre">jax.ffi</span></code> module</a></li>

<li class="toctree-l2"><a class="reference internal" href="jax.flatten_util.html"><code class="docutils literal notranslate"><span class="pre">jax.flatten_util</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.image.html"><code class="docutils literal notranslate"><span class="pre">jax.image</span></code> module</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="jax.nn.html"><code class="docutils literal notranslate"><span class="pre">jax.nn</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="jax.nn.initializers.html"><code class="docutils literal notranslate"><span class="pre">jax.nn.initializers</span></code> module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="jax.ops.html"><code class="docutils literal notranslate"><span class="pre">jax.ops</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.profiler.html"><code class="docutils literal notranslate"><span class="pre">jax.profiler</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.stages.html"><code class="docutils literal notranslate"><span class="pre">jax.stages</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.test_util.html"><code class="docutils literal notranslate"><span class="pre">jax.test_util</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.tree.html"><code class="docutils literal notranslate"><span class="pre">jax.tree</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.tree_util.html"><code class="docutils literal notranslate"><span class="pre">jax.tree_util</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.typing.html"><code class="docutils literal notranslate"><span class="pre">jax.typing</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="jax.export.html"><code class="docutils literal notranslate"><span class="pre">jax.export</span></code> module</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="jax.extend.html"><code class="docutils literal notranslate"><span class="pre">jax.extend</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="jax.extend.core.html"><code class="docutils literal notranslate"><span class="pre">jax.extend.core</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.extend.linear_util.html"><code class="docutils literal notranslate"><span class="pre">jax.extend.linear_util</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.extend.mlir.html"><code class="docutils literal notranslate"><span class="pre">jax.extend.mlir</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.extend.random.html"><code class="docutils literal notranslate"><span class="pre">jax.extend.random</span></code> module</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="jax.example_libraries.html"><code class="docutils literal notranslate"><span class="pre">jax.example_libraries</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="jax.example_libraries.optimizers.html"><code class="docutils literal notranslate"><span class="pre">jax.example_libraries.optimizers</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.example_libraries.stax.html"><code class="docutils literal notranslate"><span class="pre">jax.example_libraries.stax</span></code> module</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="jax.experimental.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-20"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="jax.experimental.checkify.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.checkify</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.experimental.compilation_cache.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.compilation_cache</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.experimental.custom_dce.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.custom_dce</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.experimental.custom_partitioning.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.custom_partitioning</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.experimental.jet.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.jet</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.experimental.key_reuse.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.key_reuse</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.experimental.mesh_utils.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.mesh_utils</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.experimental.multihost_utils.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.multihost_utils</span></code> module</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="jax.experimental.pallas.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.pallas</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-21"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="jax.experimental.pallas.mosaic_gpu.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.pallas.mosaic_gpu</span></code> module</a></li>
<li class="toctree-l4"><a class="reference internal" href="jax.experimental.pallas.triton.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.pallas.triton</span></code> module</a></li>
<li class="toctree-l4"><a class="reference internal" href="jax.experimental.pallas.tpu.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.pallas.tpu</span></code> module</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="jax.experimental.pjit.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.pjit</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.experimental.serialize_executable.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.serialize_executable</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="jax.experimental.shard_map.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.shard_map</span></code> module</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="jax.experimental.sparse.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.sparse</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-22"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.BCOO.html">jax.experimental.sparse.BCOO</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_broadcast_in_dim.html">jax.experimental.sparse.bcoo_broadcast_in_dim</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_concatenate.html">jax.experimental.sparse.bcoo_concatenate</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_dot_general.html">jax.experimental.sparse.bcoo_dot_general</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_dot_general_sampled.html">jax.experimental.sparse.bcoo_dot_general_sampled</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_dynamic_slice.html">jax.experimental.sparse.bcoo_dynamic_slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_extract.html">jax.experimental.sparse.bcoo_extract</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_fromdense.html">jax.experimental.sparse.bcoo_fromdense</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_gather.html">jax.experimental.sparse.bcoo_gather</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_multiply_dense.html">jax.experimental.sparse.bcoo_multiply_dense</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_multiply_sparse.html">jax.experimental.sparse.bcoo_multiply_sparse</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_update_layout.html">jax.experimental.sparse.bcoo_update_layout</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_reduce_sum.html">jax.experimental.sparse.bcoo_reduce_sum</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_reshape.html">jax.experimental.sparse.bcoo_reshape</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_slice.html">jax.experimental.sparse.bcoo_slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_sort_indices.html">jax.experimental.sparse.bcoo_sort_indices</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_squeeze.html">jax.experimental.sparse.bcoo_squeeze</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_sum_duplicates.html">jax.experimental.sparse.bcoo_sum_duplicates</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_todense.html">jax.experimental.sparse.bcoo_todense</a></li>
<li class="toctree-l4"><a class="reference internal" href="_autosummary/jax.experimental.sparse.bcoo_transpose.html">jax.experimental.sparse.bcoo_transpose</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="jax.lib.html"><code class="docutils literal notranslate"><span class="pre">jax.lib</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.addressable_shards.html">jax.Array.addressable_shards</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.all.html">jax.Array.all</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.any.html">jax.Array.any</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.argmax.html">jax.Array.argmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.argmin.html">jax.Array.argmin</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.argpartition.html">jax.Array.argpartition</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.argsort.html">jax.Array.argsort</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.astype.html">jax.Array.astype</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.at.html">jax.Array.at</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.choose.html">jax.Array.choose</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.clip.html">jax.Array.clip</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.compress.html">jax.Array.compress</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.committed.html">jax.Array.committed</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.conj.html">jax.Array.conj</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.conjugate.html">jax.Array.conjugate</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.copy.html">jax.Array.copy</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.copy_to_host_async.html">jax.Array.copy_to_host_async</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.cumprod.html">jax.Array.cumprod</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.cumsum.html">jax.Array.cumsum</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.device.html">jax.Array.device</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.diagonal.html">jax.Array.diagonal</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.dot.html">jax.Array.dot</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.dtype.html">jax.Array.dtype</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.flat.html">jax.Array.flat</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.flatten.html">jax.Array.flatten</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.global_shards.html">jax.Array.global_shards</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.imag.html">jax.Array.imag</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.is_fully_addressable.html">jax.Array.is_fully_addressable</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.is_fully_replicated.html">jax.Array.is_fully_replicated</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.item.html">jax.Array.item</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.itemsize.html">jax.Array.itemsize</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.max.html">jax.Array.max</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.mean.html">jax.Array.mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.min.html">jax.Array.min</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.nbytes.html">jax.Array.nbytes</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.ndim.html">jax.Array.ndim</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.nonzero.html">jax.Array.nonzero</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.prod.html">jax.Array.prod</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.ptp.html">jax.Array.ptp</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.ravel.html">jax.Array.ravel</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.real.html">jax.Array.real</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.repeat.html">jax.Array.repeat</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.reshape.html">jax.Array.reshape</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.round.html">jax.Array.round</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.searchsorted.html">jax.Array.searchsorted</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.shape.html">jax.Array.shape</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.sharding.html">jax.Array.sharding</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.size.html">jax.Array.size</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.sort.html">jax.Array.sort</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.squeeze.html">jax.Array.squeeze</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.std.html">jax.Array.std</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.sum.html">jax.Array.sum</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.swapaxes.html">jax.Array.swapaxes</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.take.html">jax.Array.take</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.to_device.html">jax.Array.to_device</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.trace.html">jax.Array.trace</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.transpose.html">jax.Array.transpose</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.var.html">jax.Array.var</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.view.html">jax.Array.view</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.T.html">jax.Array.T</a></li>
<li class="toctree-l2"><a class="reference internal" href="_autosummary/jax.Array.mT.html">jax.Array.mT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="about.html">About the project</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="faq.html">Frequently asked questions (FAQ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">Change log</a></li>
<li class="toctree-l1"><a class="reference internal" href="glossary.html">Glossary of terms</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="config_options.html">Configuration Options</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="advanced_guide.html" class="nav-link">Resources and Advanced Guides</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">JAX...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/jax-ml/jax" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/jax-primitives.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>JAX Internals: primitives</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-jax-primitives">Introduction to JAX primitives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-existing-jax-primitives">Using existing JAX primitives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-new-jax-primitives">Defining new JAX primitives</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#primal-evaluation-rules">Primal evaluation rules</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-happens-when-you-use-jit">What happens when you use <code class="docutils literal notranslate"><span class="pre">jit</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#abstract-evaluation-rules">Abstract evaluation rules</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#xla-compilation-rules">XLA Compilation rules</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#forward-differentiation">Forward differentiation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#jit-of-forward-differentiation">JIT of forward differentiation</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reverse-differentiation">Reverse differentiation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transposition">Transposition</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#jit-of-reverse-differentiation">JIT of reverse differentiation</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#batching">Batching</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#jit-of-batching">JIT of batching</a></li>
</ul>
</li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="jax-internals-primitives">
<span id="jax-internals-jax-primitives"></span><h1>JAX Internals: primitives<a class="headerlink" href="#jax-internals-primitives" title="Link to this heading">#</a></h1>
<!--* freshness: { reviewed: '2024-05-03' } *-->
<section id="introduction-to-jax-primitives">
<h2>Introduction to JAX primitives<a class="headerlink" href="#introduction-to-jax-primitives" title="Link to this heading">#</a></h2>
<p>A JAX primitive is the basic computational unit of a JAX program. This document explains the interface that a JAX primitive must support to allow JAX to perform all its transformations (this is not a how-to guide).</p>
<p>For example, the multiply-add operation can be implemented in terms of the low-level <code class="docutils literal notranslate"><span class="pre">jax.lax.*</span></code> primitives (which are like XLA operator wrappers) or <code class="docutils literal notranslate"><span class="pre">jax.extend.core.Primitive(&quot;multiply_add&quot;)</span></code>, as demonstrated further below.</p>
<p>And JAX is able to take sequences of such primitive operations, and transform them via its composable transformations of Python functions, such as <a class="reference internal" href="_autosummary/jax.jit.html#jax.jit" title="jax.jit"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.jit()</span></code></a>, <a class="reference internal" href="_autosummary/jax.grad.html#jax.grad" title="jax.grad"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.grad()</span></code></a> and <a class="reference internal" href="_autosummary/jax.vmap.html#jax.vmap" title="jax.vmap"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.vmap()</span></code></a>. JAX implements these transforms in a <em>JAX-traceable</em> way. This means that when a Python function is executed, the only operations it applies to the data are either:</p>
<ul class="simple">
<li><p><strong>Inspections of data attributes:</strong> Data information, such as shape or type; or</p></li>
<li><p><strong>JAX primitives:</strong> These are the JAX special operations covered in this tutorial.</p></li>
</ul>
<p>JAX primitives know how to operate on both concrete data values and abstract JAX values. <em>A JAX-traceable function</em> can be invoked by JAX with abstract arguments. For example, a JAX abstract value ‚Äî <code class="docutils literal notranslate"><span class="pre">ShapedArray(float32[2,2])</span></code> ‚Äî captures the type and the shape of values, but not the concrete data values.</p>
<p>The JAX-transformed functions must themselves be JAX-traceable functions <em>to make sure that these transformations are composable</em>, for example like <code class="docutils literal notranslate"><span class="pre">jax.jit(jax.jacfwd(jax.grad(f)))</span></code>.</p>
<p>JAX provides pre-defined primitives corresponding to most XLA operations, including add, matmul, sin, cos, and indexing.</p>
<p>In addition, JAX offers an implementation of NumPy functions in terms of JAX primitives. This means that <em>Python programs using JAX‚Äôs implementation of NumPy are JAX-traceable and, therefore, transformable</em>. Other libraries can be made JAX-traceable by implementing them in terms of JAX primitives.</p>
<p>Furthermore, the set of JAX primitives is extensible, so instead of reimplementing a function in terms of pre-defined JAX primitives, you can define a new primitive that encapsulates the behavior of the function.</p>
<p>Consider the following example: you want to add to JAX support for a multiply-add function with three arguments, defined mathematically as <code class="docutils literal notranslate"><span class="pre">multiply_add(x,</span> <span class="pre">y,</span> <span class="pre">z)</span> <span class="pre">=</span> <span class="pre">x</span> <span class="pre">*</span> <span class="pre">y</span> <span class="pre">+</span> <span class="pre">z</span></code>. This function operates on 3 identically-shaped tensors of floating point values and performs the operations pointwise. You can do this by:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#using-existing-jax-primitives"><span class="std std-ref">Using existing JAX primitives</span></a>; or</p></li>
<li><p><a class="reference internal" href="#defining-new-jax-primitives"><span class="std std-ref">Defining new JAX primitives</span></a></p></li>
</ul>
</section>
<section id="using-existing-jax-primitives">
<span id="id1"></span><h2>Using existing JAX primitives<a class="headerlink" href="#using-existing-jax-primitives" title="Link to this heading">#</a></h2>
<p>The easiest way to define new functions is to write them in terms of JAX primitives, or in terms of other functions that are themselves written using JAX primitives, for example, those defined in the <a class="reference internal" href="jax.lax.html#module-jax.lax" title="jax.lax"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.lax()</span></code></a> module:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">lax</span>
<span class="kn">from</span> <span class="nn">jax._src</span> <span class="kn">import</span> <span class="n">api</span>

<span class="k">def</span> <span class="nf">multiply_add_lax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Implementation of multiply-add using the `jax.lax` primitives.&quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="n">lax</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">lax</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">z</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">square_add_lax</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;A square-add function using the newly defined multiply-add.&quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="n">multiply_add_lax</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;square_add_lax = &quot;</span><span class="p">,</span> <span class="n">square_add_lax</span><span class="p">(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">))</span>
<span class="c1"># Differentiate w.r.t. the first argument</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;grad(square_add_lax) = &quot;</span><span class="p">,</span> <span class="n">api</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">square_add_lax</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">0</span><span class="p">)(</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">10.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>square_add_lax =  14.0
grad(square_add_lax) =  4.0
</pre></div>
</div>
</div>
</div>
<p>To understand how JAX is internally using the primitives, add some helpers for tracing function calls:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@title Helper functions (execute this cell)</span>
<span class="kn">import</span> <span class="nn">functools</span>
<span class="kn">import</span> <span class="nn">traceback</span>

<span class="n">_indentation</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">def</span> <span class="nf">_trace</span><span class="p">(</span><span class="n">msg</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Print a message at current indentation.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">msg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  &quot;</span> <span class="o">*</span> <span class="n">_indentation</span> <span class="o">+</span> <span class="n">msg</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_trace_indent</span><span class="p">(</span><span class="n">msg</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Print a message and then indent the rest.&quot;&quot;&quot;</span>
    <span class="k">global</span> <span class="n">_indentation</span>
    <span class="n">_trace</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
    <span class="n">_indentation</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">_indentation</span>

<span class="k">def</span> <span class="nf">_trace_unindent</span><span class="p">(</span><span class="n">msg</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Unindent then print a message.&quot;&quot;&quot;</span>
    <span class="k">global</span> <span class="n">_indentation</span>
    <span class="n">_indentation</span> <span class="o">=</span> <span class="n">_indentation</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">_trace</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">trace</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;A decorator for functions to trace arguments and results.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">trace_func</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>  <span class="c1"># pylint: disable=missing-docstring</span>
    <span class="k">def</span> <span class="nf">pp</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Print certain values more succinctly&quot;&quot;&quot;</span>
        <span class="n">vtype</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
        <span class="k">if</span> <span class="s2">&quot;jax._src.xla_bridge._JaxComputationBuilder&quot;</span> <span class="ow">in</span> <span class="n">vtype</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;&lt;JaxComputationBuilder&gt;&quot;</span>
        <span class="k">elif</span> <span class="s2">&quot;jaxlib._jax_.XlaOp&quot;</span> <span class="ow">in</span> <span class="n">vtype</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;&lt;XlaOp at 0x</span><span class="si">{:x}</span><span class="s2">&gt;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">id</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
        <span class="k">elif</span> <span class="p">(</span><span class="s2">&quot;partial_eval.JaxprTracer&quot;</span> <span class="ow">in</span> <span class="n">vtype</span> <span class="ow">or</span>
              <span class="s2">&quot;batching.BatchTracer&quot;</span> <span class="ow">in</span> <span class="n">vtype</span> <span class="ow">or</span>
              <span class="s2">&quot;ad.JVPTracer&quot;</span> <span class="ow">in</span> <span class="n">vtype</span><span class="p">):</span>
            <span class="k">return</span> <span class="s2">&quot;Traced&lt;</span><span class="si">{}</span><span class="s2">&gt;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">aval</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="k">return</span> <span class="s2">&quot;(</span><span class="si">{}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pp_values</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">pp_values</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">pp</span><span class="p">(</span><span class="n">arg</span><span class="p">)</span> <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">args</span><span class="p">])</span>
    
    <span class="nd">@functools</span><span class="o">.</span><span class="n">wraps</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">func_wrapper</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
      <span class="n">_trace_indent</span><span class="p">(</span><span class="s2">&quot;call </span><span class="si">{}</span><span class="s2">(</span><span class="si">{}</span><span class="s2">)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">pp_values</span><span class="p">(</span><span class="n">args</span><span class="p">)))</span>
      <span class="n">res</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
      <span class="n">_trace_unindent</span><span class="p">(</span><span class="s2">&quot;|&lt;- </span><span class="si">{}</span><span class="s2"> = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">pp</span><span class="p">(</span><span class="n">res</span><span class="p">)))</span>
      <span class="k">return</span> <span class="n">res</span>

    <span class="k">return</span> <span class="n">func_wrapper</span>

  <span class="k">return</span> <span class="n">trace_func</span>

<span class="k">class</span> <span class="nc">expectNotImplementedError</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Context manager to check for NotImplementedError.&quot;&quot;&quot;</span>
  <span class="k">def</span> <span class="fm">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="k">pass</span>
  <span class="k">def</span> <span class="fm">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">type</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">tb</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">_indentation</span>
    <span class="n">_indentation</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="nb">type</span> <span class="ow">is</span> <span class="ne">NotImplementedError</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Found expected exception:&quot;</span><span class="p">)</span>
      <span class="n">traceback</span><span class="o">.</span><span class="n">print_exc</span><span class="p">(</span><span class="n">limit</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
      <span class="k">return</span> <span class="kc">True</span>
    <span class="k">elif</span> <span class="nb">type</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># No exception</span>
      <span class="k">assert</span> <span class="kc">False</span><span class="p">,</span> <span class="s2">&quot;Expected NotImplementedError&quot;</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="kc">False</span>
</pre></div>
</div>
</div>
</div>
<p>Instead of using <a class="reference internal" href="jax.lax.html#module-jax.lax" title="jax.lax"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.lax()</span></code></a> primitives directly, you can use other functions
that are already written in terms of those primitives, such as those in <code class="docutils literal notranslate"><span class="pre">jax.numpy</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">jnp</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="nd">@trace</span><span class="p">(</span><span class="s2">&quot;multiply_add_numpy&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">multiply_add_numpy</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">z</span><span class="p">)</span>

<span class="nd">@trace</span><span class="p">(</span><span class="s2">&quot;square_add_numpy&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">square_add_numpy</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">multiply_add_numpy</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Normal evaluation:&quot;</span><span class="p">)</span>  
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;square_add_numpy = &quot;</span><span class="p">,</span> <span class="n">square_add_numpy</span><span class="p">(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Gradient evaluation:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;grad(square_add_numpy) = &quot;</span><span class="p">,</span> <span class="n">api</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">square_add_numpy</span><span class="p">)(</span><span class="mf">2.0</span><span class="p">,</span> <span class="mf">10.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Normal evaluation:
call square_add_numpy(2.0, 10.0)
  call multiply_add_numpy(2.0, 2.0, 10.0)
  |&lt;- multiply_add_numpy = 14.0
|&lt;- square_add_numpy = 14.0
square_add_numpy =  14.0

Gradient evaluation:
call square_add_numpy(Traced&lt;~float32[]&gt;, 10.0)
  call multiply_add_numpy(Traced&lt;~float32[]&gt;, Traced&lt;~float32[]&gt;, 10.0)
  |&lt;- multiply_add_numpy = Traced&lt;~float32[]&gt;
|&lt;- square_add_numpy = Traced&lt;~float32[]&gt;
grad(square_add_numpy) =  4.0
</pre></div>
</div>
</div>
</div>
<p>Notice that in the process of computing <a class="reference internal" href="_autosummary/jax.grad.html#jax.grad" title="jax.grad"><code class="xref py py-func docutils literal notranslate"><span class="pre">jax.grad()</span></code></a>, JAX invokes <code class="docutils literal notranslate"><span class="pre">square_add_numpy</span></code> and <code class="docutils literal notranslate"><span class="pre">multiply_add_numpy</span></code> with special arguments <code class="docutils literal notranslate"><span class="pre">ConcreteArray(...)</span></code> (described further below in this colab). It is important to remember that a JAX-traceable function must be able to operate not only on concrete arguments but also on special abstract arguments that JAX may use to abstract the function execution.</p>
<p>The JAX traceability property is satisfied as long as the function is written in terms of JAX primitives.</p>
</section>
<section id="defining-new-jax-primitives">
<span id="id2"></span><h2>Defining new JAX primitives<a class="headerlink" href="#defining-new-jax-primitives" title="Link to this heading">#</a></h2>
<p>The right way to add support for multiply-add is in terms of existing JAX primitives, as shown above. However, to demonstrate how JAX primitives work, pretend that you want to add a new primitive to JAX for the multiply-add functionality.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">jax.extend</span> <span class="kn">import</span> <span class="n">core</span>

<span class="n">multiply_add_p</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">Primitive</span><span class="p">(</span><span class="s2">&quot;multiply_add&quot;</span><span class="p">)</span>  <span class="c1"># Create the primitive</span>

<span class="nd">@trace</span><span class="p">(</span><span class="s2">&quot;multiply_add_prim&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">multiply_add_prim</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;The JAX-traceable way to use the JAX primitive.</span>
<span class="sd">  </span>
<span class="sd">  Note that the traced arguments must be passed as positional arguments</span>
<span class="sd">  to `bind`. </span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="n">multiply_add_p</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>

<span class="nd">@trace</span><span class="p">(</span><span class="s2">&quot;square_add_prim&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">square_add_prim</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;A square-add function implemented using the new JAX-primitive.&quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="n">multiply_add_prim</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>If you try to call the newly defined functions, you‚Äôll get an error, because you haven‚Äôt yet told JAX anything about the semantics of the new primitive.</p>
<div class="cell tag_raises-exception docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">expectNotImplementedError</span><span class="p">():</span>
  <span class="n">square_add_prim</span><span class="p">(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(2.0, 10.0)
  call multiply_add_prim(2.0, 2.0, 10.0)

Found expected exception:
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Traceback (most recent call last):
  File &quot;/tmp/ipykernel_229732/2844449444.py&quot;, line 2, in &lt;module&gt;
    square_add_prim(2., 10.)
  File &quot;/tmp/ipykernel_229732/2803309189.py&quot;, line 48, in func_wrapper
    res = func(*args)
          ^^^^^^^^^^^
  File &quot;/tmp/ipykernel_229732/2637569133.py&quot;, line 17, in square_add_prim
    return multiply_add_prim(a, a, b)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
NotImplementedError: Evaluation rule for &#39;multiply_add&#39; not implemented
</pre></div>
</div>
</div>
</div>
<section id="primal-evaluation-rules">
<h3>Primal evaluation rules<a class="headerlink" href="#primal-evaluation-rules" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@trace</span><span class="p">(</span><span class="s2">&quot;multiply_add_impl&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">multiply_add_impl</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Concrete implementation of the primitive.</span>

<span class="sd">  This function does not need to be JAX traceable.</span>

<span class="sd">  Args:</span>
<span class="sd">    x, y, z: The concrete arguments of the primitive. Will only be called with </span>
<span class="sd">      concrete values.</span>

<span class="sd">  Returns:</span>
<span class="sd">    the concrete result of the primitive.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># Note: you can use the ordinary (non-JAX) NumPy, which is not JAX-traceable.</span>
  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">z</span><span class="p">)</span>

<span class="c1"># Now, register the primal implementation with JAX:</span>
<span class="n">multiply_add_p</span><span class="o">.</span><span class="n">def_impl</span><span class="p">(</span><span class="n">multiply_add_impl</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;function __main__.multiply_add_impl(x, y, z)&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="n">square_add_prim</span><span class="p">(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">)</span> <span class="o">==</span> <span class="mf">14.</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(2.0, 10.0)
  call multiply_add_prim(2.0, 2.0, 10.0)
    call multiply_add_impl(2.0, 2.0, 10.0)
    |&lt;- multiply_add_impl = 14.0
  |&lt;- multiply_add_prim = 14.0
|&lt;- square_add_prim = 14.0
</pre></div>
</div>
</div>
</div>
</section>
<section id="what-happens-when-you-use-jit">
<h3>What happens when you use <code class="docutils literal notranslate"><span class="pre">jit</span></code><a class="headerlink" href="#what-happens-when-you-use-jit" title="Link to this heading">#</a></h3>
<p>Now, if you try to use <code class="docutils literal notranslate"><span class="pre">jit</span></code>, you‚Äôll get a <code class="docutils literal notranslate"><span class="pre">NotImplementedError</span></code>:</p>
<div class="cell tag_raises-exception docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">expectNotImplementedError</span><span class="p">():</span>
  <span class="n">api</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">square_add_prim</span><span class="p">)(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;)
  call multiply_add_prim(Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;)

Found expected exception:
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Traceback (most recent call last):
  File &quot;/tmp/ipykernel_229732/1813425700.py&quot;, line 2, in &lt;module&gt;
    api.jit(square_add_prim)(2., 10.)
  File &quot;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/traceback_util.py&quot;, line 182, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File &quot;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/pjit.py&quot;, line 292, in cache_miss
    executable, pgle_profiler) = _python_pjit_helper(fun, jit_info, *args, **kwargs)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NotImplementedError: Abstract evaluation for &#39;multiply_add&#39; not implemented
</pre></div>
</div>
</div>
</div>
<section id="abstract-evaluation-rules">
<h4>Abstract evaluation rules<a class="headerlink" href="#abstract-evaluation-rules" title="Link to this heading">#</a></h4>
<p>To JIT the function, and for other transformations as well, JAX first evaluates it abstractly using only the shape and type of the arguments. This abstract evaluation serves multiple purposes:</p>
<ul class="simple">
<li><p>Gets the sequence of JAX primitives that are used in the computation. This sequence will be compiled.</p></li>
<li><p>Computes the shape and type of all vectors and operations used in the computation.</p></li>
</ul>
<p>For example, the abstraction of a vector with 3 elements may be <code class="docutils literal notranslate"><span class="pre">ShapedArray(float32[3])</span></code>, or <code class="docutils literal notranslate"><span class="pre">ConcreteArray([1.,</span> <span class="pre">2.,</span> <span class="pre">3.])</span></code>.  In the latter case, JAX uses the actual concrete value wrapped as an abstract value.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">core</span>

<span class="nd">@trace</span><span class="p">(</span><span class="s2">&quot;multiply_add_abstract_eval&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">multiply_add_abstract_eval</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">zs</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Abstract evaluation of the primitive.</span>

<span class="sd">  This function does not need to be JAX traceable. It will be invoked with</span>
<span class="sd">  abstractions of the actual arguments</span>

<span class="sd">  Args:</span>
<span class="sd">    xs, ys, zs: Abstractions of the arguments.</span>

<span class="sd">  Result:</span>
<span class="sd">    a ShapedArray for the result of the primitive.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">assert</span> <span class="n">xs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">ys</span><span class="o">.</span><span class="n">shape</span>
  <span class="k">assert</span> <span class="n">xs</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">zs</span><span class="o">.</span><span class="n">shape</span>
  <span class="k">return</span> <span class="n">core</span><span class="o">.</span><span class="n">ShapedArray</span><span class="p">(</span><span class="n">xs</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">xs</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

<span class="c1"># Now, register the abstract evaluation with JAX:</span>
<span class="n">multiply_add_p</span><span class="o">.</span><span class="n">def_abstract_eval</span><span class="p">(</span><span class="n">multiply_add_abstract_eval</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;function __main__.multiply_add_abstract_eval(xs, ys, zs)&gt;
</pre></div>
</div>
</div>
</div>
<p>If you re-attempt to apply <code class="docutils literal notranslate"><span class="pre">jit</span></code>, you can inspect how the abstract evaluation proceeds, but you‚Äôll get another error about missing the actual XLA compilation rule:</p>
<div class="cell tag_raises-exception docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">expectNotImplementedError</span><span class="p">():</span>
  <span class="n">api</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">square_add_prim</span><span class="p">)(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;)
  call multiply_add_prim(Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;)
    call multiply_add_abstract_eval(~float32[], ~float32[], ~float32[])
    |&lt;- multiply_add_abstract_eval = float32[]
  |&lt;- multiply_add_prim = Traced&lt;float32[]&gt;with&lt;DynamicJaxprTrace&gt;
|&lt;- square_add_prim = Traced&lt;float32[]&gt;with&lt;DynamicJaxprTrace&gt;
Found expected exception:
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Traceback (most recent call last):
  File &quot;&lt;frozen runpy&gt;&quot;, line 198, in _run_module_as_main
  File &quot;&lt;frozen runpy&gt;&quot;, line 88, in _run_code
  File &quot;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/ipykernel_launcher.py&quot;, line 18, in &lt;module&gt;
    app.launch_new_instance()
jax._src.source_info_util.JaxStackTraceBeforeTransformation: NotImplementedError: MLIR translation rule for primitive &#39;multiply_add&#39; not found for platform cpu

The preceding stack trace is the source of the JAX operation that, once transformed by JAX, triggered the following exception.

--------------------

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File &quot;/tmp/ipykernel_229732/1813425700.py&quot;, line 2, in &lt;module&gt;
    api.jit(square_add_prim)(2., 10.)
  File &quot;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/traceback_util.py&quot;, line 182, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File &quot;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/pjit.py&quot;, line 292, in cache_miss
    executable, pgle_profiler) = _python_pjit_helper(fun, jit_info, *args, **kwargs)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NotImplementedError: MLIR translation rule for primitive &#39;multiply_add&#39; not found for platform cpu
</pre></div>
</div>
</div>
</div>
</section>
<section id="xla-compilation-rules">
<h4>XLA Compilation rules<a class="headerlink" href="#xla-compilation-rules" title="Link to this heading">#</a></h4>
<p>JAX compilation works by compiling each primitive into a graph of XLA operations.</p>
<p>This is the biggest hurdle to adding new functionality to JAX, because the  set of XLA operations is limited, and JAX already has pre-defined primitives for most of them. However, XLA includes a <code class="docutils literal notranslate"><span class="pre">CustomCall</span></code> operation that can be used to encapsulate arbitrary functionality defined using C++.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">jax._src.lib.mlir.dialects</span> <span class="kn">import</span> <span class="n">hlo</span>

<span class="nd">@trace</span><span class="p">(</span><span class="s2">&quot;multiply_add_lowering&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">multiply_add_lowering</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">xc</span><span class="p">,</span> <span class="n">yc</span><span class="p">,</span> <span class="n">zc</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;The compilation to XLA of the primitive.</span>

<span class="sd">  Given an mlir.ir.Value for each argument, return the mlir.ir.Values for</span>
<span class="sd">  the results of the function.</span>

<span class="sd">  Does not need to be a JAX-traceable function.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="p">[</span><span class="n">hlo</span><span class="o">.</span><span class="n">AddOp</span><span class="p">(</span><span class="n">hlo</span><span class="o">.</span><span class="n">MulOp</span><span class="p">(</span><span class="n">xc</span><span class="p">,</span> <span class="n">yc</span><span class="p">),</span> <span class="n">zc</span><span class="p">)</span><span class="o">.</span><span class="n">result</span><span class="p">]</span>

<span class="c1"># Now, register the lowering rule with JAX.</span>
<span class="c1"># For GPU, refer to the https://docs.jax.dev/en/latest/Custom_Operation_for_GPUs.html</span>
<span class="kn">from</span> <span class="nn">jax.interpreters</span> <span class="kn">import</span> <span class="n">mlir</span>

<span class="n">mlir</span><span class="o">.</span><span class="n">register_lowering</span><span class="p">(</span><span class="n">multiply_add_p</span><span class="p">,</span> <span class="n">multiply_add_lowering</span><span class="p">,</span> <span class="n">platform</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;function __main__.multiply_add_lowering(ctx, xc, yc, zc)&gt;
</pre></div>
</div>
</div>
</div>
<p>You will now succeed to apply <code class="docutils literal notranslate"><span class="pre">jax.jit</span></code>. Notice below that JAX first evaluates the function abstractly, which triggers the <code class="docutils literal notranslate"><span class="pre">multiply_add_abstract_eval</span></code> function, and  then compiles the set of primitives it has encountered, including <code class="docutils literal notranslate"><span class="pre">multiply_add</span></code>. At this point JAX invokes <code class="docutils literal notranslate"><span class="pre">multiply_add_lowering</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="n">api</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">square_add_prim</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">)</span> <span class="o">==</span> <span class="mf">14.</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;)
  call multiply_add_prim(Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;)
    call multiply_add_abstract_eval(~float32[], ~float32[], ~float32[])
    |&lt;- multiply_add_abstract_eval = float32[]
  |&lt;- multiply_add_prim = Traced&lt;float32[]&gt;with&lt;DynamicJaxprTrace&gt;
|&lt;- square_add_prim = Traced&lt;float32[]&gt;with&lt;DynamicJaxprTrace&gt;
call multiply_add_lowering(LoweringRuleContext(module_context=ModuleContext(context=&lt;jax._src.interpreters.mlir.JaxIrContext object at 0x7f1d38113a40&gt;, module=&lt;jaxlib.mlir._mlir_libs._mlir.ir.Module object at 0x7f1d3812f6f0&gt;, ip=&lt;jaxlib.mlir._mlir_libs._mlir.ir.InsertionPoint object at 0x7f1d3812f640&gt;, symbol_table=&lt;jaxlib.mlir._mlir_libs._mlir.ir.SymbolTable object at 0x7f1d5014a940&gt;, platforms=(&#39;cpu&#39;,), backend=&lt;jaxlib._jax.Client object at 0x7f1d53bef5e0&gt;, axis_context=ShardingContext(num_devices=1, device_assignment=None, abstract_mesh=None), keepalives=[], channel_iterator=count(1), host_callbacks=[], shape_poly_state=&lt;jax._src.interpreters.mlir.ShapePolyLoweringState object at 0x7f1d38155e90&gt;, all_default_mem_kind=True, cached_primitive_lowerings={}, traceback_caches=TracebackCaches(traceback_cache={&lt;jaxlib._jax.Traceback object at 0x55898b26a120&gt;: loc(callsite(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;square_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:17:9 to :35) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;&lt;lambda&gt;&quot;(&quot;/tmp/ipykernel_229732/1570919344.py&quot;:1:28 to :49) at callsite(&quot;&lt;module&gt;&quot;(&quot;/tmp/ipykernel_229732/1570919344.py&quot;:1:7 to :59) at callsite(&quot;_run_code&quot;(&quot;&lt;frozen runpy&gt;&quot;:88:4 to :27) at &quot;_run_module_as_main&quot;(&quot;&lt;frozen runpy&gt;&quot;:198:11 to 199:42)))))))))}, location_cache={(&lt;code object multiply_add_prim at 0x7f1d53ce3730, file &quot;/tmp/ipykernel_229732/2637569133.py&quot;, line 5&gt;, 54): loc(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37)), (&lt;code object func_wrapper at 0x7f1d53d71230, file &quot;/tmp/ipykernel_229732/2803309189.py&quot;, line 45&gt;, 98): loc(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23)), (&lt;code object square_add_prim at 0x7f1d500ee950, file &quot;/tmp/ipykernel_229732/2637569133.py&quot;, line 14&gt;, 32): loc(&quot;square_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:17:9 to :35)), (&lt;code object &lt;lambda&gt; at 0x7f1d5018ebf0, file &quot;/tmp/ipykernel_229732/1570919344.py&quot;, line 1&gt;, 30): loc(&quot;&lt;lambda&gt;&quot;(&quot;/tmp/ipykernel_229732/1570919344.py&quot;:1:28 to :49)), (&lt;code object &lt;module&gt; at 0x7f1d501b6230, file &quot;/tmp/ipykernel_229732/1570919344.py&quot;, line 1&gt;, 54): loc(&quot;&lt;module&gt;&quot;(&quot;/tmp/ipykernel_229732/1570919344.py&quot;:1:7 to :59)), (&lt;code object _run_code at 0x558966317d00, file &quot;&lt;frozen runpy&gt;&quot;, line 65&gt;, 202): loc(&quot;_run_code&quot;(&quot;&lt;frozen runpy&gt;&quot;:88:4 to :27)), (&lt;code object _run_module_as_main at 0x558966316640, file &quot;&lt;frozen runpy&gt;&quot;, line 173&gt;, 366): loc(&quot;_run_module_as_main&quot;(&quot;&lt;frozen runpy&gt;&quot;:198:11 to 199:42))}, canonical_name_cache={&#39;/tmp/ipykernel_229732/2637569133.py&#39;: &#39;/tmp/ipykernel_229732/2637569133.py&#39;, &#39;/tmp/ipykernel_229732/2803309189.py&#39;: &#39;/tmp/ipykernel_229732/2803309189.py&#39;, &#39;/tmp/ipykernel_229732/1570919344.py&#39;: &#39;/tmp/ipykernel_229732/1570919344.py&#39;, &#39;&lt;frozen runpy&gt;&#39;: &#39;&lt;frozen runpy&gt;&#39;}, is_user_file_cache={&#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/source_info_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/interpreters/partial_eval.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/core.py&#39;: False, &#39;/tmp/ipykernel_229732/2637569133.py&#39;: True, &#39;/tmp/ipykernel_229732/2803309189.py&#39;: True, &#39;/tmp/ipykernel_229732/1570919344.py&#39;: True, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/linear_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/api_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/profiler.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/pjit.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/traceback_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/IPython/core/interactiveshell.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/IPython/core/async_helpers.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/ipykernel/zmqshell.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/ipykernel/ipkernel.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/ipykernel/kernelbase.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/asyncio/events.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/asyncio/base_events.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/tornado/platform/asyncio.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/ipykernel/kernelapp.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/traitlets/config/application.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/ipykernel_launcher.py&#39;: False, &#39;&lt;frozen runpy&gt;&#39;: True}), lowering_parameters=LoweringParameters(override_lowering_rules=None, global_constant_computation=False, for_export=False, export_ignore_forward_compatibility=False)), name_stack=NameStack(stack=(Scope(name=&#39;jit(&lt;lambda&gt;)&#39;), Scope(name=&#39;jit(main)&#39;))), primitive=multiply_add, avals_in=[ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True)], avals_out=[ShapedArray(float32[])], tokens_in=&lt;jax._src.interpreters.mlir.TokenSet object at 0x7f1d38157190&gt;, tokens_out=None, axis_size_env=None, dim_var_values=[], jaxpr_eqn_ctx=JaxprEqnContext(compute_type=None, threefry_partitionable=True, cur_abstract_mesh=AbstractMesh((), axis_types=()), xla_metadata=None), platforms=None), Value(&lt;block argument&gt; of type &#39;tensor&lt;f32&gt;&#39; at index: 0), Value(&lt;block argument&gt; of type &#39;tensor&lt;f32&gt;&#39; at index: 0), Value(&lt;block argument&gt; of type &#39;tensor&lt;f32&gt;&#39; at index: 1))
|&lt;- multiply_add_lowering = [&lt;jaxlib.mlir._mlir_libs._mlir.ir.OpResult object at 0x7f1d501b3570&gt;]
</pre></div>
</div>
</div>
</div>
<p>Below is another use of <code class="docutils literal notranslate"><span class="pre">jit</span></code>, where you compile only with respect to the first argument. Notice how the second argument to <code class="docutils literal notranslate"><span class="pre">square_add_prim</span></code> is concrete, which leads in the third argument to <code class="docutils literal notranslate"><span class="pre">multiply_add_abstract_eval</span></code> being <code class="docutils literal notranslate"><span class="pre">ConcreteArray</span></code>. Notice that <code class="docutils literal notranslate"><span class="pre">multiply_add_abstract_eval</span></code> may be used with both <code class="docutils literal notranslate"><span class="pre">ShapedArray</span></code> and <code class="docutils literal notranslate"><span class="pre">ConcreteArray</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="n">api</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">square_add_prim</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> 
               <span class="n">static_argnums</span><span class="o">=</span><span class="mi">1</span><span class="p">)(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">)</span> <span class="o">==</span> <span class="mf">14.</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, 10.0)
  call multiply_add_prim(Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, 10.0)
    call multiply_add_abstract_eval(~float32[], ~float32[], ~float32[])
    |&lt;- multiply_add_abstract_eval = float32[]
  |&lt;- multiply_add_prim = Traced&lt;float32[]&gt;with&lt;DynamicJaxprTrace&gt;
|&lt;- square_add_prim = Traced&lt;float32[]&gt;with&lt;DynamicJaxprTrace&gt;
call multiply_add_lowering(LoweringRuleContext(module_context=ModuleContext(context=&lt;jax._src.interpreters.mlir.JaxIrContext object at 0x7f1d53c948c0&gt;, module=&lt;jaxlib.mlir._mlir_libs._mlir.ir.Module object at 0x7f1d38160450&gt;, ip=&lt;jaxlib.mlir._mlir_libs._mlir.ir.InsertionPoint object at 0x7f1d38160210&gt;, symbol_table=&lt;jaxlib.mlir._mlir_libs._mlir.ir.SymbolTable object at 0x7f1dac297810&gt;, platforms=(&#39;cpu&#39;,), backend=&lt;jaxlib._jax.Client object at 0x7f1d53bef5e0&gt;, axis_context=ShardingContext(num_devices=1, device_assignment=None, abstract_mesh=None), keepalives=[], channel_iterator=count(1), host_callbacks=[], shape_poly_state=&lt;jax._src.interpreters.mlir.ShapePolyLoweringState object at 0x7f1d3815d790&gt;, all_default_mem_kind=True, cached_primitive_lowerings={}, traceback_caches=TracebackCaches(traceback_cache={&lt;jaxlib._jax.Traceback object at 0x55898b40d6e0&gt;: loc(callsite(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;square_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:17:9 to :35) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;&lt;lambda&gt;&quot;(&quot;/tmp/ipykernel_229732/4165789807.py&quot;:1:28 to :49) at callsite(&quot;&lt;module&gt;&quot;(&quot;/tmp/ipykernel_229732/4165789807.py&quot;:1:7 to 2:41) at callsite(&quot;_run_code&quot;(&quot;&lt;frozen runpy&gt;&quot;:88:4 to :27) at &quot;_run_module_as_main&quot;(&quot;&lt;frozen runpy&gt;&quot;:198:11 to 199:42)))))))))}, location_cache={(&lt;code object multiply_add_prim at 0x7f1d53ce3730, file &quot;/tmp/ipykernel_229732/2637569133.py&quot;, line 5&gt;, 54): loc(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37)), (&lt;code object func_wrapper at 0x7f1d53d71230, file &quot;/tmp/ipykernel_229732/2803309189.py&quot;, line 45&gt;, 98): loc(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23)), (&lt;code object square_add_prim at 0x7f1d500ee950, file &quot;/tmp/ipykernel_229732/2637569133.py&quot;, line 14&gt;, 32): loc(&quot;square_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:17:9 to :35)), (&lt;code object &lt;lambda&gt; at 0x7f1d5018f4b0, file &quot;/tmp/ipykernel_229732/4165789807.py&quot;, line 1&gt;, 30): loc(&quot;&lt;lambda&gt;&quot;(&quot;/tmp/ipykernel_229732/4165789807.py&quot;:1:28 to :49)), (&lt;code object &lt;module&gt; at 0x7f1d501b6890, file &quot;/tmp/ipykernel_229732/4165789807.py&quot;, line 1&gt;, 58): loc(&quot;&lt;module&gt;&quot;(&quot;/tmp/ipykernel_229732/4165789807.py&quot;:1:7 to 2:41)), (&lt;code object _run_code at 0x558966317d00, file &quot;&lt;frozen runpy&gt;&quot;, line 65&gt;, 202): loc(&quot;_run_code&quot;(&quot;&lt;frozen runpy&gt;&quot;:88:4 to :27)), (&lt;code object _run_module_as_main at 0x558966316640, file &quot;&lt;frozen runpy&gt;&quot;, line 173&gt;, 366): loc(&quot;_run_module_as_main&quot;(&quot;&lt;frozen runpy&gt;&quot;:198:11 to 199:42))}, canonical_name_cache={&#39;/tmp/ipykernel_229732/2637569133.py&#39;: &#39;/tmp/ipykernel_229732/2637569133.py&#39;, &#39;/tmp/ipykernel_229732/2803309189.py&#39;: &#39;/tmp/ipykernel_229732/2803309189.py&#39;, &#39;/tmp/ipykernel_229732/4165789807.py&#39;: &#39;/tmp/ipykernel_229732/4165789807.py&#39;, &#39;&lt;frozen runpy&gt;&#39;: &#39;&lt;frozen runpy&gt;&#39;}, is_user_file_cache={&#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/source_info_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/interpreters/partial_eval.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/core.py&#39;: False, &#39;/tmp/ipykernel_229732/2637569133.py&#39;: True, &#39;/tmp/ipykernel_229732/2803309189.py&#39;: True, &#39;/tmp/ipykernel_229732/4165789807.py&#39;: True, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/linear_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/api_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/profiler.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/pjit.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/traceback_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/IPython/core/interactiveshell.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/IPython/core/async_helpers.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/ipykernel/zmqshell.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/ipykernel/ipkernel.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/ipykernel/kernelbase.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/asyncio/events.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/asyncio/base_events.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/tornado/platform/asyncio.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/ipykernel/kernelapp.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/traitlets/config/application.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/ipykernel_launcher.py&#39;: False, &#39;&lt;frozen runpy&gt;&#39;: True}), lowering_parameters=LoweringParameters(override_lowering_rules=None, global_constant_computation=False, for_export=False, export_ignore_forward_compatibility=False)), name_stack=NameStack(stack=(Scope(name=&#39;jit(&lt;lambda&gt;)&#39;), Scope(name=&#39;jit(main)&#39;))), primitive=multiply_add, avals_in=[ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True)], avals_out=[ShapedArray(float32[])], tokens_in=&lt;jax._src.interpreters.mlir.TokenSet object at 0x7f1d3815de50&gt;, tokens_out=None, axis_size_env=None, dim_var_values=[], jaxpr_eqn_ctx=JaxprEqnContext(compute_type=None, threefry_partitionable=True, cur_abstract_mesh=AbstractMesh((), axis_types=()), xla_metadata=None), platforms=None), Value(&lt;block argument&gt; of type &#39;tensor&lt;f32&gt;&#39; at index: 0), Value(&lt;block argument&gt; of type &#39;tensor&lt;f32&gt;&#39; at index: 0), Value(%0 = &quot;stablehlo.constant&quot;() &lt;{value = dense&lt;1.000000e+01&gt; : tensor&lt;f32&gt;}&gt; : () -&gt; tensor&lt;f32&gt;))
|&lt;- multiply_add_lowering = [&lt;jaxlib.mlir._mlir_libs._mlir.ir.OpResult object at 0x7f1d941332f0&gt;]
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="forward-differentiation">
<h3>Forward differentiation<a class="headerlink" href="#forward-differentiation" title="Link to this heading">#</a></h3>
<p>JAX implements forward differentiation in the form of a Jacobian-Vector Product (JVP) (you can learn more about it in <a class="reference internal" href="advanced-autodiff.html#advanced-autodiff"><span class="std std-ref">Advanced automatic differentiation</span></a>).</p>
<p>If you attempt to compute the <code class="docutils literal notranslate"><span class="pre">jvp</span></code> function, you‚Äôll get an error because you have not yet told JAX how to differentiate the <code class="docutils literal notranslate"><span class="pre">multiply_add</span></code> primitive.</p>
<div class="cell tag_raises-exception docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># The second argument is set to `(2., 10.)` values where you</span>
<span class="c1"># evaluate the Jacobian, and the third argument `(1., 1.)`</span>
<span class="c1"># contains the values of the tangents for the arguments.</span>
<span class="k">with</span> <span class="n">expectNotImplementedError</span><span class="p">():</span>
  <span class="n">api</span><span class="o">.</span><span class="n">jvp</span><span class="p">(</span><span class="n">square_add_prim</span><span class="p">,</span> <span class="p">(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">),</span> <span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(Traced&lt;~float32[]&gt;, Traced&lt;~float32[]&gt;)
  call multiply_add_prim(Traced&lt;~float32[]&gt;, Traced&lt;~float32[]&gt;, Traced&lt;~float32[]&gt;)
Found expected exception:
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Traceback (most recent call last):
  File &quot;/tmp/ipykernel_229732/459539105.py&quot;, line 5, in &lt;module&gt;
    api.jvp(square_add_prim, (2., 10.), (1., 1.))
  File &quot;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/traceback_util.py&quot;, line 182, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File &quot;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/api.py&quot;, line 1864, in jvp
    return _jvp(lu.wrap_init(fun, debug_info=debug_info(&quot;jvp&quot;, fun, primals, {})),
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NotImplementedError: Differentiation rule for &#39;multiply_add&#39; not implemented
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">jax.interpreters</span> <span class="kn">import</span> <span class="n">ad</span>

<span class="nd">@trace</span><span class="p">(</span><span class="s2">&quot;multiply_add_value_and_jvp&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">multiply_add_value_and_jvp</span><span class="p">(</span><span class="n">arg_values</span><span class="p">,</span> <span class="n">arg_tangents</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Evaluates the primal output and the tangents (Jacobian-vector product).</span>

<span class="sd">  Given values of the arguments and perturbation of the arguments (tangents), </span>
<span class="sd">  compute the output of the primitive and the perturbation of the output.</span>

<span class="sd">  This method must be JAX-traceable. JAX may invoke it with abstract values </span>
<span class="sd">  for the arguments and tangents.</span>

<span class="sd">  Args:</span>
<span class="sd">    arg_values: A tuple of arguments</span>
<span class="sd">    arg_tangents: A tuple with the tangents of the arguments. The tuple has </span>
<span class="sd">      the same length as the arg_values. Some of the tangents may also be the </span>
<span class="sd">      special value `ad.Zero` to specify a zero tangent</span>

<span class="sd">  Returns:</span>
<span class="sd">     A pair of the primal output and the tangent.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">arg_values</span>
  <span class="n">xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">,</span> <span class="n">zt</span> <span class="o">=</span> <span class="n">arg_tangents</span>
  <span class="n">_trace</span><span class="p">(</span><span class="s2">&quot;Primal evaluation:&quot;</span><span class="p">)</span>
  <span class="c1"># Now, you have a JAX-traceable computation of the output. </span>
  <span class="c1"># Normally, you can use the multiply add (`ma`) primitive itself to compute the primal output. </span>
  <span class="n">primal_out</span> <span class="o">=</span> <span class="n">multiply_add_prim</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>

  <span class="n">_trace</span><span class="p">(</span><span class="s2">&quot;Tangent evaluation:&quot;</span><span class="p">)</span>
  <span class="c1"># You must use a JAX-traceable way to compute the tangent. It turns out that </span>
  <span class="c1"># the output tangent can be computed as (xt * y + x * yt + zt),</span>
  <span class="c1"># which you can implement in a JAX-traceable way using the same &quot;multiply_add_prim&quot; primitive.</span>

  <span class="c1"># You do need to deal specially with `Zero`. Here, you just turn it into a </span>
  <span class="c1"># proper tensor of 0s (of the same shape as &#39;x&#39;). </span>
  <span class="c1"># An alternative would be to check for `Zero` and perform algebraic </span>
  <span class="c1"># simplification of the output tangent computation.</span>
  <span class="k">def</span> <span class="nf">make_zero</span><span class="p">(</span><span class="n">tan</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">lax</span><span class="o">.</span><span class="n">zeros_like_array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">tan</span><span class="p">)</span> <span class="ow">is</span> <span class="n">ad</span><span class="o">.</span><span class="n">Zero</span> <span class="k">else</span> <span class="n">tan</span>  

  <span class="n">output_tangent</span> <span class="o">=</span> <span class="n">multiply_add_prim</span><span class="p">(</span><span class="n">make_zero</span><span class="p">(</span><span class="n">xt</span><span class="p">),</span> <span class="n">y</span><span class="p">,</span> <span class="n">multiply_add_prim</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">make_zero</span><span class="p">(</span><span class="n">yt</span><span class="p">),</span> <span class="n">make_zero</span><span class="p">(</span><span class="n">zt</span><span class="p">)))</span>
  <span class="k">return</span> <span class="p">(</span><span class="n">primal_out</span><span class="p">,</span> <span class="n">output_tangent</span><span class="p">)</span>

<span class="c1"># Register the forward differentiation rule with JAX:</span>
<span class="n">ad</span><span class="o">.</span><span class="n">primitive_jvps</span><span class="p">[</span><span class="n">multiply_add_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">multiply_add_value_and_jvp</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Tangent is: xt*y + x*yt + zt = 1.*2. + 2.*1. + 1. = 5.</span>
<span class="k">assert</span> <span class="n">api</span><span class="o">.</span><span class="n">jvp</span><span class="p">(</span><span class="n">square_add_prim</span><span class="p">,</span> <span class="p">(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">),</span> <span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">))</span> <span class="o">==</span> <span class="p">(</span><span class="mf">14.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(Traced&lt;~float32[]&gt;, Traced&lt;~float32[]&gt;)
  call multiply_add_prim(Traced&lt;~float32[]&gt;, Traced&lt;~float32[]&gt;, Traced&lt;~float32[]&gt;)
    call multiply_add_value_and_jvp((2.0, 2.0, 10.0), (1.0, 1.0, 1.0))
      Primal evaluation:
      call multiply_add_prim(2.0, 2.0, 10.0)
        call multiply_add_impl(2.0, 2.0, 10.0)
        |&lt;- multiply_add_impl = 14.0
      |&lt;- multiply_add_prim = 14.0
      Tangent evaluation:
      call multiply_add_prim(2.0, 1.0, 1.0)
        call multiply_add_impl(2.0, 1.0, 1.0)
        |&lt;- multiply_add_impl = 3.0
      |&lt;- multiply_add_prim = 3.0
      call multiply_add_prim(1.0, 2.0, 3.0)
        call multiply_add_impl(1.0, 2.0, 3.0)
        |&lt;- multiply_add_impl = 5.0
      |&lt;- multiply_add_prim = 5.0
    |&lt;- multiply_add_value_and_jvp = (14.0, 5.0)
  |&lt;- multiply_add_prim = Traced&lt;float32[]&gt;
|&lt;- square_add_prim = Traced&lt;float32[]&gt;
</pre></div>
</div>
</div>
</div>
<section id="jit-of-forward-differentiation">
<h4>JIT of forward differentiation<a class="headerlink" href="#jit-of-forward-differentiation" title="Link to this heading">#</a></h4>
<p>You can apply <code class="docutils literal notranslate"><span class="pre">jit</span></code> to the forward differentiation function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="n">api</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="k">lambda</span> <span class="n">arg_values</span><span class="p">,</span> <span class="n">arg_tangents</span><span class="p">:</span> 
                   <span class="n">api</span><span class="o">.</span><span class="n">jvp</span><span class="p">(</span><span class="n">square_add_prim</span><span class="p">,</span> <span class="n">arg_values</span><span class="p">,</span> <span class="n">arg_tangents</span><span class="p">))(</span>
         <span class="p">(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">),</span> <span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">))</span> <span class="o">==</span> <span class="p">(</span><span class="mf">14.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(Traced&lt;~float32[]&gt;, Traced&lt;~float32[]&gt;)
  call multiply_add_prim(Traced&lt;~float32[]&gt;, Traced&lt;~float32[]&gt;, Traced&lt;~float32[]&gt;)
    call multiply_add_value_and_jvp((Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;), (Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;))
      Primal evaluation:
      call multiply_add_prim(Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;)
        call multiply_add_abstract_eval(~float32[], ~float32[], ~float32[])
        |&lt;- multiply_add_abstract_eval = float32[]
      |&lt;- multiply_add_prim = Traced&lt;float32[]&gt;with&lt;DynamicJaxprTrace&gt;
      Tangent evaluation:
      call multiply_add_prim(Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;)
        call multiply_add_abstract_eval(~float32[], ~float32[], ~float32[])
        |&lt;- multiply_add_abstract_eval = float32[]
      |&lt;- multiply_add_prim = Traced&lt;float32[]&gt;with&lt;DynamicJaxprTrace&gt;
      call multiply_add_prim(Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;float32[]&gt;with&lt;DynamicJaxprTrace&gt;)
        call multiply_add_abstract_eval(~float32[], ~float32[], float32[])
        |&lt;- multiply_add_abstract_eval = float32[]
      |&lt;- multiply_add_prim = Traced&lt;float32[]&gt;with&lt;DynamicJaxprTrace&gt;
    |&lt;- multiply_add_value_and_jvp = (Traced&lt;float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;float32[]&gt;with&lt;DynamicJaxprTrace&gt;)
  |&lt;- multiply_add_prim = Traced&lt;float32[]&gt;
|&lt;- square_add_prim = Traced&lt;float32[]&gt;
call multiply_add_lowering(LoweringRuleContext(module_context=ModuleContext(context=&lt;jax._src.interpreters.mlir.JaxIrContext object at 0x7f1d381971d0&gt;, module=&lt;jaxlib.mlir._mlir_libs._mlir.ir.Module object at 0x7f1d3819f920&gt;, ip=&lt;jaxlib.mlir._mlir_libs._mlir.ir.InsertionPoint object at 0x7f1d381b48f0&gt;, symbol_table=&lt;jaxlib.mlir._mlir_libs._mlir.ir.SymbolTable object at 0x7f1d3816d440&gt;, platforms=(&#39;cpu&#39;,), backend=&lt;jaxlib._jax.Client object at 0x7f1d53bef5e0&gt;, axis_context=ShardingContext(num_devices=1, device_assignment=None, abstract_mesh=None), keepalives=[], channel_iterator=count(1), host_callbacks=[], shape_poly_state=&lt;jax._src.interpreters.mlir.ShapePolyLoweringState object at 0x7f1d381ae510&gt;, all_default_mem_kind=True, cached_primitive_lowerings={}, traceback_caches=TracebackCaches(traceback_cache={&lt;jaxlib._jax.Traceback object at 0x55898b50b970&gt;: loc(callsite(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;multiply_add_value_and_jvp&quot;(&quot;/tmp/ipykernel_229732/347789876.py&quot;:27:15 to :41) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;square_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:17:9 to :35) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;&lt;lambda&gt;&quot;(&quot;/tmp/ipykernel_229732/2145028508.py&quot;:2:19 to :69) at &quot;&lt;module&gt;&quot;(&quot;/tmp/ipykernel_229732/2145028508.py&quot;:1:7 to 3:29)))))))))))}, location_cache={(&lt;code object multiply_add_prim at 0x7f1d53ce3730, file &quot;/tmp/ipykernel_229732/2637569133.py&quot;, line 5&gt;, 54): loc(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37)), (&lt;code object func_wrapper at 0x7f1d53d71230, file &quot;/tmp/ipykernel_229732/2803309189.py&quot;, line 45&gt;, 98): loc(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23)), (&lt;code object multiply_add_value_and_jvp at 0x7f1d53c5c1f0, file &quot;/tmp/ipykernel_229732/347789876.py&quot;, line 3&gt;, 88): loc(&quot;multiply_add_value_and_jvp&quot;(&quot;/tmp/ipykernel_229732/347789876.py&quot;:27:15 to :41)), (&lt;code object square_add_prim at 0x7f1d500ee950, file &quot;/tmp/ipykernel_229732/2637569133.py&quot;, line 14&gt;, 32): loc(&quot;square_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:17:9 to :35)), (&lt;code object &lt;lambda&gt; at 0x7f1d501a0430, file &quot;/tmp/ipykernel_229732/2145028508.py&quot;, line 1&gt;, 64): loc(&quot;&lt;lambda&gt;&quot;(&quot;/tmp/ipykernel_229732/2145028508.py&quot;:2:19 to :69)), (&lt;code object &lt;module&gt; at 0x7f1d381b0030, file &quot;/tmp/ipykernel_229732/2145028508.py&quot;, line 1&gt;, 54): loc(&quot;&lt;module&gt;&quot;(&quot;/tmp/ipykernel_229732/2145028508.py&quot;:1:7 to 3:29))}, canonical_name_cache={&#39;/tmp/ipykernel_229732/2637569133.py&#39;: &#39;/tmp/ipykernel_229732/2637569133.py&#39;, &#39;/tmp/ipykernel_229732/2803309189.py&#39;: &#39;/tmp/ipykernel_229732/2803309189.py&#39;, &#39;/tmp/ipykernel_229732/347789876.py&#39;: &#39;/tmp/ipykernel_229732/347789876.py&#39;, &#39;/tmp/ipykernel_229732/2145028508.py&#39;: &#39;/tmp/ipykernel_229732/2145028508.py&#39;}, is_user_file_cache={&#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/source_info_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/interpreters/partial_eval.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/core.py&#39;: False, &#39;/tmp/ipykernel_229732/2637569133.py&#39;: True, &#39;/tmp/ipykernel_229732/2803309189.py&#39;: True, &#39;/tmp/ipykernel_229732/347789876.py&#39;: True, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/interpreters/ad.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/linear_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/pjit.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/api_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/api.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/traceback_util.py&#39;: False, &#39;/tmp/ipykernel_229732/2145028508.py&#39;: True, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/profiler.py&#39;: False}), lowering_parameters=LoweringParameters(override_lowering_rules=None, global_constant_computation=False, for_export=False, export_ignore_forward_compatibility=False)), name_stack=NameStack(stack=(Scope(name=&#39;jit(&lt;lambda&gt;)&#39;), Scope(name=&#39;jit(main)&#39;), Transform(name=&#39;jvp&#39;))), primitive=multiply_add, avals_in=[ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True)], avals_out=[ShapedArray(float32[])], tokens_in=&lt;jax._src.interpreters.mlir.TokenSet object at 0x7f1d381af6d0&gt;, tokens_out=None, axis_size_env=None, dim_var_values=[], jaxpr_eqn_ctx=JaxprEqnContext(compute_type=None, threefry_partitionable=True, cur_abstract_mesh=AbstractMesh((), axis_types=()), xla_metadata=None), platforms=None), Value(&lt;block argument&gt; of type &#39;tensor&lt;f32&gt;&#39; at index: 0), Value(&lt;block argument&gt; of type &#39;tensor&lt;f32&gt;&#39; at index: 0), Value(&lt;block argument&gt; of type &#39;tensor&lt;f32&gt;&#39; at index: 1))
|&lt;- multiply_add_lowering = [&lt;jaxlib.mlir._mlir_libs._mlir.ir.OpResult object at 0x7f1d381af930&gt;]
call multiply_add_lowering(LoweringRuleContext(module_context=ModuleContext(context=&lt;jax._src.interpreters.mlir.JaxIrContext object at 0x7f1d381971d0&gt;, module=&lt;jaxlib.mlir._mlir_libs._mlir.ir.Module object at 0x7f1d3819f920&gt;, ip=&lt;jaxlib.mlir._mlir_libs._mlir.ir.InsertionPoint object at 0x7f1d381b48f0&gt;, symbol_table=&lt;jaxlib.mlir._mlir_libs._mlir.ir.SymbolTable object at 0x7f1d3816d440&gt;, platforms=(&#39;cpu&#39;,), backend=&lt;jaxlib._jax.Client object at 0x7f1d53bef5e0&gt;, axis_context=ShardingContext(num_devices=1, device_assignment=None, abstract_mesh=None), keepalives=[], channel_iterator=count(1), host_callbacks=[], shape_poly_state=&lt;jax._src.interpreters.mlir.ShapePolyLoweringState object at 0x7f1d381ae510&gt;, all_default_mem_kind=True, cached_primitive_lowerings={}, traceback_caches=TracebackCaches(traceback_cache={&lt;jaxlib._jax.Traceback object at 0x55898b50b970&gt;: loc(callsite(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;multiply_add_value_and_jvp&quot;(&quot;/tmp/ipykernel_229732/347789876.py&quot;:27:15 to :41) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;square_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:17:9 to :35) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;&lt;lambda&gt;&quot;(&quot;/tmp/ipykernel_229732/2145028508.py&quot;:2:19 to :69) at &quot;&lt;module&gt;&quot;(&quot;/tmp/ipykernel_229732/2145028508.py&quot;:1:7 to 3:29))))))))))), &lt;jaxlib._jax.Traceback object at 0x55898b2bda00&gt;: loc(callsite(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;multiply_add_value_and_jvp&quot;(&quot;/tmp/ipykernel_229732/347789876.py&quot;:41:55 to :105) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;square_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:17:9 to :35) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;&lt;lambda&gt;&quot;(&quot;/tmp/ipykernel_229732/2145028508.py&quot;:2:19 to :69) at &quot;&lt;module&gt;&quot;(&quot;/tmp/ipykernel_229732/2145028508.py&quot;:1:7 to 3:29)))))))))))}, location_cache={(&lt;code object multiply_add_prim at 0x7f1d53ce3730, file &quot;/tmp/ipykernel_229732/2637569133.py&quot;, line 5&gt;, 54): loc(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37)), (&lt;code object func_wrapper at 0x7f1d53d71230, file &quot;/tmp/ipykernel_229732/2803309189.py&quot;, line 45&gt;, 98): loc(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23)), (&lt;code object multiply_add_value_and_jvp at 0x7f1d53c5c1f0, file &quot;/tmp/ipykernel_229732/347789876.py&quot;, line 3&gt;, 88): loc(&quot;multiply_add_value_and_jvp&quot;(&quot;/tmp/ipykernel_229732/347789876.py&quot;:27:15 to :41)), (&lt;code object square_add_prim at 0x7f1d500ee950, file &quot;/tmp/ipykernel_229732/2637569133.py&quot;, line 14&gt;, 32): loc(&quot;square_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:17:9 to :35)), (&lt;code object &lt;lambda&gt; at 0x7f1d501a0430, file &quot;/tmp/ipykernel_229732/2145028508.py&quot;, line 1&gt;, 64): loc(&quot;&lt;lambda&gt;&quot;(&quot;/tmp/ipykernel_229732/2145028508.py&quot;:2:19 to :69)), (&lt;code object &lt;module&gt; at 0x7f1d381b0030, file &quot;/tmp/ipykernel_229732/2145028508.py&quot;, line 1&gt;, 54): loc(&quot;&lt;module&gt;&quot;(&quot;/tmp/ipykernel_229732/2145028508.py&quot;:1:7 to 3:29)), (&lt;code object multiply_add_value_and_jvp at 0x7f1d53c5c1f0, file &quot;/tmp/ipykernel_229732/347789876.py&quot;, line 3&gt;, 232): loc(&quot;multiply_add_value_and_jvp&quot;(&quot;/tmp/ipykernel_229732/347789876.py&quot;:41:55 to :105))}, canonical_name_cache={&#39;/tmp/ipykernel_229732/2637569133.py&#39;: &#39;/tmp/ipykernel_229732/2637569133.py&#39;, &#39;/tmp/ipykernel_229732/2803309189.py&#39;: &#39;/tmp/ipykernel_229732/2803309189.py&#39;, &#39;/tmp/ipykernel_229732/347789876.py&#39;: &#39;/tmp/ipykernel_229732/347789876.py&#39;, &#39;/tmp/ipykernel_229732/2145028508.py&#39;: &#39;/tmp/ipykernel_229732/2145028508.py&#39;}, is_user_file_cache={&#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/source_info_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/interpreters/partial_eval.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/core.py&#39;: False, &#39;/tmp/ipykernel_229732/2637569133.py&#39;: True, &#39;/tmp/ipykernel_229732/2803309189.py&#39;: True, &#39;/tmp/ipykernel_229732/347789876.py&#39;: True, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/interpreters/ad.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/linear_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/pjit.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/api_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/api.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/traceback_util.py&#39;: False, &#39;/tmp/ipykernel_229732/2145028508.py&#39;: True, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/profiler.py&#39;: False}), lowering_parameters=LoweringParameters(override_lowering_rules=None, global_constant_computation=False, for_export=False, export_ignore_forward_compatibility=False)), name_stack=NameStack(stack=(Scope(name=&#39;jit(&lt;lambda&gt;)&#39;), Scope(name=&#39;jit(main)&#39;), Transform(name=&#39;jvp&#39;))), primitive=multiply_add, avals_in=[ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True)], avals_out=[ShapedArray(float32[])], tokens_in=&lt;jax._src.interpreters.mlir.TokenSet object at 0x7f1d381af850&gt;, tokens_out=None, axis_size_env=None, dim_var_values=[], jaxpr_eqn_ctx=JaxprEqnContext(compute_type=None, threefry_partitionable=True, cur_abstract_mesh=AbstractMesh((), axis_types=()), xla_metadata=None), platforms=None), Value(&lt;block argument&gt; of type &#39;tensor&lt;f32&gt;&#39; at index: 0), Value(&lt;block argument&gt; of type &#39;tensor&lt;f32&gt;&#39; at index: 2), Value(&lt;block argument&gt; of type &#39;tensor&lt;f32&gt;&#39; at index: 3))
|&lt;- multiply_add_lowering = [&lt;jaxlib.mlir._mlir_libs._mlir.ir.OpResult object at 0x7f1d381af4f0&gt;]
call multiply_add_lowering(LoweringRuleContext(module_context=ModuleContext(context=&lt;jax._src.interpreters.mlir.JaxIrContext object at 0x7f1d381971d0&gt;, module=&lt;jaxlib.mlir._mlir_libs._mlir.ir.Module object at 0x7f1d3819f920&gt;, ip=&lt;jaxlib.mlir._mlir_libs._mlir.ir.InsertionPoint object at 0x7f1d381b48f0&gt;, symbol_table=&lt;jaxlib.mlir._mlir_libs._mlir.ir.SymbolTable object at 0x7f1d3816d440&gt;, platforms=(&#39;cpu&#39;,), backend=&lt;jaxlib._jax.Client object at 0x7f1d53bef5e0&gt;, axis_context=ShardingContext(num_devices=1, device_assignment=None, abstract_mesh=None), keepalives=[], channel_iterator=count(1), host_callbacks=[], shape_poly_state=&lt;jax._src.interpreters.mlir.ShapePolyLoweringState object at 0x7f1d381ae510&gt;, all_default_mem_kind=True, cached_primitive_lowerings={}, traceback_caches=TracebackCaches(traceback_cache={&lt;jaxlib._jax.Traceback object at 0x55898b50b970&gt;: loc(callsite(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;multiply_add_value_and_jvp&quot;(&quot;/tmp/ipykernel_229732/347789876.py&quot;:27:15 to :41) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;square_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:17:9 to :35) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;&lt;lambda&gt;&quot;(&quot;/tmp/ipykernel_229732/2145028508.py&quot;:2:19 to :69) at &quot;&lt;module&gt;&quot;(&quot;/tmp/ipykernel_229732/2145028508.py&quot;:1:7 to 3:29))))))))))), &lt;jaxlib._jax.Traceback object at 0x55898b2bda00&gt;: loc(callsite(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;multiply_add_value_and_jvp&quot;(&quot;/tmp/ipykernel_229732/347789876.py&quot;:41:55 to :105) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;square_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:17:9 to :35) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;&lt;lambda&gt;&quot;(&quot;/tmp/ipykernel_229732/2145028508.py&quot;:2:19 to :69) at &quot;&lt;module&gt;&quot;(&quot;/tmp/ipykernel_229732/2145028508.py&quot;:1:7 to 3:29))))))))))), &lt;jaxlib._jax.Traceback object at 0x55898b51eb50&gt;: loc(callsite(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;multiply_add_value_and_jvp&quot;(&quot;/tmp/ipykernel_229732/347789876.py&quot;:41:19 to :106) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;square_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:17:9 to :35) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;&lt;lambda&gt;&quot;(&quot;/tmp/ipykernel_229732/2145028508.py&quot;:2:19 to :69) at &quot;&lt;module&gt;&quot;(&quot;/tmp/ipykernel_229732/2145028508.py&quot;:1:7 to 3:29)))))))))))}, location_cache={(&lt;code object multiply_add_prim at 0x7f1d53ce3730, file &quot;/tmp/ipykernel_229732/2637569133.py&quot;, line 5&gt;, 54): loc(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37)), (&lt;code object func_wrapper at 0x7f1d53d71230, file &quot;/tmp/ipykernel_229732/2803309189.py&quot;, line 45&gt;, 98): loc(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23)), (&lt;code object multiply_add_value_and_jvp at 0x7f1d53c5c1f0, file &quot;/tmp/ipykernel_229732/347789876.py&quot;, line 3&gt;, 88): loc(&quot;multiply_add_value_and_jvp&quot;(&quot;/tmp/ipykernel_229732/347789876.py&quot;:27:15 to :41)), (&lt;code object square_add_prim at 0x7f1d500ee950, file &quot;/tmp/ipykernel_229732/2637569133.py&quot;, line 14&gt;, 32): loc(&quot;square_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:17:9 to :35)), (&lt;code object &lt;lambda&gt; at 0x7f1d501a0430, file &quot;/tmp/ipykernel_229732/2145028508.py&quot;, line 1&gt;, 64): loc(&quot;&lt;lambda&gt;&quot;(&quot;/tmp/ipykernel_229732/2145028508.py&quot;:2:19 to :69)), (&lt;code object &lt;module&gt; at 0x7f1d381b0030, file &quot;/tmp/ipykernel_229732/2145028508.py&quot;, line 1&gt;, 54): loc(&quot;&lt;module&gt;&quot;(&quot;/tmp/ipykernel_229732/2145028508.py&quot;:1:7 to 3:29)), (&lt;code object multiply_add_value_and_jvp at 0x7f1d53c5c1f0, file &quot;/tmp/ipykernel_229732/347789876.py&quot;, line 3&gt;, 232): loc(&quot;multiply_add_value_and_jvp&quot;(&quot;/tmp/ipykernel_229732/347789876.py&quot;:41:55 to :105)), (&lt;code object multiply_add_value_and_jvp at 0x7f1d53c5c1f0, file &quot;/tmp/ipykernel_229732/347789876.py&quot;, line 3&gt;, 246): loc(&quot;multiply_add_value_and_jvp&quot;(&quot;/tmp/ipykernel_229732/347789876.py&quot;:41:19 to :106))}, canonical_name_cache={&#39;/tmp/ipykernel_229732/2637569133.py&#39;: &#39;/tmp/ipykernel_229732/2637569133.py&#39;, &#39;/tmp/ipykernel_229732/2803309189.py&#39;: &#39;/tmp/ipykernel_229732/2803309189.py&#39;, &#39;/tmp/ipykernel_229732/347789876.py&#39;: &#39;/tmp/ipykernel_229732/347789876.py&#39;, &#39;/tmp/ipykernel_229732/2145028508.py&#39;: &#39;/tmp/ipykernel_229732/2145028508.py&#39;}, is_user_file_cache={&#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/source_info_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/interpreters/partial_eval.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/core.py&#39;: False, &#39;/tmp/ipykernel_229732/2637569133.py&#39;: True, &#39;/tmp/ipykernel_229732/2803309189.py&#39;: True, &#39;/tmp/ipykernel_229732/347789876.py&#39;: True, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/interpreters/ad.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/linear_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/pjit.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/api_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/api.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/traceback_util.py&#39;: False, &#39;/tmp/ipykernel_229732/2145028508.py&#39;: True, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/profiler.py&#39;: False}), lowering_parameters=LoweringParameters(override_lowering_rules=None, global_constant_computation=False, for_export=False, export_ignore_forward_compatibility=False)), name_stack=NameStack(stack=(Scope(name=&#39;jit(&lt;lambda&gt;)&#39;), Scope(name=&#39;jit(main)&#39;), Transform(name=&#39;jvp&#39;))), primitive=multiply_add, avals_in=[ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[])], avals_out=[ShapedArray(float32[])], tokens_in=&lt;jax._src.interpreters.mlir.TokenSet object at 0x7f1d381af5d0&gt;, tokens_out=None, axis_size_env=None, dim_var_values=[], jaxpr_eqn_ctx=JaxprEqnContext(compute_type=None, threefry_partitionable=True, cur_abstract_mesh=AbstractMesh((), axis_types=()), xla_metadata=None), platforms=None), Value(&lt;block argument&gt; of type &#39;tensor&lt;f32&gt;&#39; at index: 2), Value(&lt;block argument&gt; of type &#39;tensor&lt;f32&gt;&#39; at index: 0), Value(%3 = &quot;stablehlo.add&quot;(%2, %arg3) : (tensor&lt;f32&gt;, tensor&lt;f32&gt;) -&gt; tensor&lt;f32&gt;))
|&lt;- multiply_add_lowering = [&lt;jaxlib.mlir._mlir_libs._mlir.ir.OpResult object at 0x7f1d381afb30&gt;]
</pre></div>
</div>
</div>
</div>
<p>Notice that first, you evaluate <code class="docutils literal notranslate"><span class="pre">multiply_add_value_and_jvp</span></code> abstractly, which in turn evaluates abstractly both the primal and the tangent evaluation (a total of 3 invocations of the <code class="docutils literal notranslate"><span class="pre">ma</span></code> primitive). Then, you compile the 3 occurrences of the primitive.</p>
</section>
</section>
<section id="reverse-differentiation">
<h3>Reverse differentiation<a class="headerlink" href="#reverse-differentiation" title="Link to this heading">#</a></h3>
<p>If you attempt now to use reverse differentiation, you‚Äôll notice that JAX starts by using the <code class="docutils literal notranslate"><span class="pre">multiply_add_value_and_jvp</span></code> to compute the forward differentiation for abstract values, but then runs into a <code class="docutils literal notranslate"><span class="pre">NotImplementedError</span></code>.</p>
<p>When computing the reverse differentiation, JAX first performs an abstract evaluation of the forward differentiation code <code class="docutils literal notranslate"><span class="pre">multiply_add_value_and_jvp</span></code> to obtain a  trace of primitives that compute the output tangent.</p>
<ul class="simple">
<li><p>Observe that JAX performs this abstract evaluation with concrete values for the differentiation point, and abstract values for the tangents.</p></li>
<li><p>Notice that JAX uses the special abstract tangent value <code class="docutils literal notranslate"><span class="pre">Zero</span></code> for the tangent corresponding to the third argument of <code class="docutils literal notranslate"><span class="pre">ma</span></code>. This reflects the fact that you do not differentiate w.r.t. the second argument to <code class="docutils literal notranslate"><span class="pre">square_add_prim</span></code>, which flows to the third argument to <code class="docutils literal notranslate"><span class="pre">multiply_add_prim</span></code>.</p></li>
<li><p>Notice also that during the abstract evaluation of the tangent you pass the value <code class="docutils literal notranslate"><span class="pre">0.0</span></code> as the tangent for the third argument. This is because of the use of the <code class="docutils literal notranslate"><span class="pre">make_zero</span></code> function in the definition of <code class="docutils literal notranslate"><span class="pre">multiply_add_value_and_jvp</span></code>.</p></li>
</ul>
<div class="cell tag_raises-exception docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># This is reverse differentiation w.r.t. the first argument of `square_add_prim`</span>
<span class="k">with</span> <span class="n">expectNotImplementedError</span><span class="p">():</span>
  <span class="n">api</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">square_add_prim</span><span class="p">)(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(Traced&lt;~float32[]&gt;, 10.0)
  call multiply_add_prim(Traced&lt;~float32[]&gt;, Traced&lt;~float32[]&gt;, 10.0)
    call multiply_add_value_and_jvp((2.0, 2.0, 10.0), (Traced&lt;~float32[]&gt;, Traced&lt;~float32[]&gt;, Zero(~float32[])))
      Primal evaluation:
      call multiply_add_prim(2.0, 2.0, 10.0)
        call multiply_add_impl(2.0, 2.0, 10.0)
        |&lt;- multiply_add_impl = 14.0
      |&lt;- multiply_add_prim = 14.0
      Tangent evaluation:
      call multiply_add_prim(2.0, Traced&lt;~float32[]&gt;, 0.0)
        call multiply_add_abstract_eval(~float32[], ~float32[], ~float32[])
        |&lt;- multiply_add_abstract_eval = float32[]
      |&lt;- multiply_add_prim = Traced&lt;float32[]&gt;
      call multiply_add_prim(Traced&lt;~float32[]&gt;, 2.0, Traced&lt;float32[]&gt;)
        call multiply_add_abstract_eval(~float32[], ~float32[], float32[])
        |&lt;- multiply_add_abstract_eval = float32[]
      |&lt;- multiply_add_prim = Traced&lt;float32[]&gt;
    |&lt;- multiply_add_value_and_jvp = (14.0, Traced&lt;float32[]&gt;)
  |&lt;- multiply_add_prim = Traced&lt;float32[]&gt;
|&lt;- square_add_prim = Traced&lt;float32[]&gt;
Found expected exception:
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Traceback (most recent call last):
  File &quot;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/interpreters/ad.py&quot;, line 464, in get_primitive_transpose
    return primitive_transposes[p]
           ~~~~~~~~~~~~~~~~~~~~^^^
KeyError: multiply_add

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File &quot;&lt;frozen runpy&gt;&quot;, line 198, in _run_module_as_main
  File &quot;&lt;frozen runpy&gt;&quot;, line 88, in _run_code
  File &quot;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/ipykernel_launcher.py&quot;, line 18, in &lt;module&gt;
    app.launch_new_instance()
jax._src.source_info_util.JaxStackTraceBeforeTransformation: NotImplementedError: Transpose rule (for reverse-mode differentiation) for &#39;multiply_add&#39; not implemented

The preceding stack trace is the source of the JAX operation that, once transformed by JAX, triggered the following exception.

--------------------

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File &quot;/tmp/ipykernel_229732/2155094905.py&quot;, line 3, in &lt;module&gt;
    api.grad(square_add_prim)(2., 10.)
  File &quot;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/traceback_util.py&quot;, line 182, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File &quot;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/api.py&quot;, line 437, in grad_f
    _, g = value_and_grad_f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
NotImplementedError: Transpose rule (for reverse-mode differentiation) for &#39;multiply_add&#39; not implemented
</pre></div>
</div>
</div>
</div>
<p>The above error is because there is a missing piece for JAX to be able to use the forward differentiation code to compute reverse differentiation.</p>
<section id="transposition">
<h4>Transposition<a class="headerlink" href="#transposition" title="Link to this heading">#</a></h4>
<p>As previously explained, when computing reverse differentiation, JAX obtains a trace of primitives that compute the tangent using forward differentiation. Then, <strong>JAX interprets this trace abstractly backwards</strong> and for each primitive it applies a <strong>transposition rule</strong>.</p>
<p>To understand what is going on, consider a simpler example of the function <code class="docutils literal notranslate"><span class="pre">f(x,</span> <span class="pre">y)</span> <span class="pre">=</span> <span class="pre">x</span> <span class="pre">*</span> <span class="pre">y</span> <span class="pre">+</span> <span class="pre">y</span></code>. Assume, you need to differentiate at the point <code class="docutils literal notranslate"><span class="pre">(2.,</span> <span class="pre">4.)</span></code>. JAX will produce the following JVP tangent calculation of <code class="docutils literal notranslate"><span class="pre">ft</span></code> from the tangents of the input <code class="docutils literal notranslate"><span class="pre">xt</span></code> and <code class="docutils literal notranslate"><span class="pre">yt</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>   <span class="n">a</span> <span class="o">=</span> <span class="n">xt</span> <span class="o">*</span> <span class="mf">4.</span>
   <span class="n">b</span> <span class="o">=</span> <span class="mf">2.</span> <span class="o">*</span> <span class="n">yt</span>
   <span class="n">c</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>
   <span class="n">ft</span> <span class="o">=</span> <span class="n">c</span> <span class="o">+</span> <span class="n">yt</span>
</pre></div>
</div>
<p>By construction, the tangent calculation is always linear in the input tangents. The only non-linear operator that may arise in the tangent calculation is multiplication, but then one of the operands is constant.</p>
<p>JAX will produce the reverse differentiation computation by processing the JVP computation backwards. For each operation in the tangent computation, it accumulates the cotangents of the variables used by the operation, using the cotangent of the result of the operation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>  <span class="c1"># Initialize cotangents of inputs and intermediate variables:</span>
  <span class="n">xct</span> <span class="o">=</span> <span class="n">yct</span> <span class="o">=</span> <span class="n">act</span> <span class="o">=</span> <span class="n">bct</span> <span class="o">=</span> <span class="n">cct</span> <span class="o">=</span> <span class="mf">0.</span>
  <span class="c1"># Initialize cotangent of the output:</span>
  <span class="n">fct</span> <span class="o">=</span> <span class="mf">1.</span>
  <span class="c1"># Process `ft = c + yt`:</span>
  <span class="n">cct</span> <span class="o">+=</span> <span class="n">fct</span>
  <span class="n">yct</span> <span class="o">+=</span> <span class="n">fct</span>
  <span class="c1"># Process `c = a + b`:</span>
  <span class="n">act</span> <span class="o">+=</span> <span class="n">cct</span>
  <span class="n">bct</span> <span class="o">+=</span> <span class="n">cct</span>
  <span class="c1"># Process `b = 2. * yt`:</span>
  <span class="n">yct</span> <span class="o">+=</span> <span class="mf">2.</span> <span class="o">*</span> <span class="n">bct</span>
  <span class="c1"># Process `a = xt * 4.`:</span>
  <span class="n">xct</span> <span class="o">+=</span> <span class="n">act</span> <span class="o">*</span> <span class="mf">4.</span>
</pre></div>
</div>
<p>One can verify that this computation produces <code class="docutils literal notranslate"><span class="pre">xct</span> <span class="pre">=</span> <span class="pre">4.</span></code> and <code class="docutils literal notranslate"><span class="pre">yct</span> <span class="pre">=</span> <span class="pre">3.</span></code>, which
are the partial derivatives of the function <code class="docutils literal notranslate"><span class="pre">f</span></code>.</p>
<p>JAX knows for each primitive that may appear in a JVP calculation how to transpose it. Conceptually, if the primitive <code class="docutils literal notranslate"><span class="pre">p(x,</span> <span class="pre">y,</span> <span class="pre">z)</span></code> is linear in the arguments <code class="docutils literal notranslate"><span class="pre">y</span></code> and <code class="docutils literal notranslate"><span class="pre">z</span></code> for a constant value of <code class="docutils literal notranslate"><span class="pre">x</span></code>, e.g., <code class="docutils literal notranslate"><span class="pre">p(x,</span> <span class="pre">y,</span> <span class="pre">z)</span> <span class="pre">=</span> <span class="pre">y*cy</span> <span class="pre">+</span> <span class="pre">z*cz</span></code>, then the transposition of the primitive is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">p_transpose</span><span class="p">(</span><span class="n">out_ct</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">out_ct</span><span class="o">*</span><span class="n">cy</span><span class="p">,</span> <span class="n">out_ct</span><span class="o">*</span><span class="n">cz</span><span class="p">)</span>
</pre></div>
</div>
<p>Notice that <code class="docutils literal notranslate"><span class="pre">p_transpose</span></code> takes the cotangent of the output of the primitive and a value corresponding to each argument of the primitive. For the linear arguments, the transposition gets an undefined <code class="docutils literal notranslate"><span class="pre">_</span></code> value, and for the other arguments it gets the actual constants. The transposition returns a cotangent value for each argument of the primitive, with the value <code class="docutils literal notranslate"><span class="pre">None</span></code> returned  for the constant arguments.</p>
<p>In particular:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span> <span class="n">add_transpose</span><span class="p">(</span><span class="n">out_ct</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="n">out_ct</span><span class="p">,</span> <span class="n">out_ct</span><span class="p">)</span>
 <span class="n">mult_transpose</span><span class="p">(</span><span class="n">out_ct</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">x</span> <span class="o">*</span> <span class="n">out_ct</span><span class="p">)</span>
 <span class="n">mult_transpose</span><span class="p">(</span><span class="n">out_ct</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="n">out_ct</span> <span class="o">*</span> <span class="n">y</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@trace</span><span class="p">(</span><span class="s2">&quot;multiply_add_transpose&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">multiply_add_transpose</span><span class="p">(</span><span class="n">ct</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Evaluates the transpose of a linear primitive.</span>

<span class="sd">  This method is only used when computing the backward gradient following </span>
<span class="sd">  `value_and_jvp`, and is only needed for primitives that are used in the JVP </span>
<span class="sd">  calculation for some other primitive. You need a transposition for `multiply_add_prim`, </span>
<span class="sd">  because you have used `multiply_add_prim` in the computation of the `output_tangent` in </span>
<span class="sd">  `multiply_add_value_and_jvp`.</span>

<span class="sd">  In this case, multiply_add is not a linear primitive. However, it is used linearly </span>
<span class="sd">  w.r.t. tangents in `multiply_add_value_and_jvp`:</span>
<span class="sd">       `output_tangent(xt, yt, zt) = multiply_add_prim(xt, y, multiply_add_prim(x, yt, zt))`.</span>

<span class="sd">  Always one of the first two multiplicative arguments is a constant.</span>

<span class="sd">  Args:</span>
<span class="sd">      ct: The cotangent of the output of the primitive.</span>
<span class="sd">      x, y, z: The values of the arguments. The arguments that are used linearly</span>
<span class="sd">        get an ad.UndefinedPrimal value. The other arguments get a constant</span>
<span class="sd">        value.</span>

<span class="sd">  Returns:</span>
<span class="sd">      A tuple with the cotangent of the inputs, with the value None</span>
<span class="sd">      corresponding to the constant arguments.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="n">ad</span><span class="o">.</span><span class="n">is_undefined_primal</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="c1"># This use of multiply_add is with a constant &quot;x&quot;.</span>
    <span class="k">assert</span> <span class="n">ad</span><span class="o">.</span><span class="n">is_undefined_primal</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">ct_y</span> <span class="o">=</span> <span class="n">ad</span><span class="o">.</span><span class="n">Zero</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">aval</span><span class="p">)</span> <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">ct</span><span class="p">)</span> <span class="ow">is</span> <span class="n">ad</span><span class="o">.</span><span class="n">Zero</span> <span class="k">else</span> <span class="n">multiply_add_prim</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ct</span><span class="p">,</span> <span class="n">lax</span><span class="o">.</span><span class="n">zeros_like_array</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">res</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">ct_y</span><span class="p">,</span> <span class="n">ct</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="c1"># This use of multiply_add is with a constant &quot;y&quot;.</span>
    <span class="k">assert</span> <span class="n">ad</span><span class="o">.</span><span class="n">is_undefined_primal</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">ct_x</span> <span class="o">=</span> <span class="n">ad</span><span class="o">.</span><span class="n">Zero</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">aval</span><span class="p">)</span> <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">ct</span><span class="p">)</span> <span class="ow">is</span> <span class="n">ad</span><span class="o">.</span><span class="n">Zero</span> <span class="k">else</span> <span class="n">multiply_add_prim</span><span class="p">(</span><span class="n">ct</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lax</span><span class="o">.</span><span class="n">zeros_like_array</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">ct_x</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">ct</span>
  <span class="k">return</span> <span class="n">res</span>

<span class="n">ad</span><span class="o">.</span><span class="n">primitive_transposes</span><span class="p">[</span><span class="n">multiply_add_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">multiply_add_transpose</span>
</pre></div>
</div>
</div>
</div>
<p>Now you can complete the run of the <code class="docutils literal notranslate"><span class="pre">grad</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="n">api</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">square_add_prim</span><span class="p">)(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">)</span> <span class="o">==</span> <span class="mf">4.</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(Traced&lt;~float32[]&gt;, 10.0)
  call multiply_add_prim(Traced&lt;~float32[]&gt;, Traced&lt;~float32[]&gt;, 10.0)
    call multiply_add_value_and_jvp((2.0, 2.0, 10.0), (Traced&lt;~float32[]&gt;, Traced&lt;~float32[]&gt;, Zero(~float32[])))
      Primal evaluation:
      call multiply_add_prim(2.0, 2.0, 10.0)
        call multiply_add_impl(2.0, 2.0, 10.0)
        |&lt;- multiply_add_impl = 14.0
      |&lt;- multiply_add_prim = 14.0
      Tangent evaluation:
      call multiply_add_prim(2.0, Traced&lt;~float32[]&gt;, 0.0)
        call multiply_add_abstract_eval(~float32[], ~float32[], ~float32[])
        |&lt;- multiply_add_abstract_eval = float32[]
      |&lt;- multiply_add_prim = Traced&lt;float32[]&gt;
      call multiply_add_prim(Traced&lt;~float32[]&gt;, 2.0, Traced&lt;float32[]&gt;)
        call multiply_add_abstract_eval(~float32[], ~float32[], float32[])
        |&lt;- multiply_add_abstract_eval = float32[]
      |&lt;- multiply_add_prim = Traced&lt;float32[]&gt;
    |&lt;- multiply_add_value_and_jvp = (14.0, Traced&lt;float32[]&gt;)
  |&lt;- multiply_add_prim = Traced&lt;float32[]&gt;
|&lt;- square_add_prim = Traced&lt;float32[]&gt;
call multiply_add_transpose(1.0, UndefinedPrimal(~float32[]), 2.0, UndefinedPrimal(float32[]))
  call multiply_add_prim(1.0, 2.0, 0.0)
    call multiply_add_impl(1.0, 2.0, 0.0)
    |&lt;- multiply_add_impl = 2.0
  |&lt;- multiply_add_prim = 2.0
|&lt;- multiply_add_transpose = (2.0, None, 1.0)
call multiply_add_transpose(1.0, 2.0, UndefinedPrimal(~float32[]), 0.0)
  call multiply_add_prim(2.0, 1.0, 0.0)
    call multiply_add_impl(2.0, 1.0, 0.0)
    |&lt;- multiply_add_impl = 2.0
  |&lt;- multiply_add_prim = 2.0
|&lt;- multiply_add_transpose = (None, 2.0, 1.0)
</pre></div>
</div>
</div>
</div>
<p>Notice the two calls to <code class="docutils literal notranslate"><span class="pre">multiply_add_transpose</span></code>. They correspond to the two uses of <code class="docutils literal notranslate"><span class="pre">multiply_add_prim</span></code> in the computation of the <code class="docutils literal notranslate"><span class="pre">output_tangent</span></code> in <code class="docutils literal notranslate"><span class="pre">multiply_add_value_and_jvp</span></code>. The first call to transpose corresponds to the last use of <code class="docutils literal notranslate"><span class="pre">multiply_add_prim</span></code>: <code class="docutils literal notranslate"><span class="pre">multiply_add_prim(xt,</span> <span class="pre">y,</span> <span class="pre">...)</span></code> where <code class="docutils literal notranslate"><span class="pre">y</span></code> is the constant <code class="docutils literal notranslate"><span class="pre">2.0</span></code>.</p>
</section>
<section id="jit-of-reverse-differentiation">
<h4>JIT of reverse differentiation<a class="headerlink" href="#jit-of-reverse-differentiation" title="Link to this heading">#</a></h4>
<p>Notice that the abstract evaluation of the <code class="docutils literal notranslate"><span class="pre">multiply_add_value_and_jvp</span></code> is using only abstract values. Meanwhile, in the absence of JIT, you used <code class="docutils literal notranslate"><span class="pre">ConcreteArray</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="n">api</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">api</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">square_add_prim</span><span class="p">))(</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">)</span> <span class="o">==</span> <span class="mf">4.</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(Traced&lt;~float32[]&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;)
  call multiply_add_prim(Traced&lt;~float32[]&gt;, Traced&lt;~float32[]&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;)
    call multiply_add_value_and_jvp((Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;), (Traced&lt;~float32[]&gt;, Traced&lt;~float32[]&gt;, Zero(~float32[])))
      Primal evaluation:
      call multiply_add_prim(Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;)
        call multiply_add_abstract_eval(~float32[], ~float32[], ~float32[])
        |&lt;- multiply_add_abstract_eval = float32[]
      |&lt;- multiply_add_prim = Traced&lt;float32[]&gt;with&lt;DynamicJaxprTrace&gt;
      Tangent evaluation:
      call multiply_add_prim(Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;~float32[]&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;)
        call multiply_add_abstract_eval(~float32[], ~float32[], ~float32[])
        |&lt;- multiply_add_abstract_eval = float32[]
      |&lt;- multiply_add_prim = Traced&lt;float32[]&gt;
      call multiply_add_prim(Traced&lt;~float32[]&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;float32[]&gt;)
        call multiply_add_abstract_eval(~float32[], ~float32[], float32[])
        |&lt;- multiply_add_abstract_eval = float32[]
      |&lt;- multiply_add_prim = Traced&lt;float32[]&gt;
    |&lt;- multiply_add_value_and_jvp = (Traced&lt;float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;float32[]&gt;)
  |&lt;- multiply_add_prim = Traced&lt;float32[]&gt;
|&lt;- square_add_prim = Traced&lt;float32[]&gt;
call multiply_add_transpose(Traced&lt;float32[]&gt;with&lt;DynamicJaxprTrace&gt;, UndefinedPrimal(~float32[]), Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, UndefinedPrimal(float32[]))
  call multiply_add_prim(Traced&lt;float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;)
    call multiply_add_abstract_eval(float32[], ~float32[], ~float32[])
    |&lt;- multiply_add_abstract_eval = float32[]
  |&lt;- multiply_add_prim = Traced&lt;float32[]&gt;with&lt;DynamicJaxprTrace&gt;
|&lt;- multiply_add_transpose = (Traced&lt;float32[]&gt;with&lt;DynamicJaxprTrace&gt;, None, Traced&lt;float32[]&gt;with&lt;DynamicJaxprTrace&gt;)
call multiply_add_transpose(Traced&lt;float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, UndefinedPrimal(~float32[]), Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;)
  call multiply_add_prim(Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;~float32[]&gt;with&lt;DynamicJaxprTrace&gt;)
    call multiply_add_abstract_eval(~float32[], float32[], ~float32[])
    |&lt;- multiply_add_abstract_eval = float32[]
  |&lt;- multiply_add_prim = Traced&lt;float32[]&gt;with&lt;DynamicJaxprTrace&gt;
|&lt;- multiply_add_transpose = (None, Traced&lt;float32[]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;float32[]&gt;with&lt;DynamicJaxprTrace&gt;)
call multiply_add_lowering(LoweringRuleContext(module_context=ModuleContext(context=&lt;jax._src.interpreters.mlir.JaxIrContext object at 0x7f1d381f23c0&gt;, module=&lt;jaxlib.mlir._mlir_libs._mlir.ir.Module object at 0x7f1d182f9fd0&gt;, ip=&lt;jaxlib.mlir._mlir_libs._mlir.ir.InsertionPoint object at 0x7f1d182fa1a0&gt;, symbol_table=&lt;jaxlib.mlir._mlir_libs._mlir.ir.SymbolTable object at 0x7f1d3816dce0&gt;, platforms=(&#39;cpu&#39;,), backend=&lt;jaxlib._jax.Client object at 0x7f1d53bef5e0&gt;, axis_context=ShardingContext(num_devices=1, device_assignment=None, abstract_mesh=None), keepalives=[], channel_iterator=count(1), host_callbacks=[], shape_poly_state=&lt;jax._src.interpreters.mlir.ShapePolyLoweringState object at 0x7f1d182fe610&gt;, all_default_mem_kind=True, cached_primitive_lowerings={}, traceback_caches=TracebackCaches(traceback_cache={&lt;jaxlib._jax.Traceback object at 0x55898b59dfa0&gt;: loc(callsite(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;multiply_add_value_and_jvp&quot;(&quot;/tmp/ipykernel_229732/347789876.py&quot;:41:19 to :106) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;square_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:17:9 to :35) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;&lt;module&gt;&quot;(&quot;/tmp/ipykernel_229732/3085343041.py&quot;:1:7 to :50) at &quot;_run_code&quot;(&quot;&lt;frozen runpy&gt;&quot;:88:4 to :27)))))))))))}, location_cache={(&lt;code object multiply_add_prim at 0x7f1d53ce3730, file &quot;/tmp/ipykernel_229732/2637569133.py&quot;, line 5&gt;, 54): loc(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37)), (&lt;code object func_wrapper at 0x7f1d53d71230, file &quot;/tmp/ipykernel_229732/2803309189.py&quot;, line 45&gt;, 98): loc(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23)), (&lt;code object multiply_add_value_and_jvp at 0x7f1d53c5c1f0, file &quot;/tmp/ipykernel_229732/347789876.py&quot;, line 3&gt;, 246): loc(&quot;multiply_add_value_and_jvp&quot;(&quot;/tmp/ipykernel_229732/347789876.py&quot;:41:19 to :106)), (&lt;code object square_add_prim at 0x7f1d500ee950, file &quot;/tmp/ipykernel_229732/2637569133.py&quot;, line 14&gt;, 32): loc(&quot;square_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:17:9 to :35)), (&lt;code object &lt;module&gt; at 0x7f1d53d83210, file &quot;/tmp/ipykernel_229732/3085343041.py&quot;, line 1&gt;, 90): loc(&quot;&lt;module&gt;&quot;(&quot;/tmp/ipykernel_229732/3085343041.py&quot;:1:7 to :50)), (&lt;code object _run_code at 0x558966317d00, file &quot;&lt;frozen runpy&gt;&quot;, line 65&gt;, 202): loc(&quot;_run_code&quot;(&quot;&lt;frozen runpy&gt;&quot;:88:4 to :27))}, canonical_name_cache={&#39;/tmp/ipykernel_229732/2637569133.py&#39;: &#39;/tmp/ipykernel_229732/2637569133.py&#39;, &#39;/tmp/ipykernel_229732/2803309189.py&#39;: &#39;/tmp/ipykernel_229732/2803309189.py&#39;, &#39;/tmp/ipykernel_229732/347789876.py&#39;: &#39;/tmp/ipykernel_229732/347789876.py&#39;, &#39;/tmp/ipykernel_229732/3085343041.py&#39;: &#39;/tmp/ipykernel_229732/3085343041.py&#39;, &#39;&lt;frozen runpy&gt;&#39;: &#39;&lt;frozen runpy&gt;&#39;}, is_user_file_cache={&#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/source_info_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/interpreters/partial_eval.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/core.py&#39;: False, &#39;/tmp/ipykernel_229732/2637569133.py&#39;: True, &#39;/tmp/ipykernel_229732/2803309189.py&#39;: True, &#39;/tmp/ipykernel_229732/347789876.py&#39;: True, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/interpreters/ad.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/linear_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/api_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/profiler.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/api.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/traceback_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/pjit.py&#39;: False, &#39;/tmp/ipykernel_229732/3085343041.py&#39;: True, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/IPython/core/interactiveshell.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/IPython/core/async_helpers.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/ipykernel/zmqshell.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/ipykernel/ipkernel.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/ipykernel/kernelbase.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/asyncio/events.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/asyncio/base_events.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/tornado/platform/asyncio.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/ipykernel/kernelapp.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/traitlets/config/application.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/ipykernel_launcher.py&#39;: False, &#39;&lt;frozen runpy&gt;&#39;: True}), lowering_parameters=LoweringParameters(override_lowering_rules=None, global_constant_computation=False, for_export=False, export_ignore_forward_compatibility=False)), name_stack=NameStack(stack=(Scope(name=&#39;jit(square_add_prim)&#39;), Scope(name=&#39;jit(main)&#39;), Transform(name=&#39;transpose&#39;), Transform(name=&#39;jvp&#39;))), primitive=multiply_add, avals_in=[ShapedArray(float32[]), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True)], avals_out=[ShapedArray(float32[])], tokens_in=&lt;jax._src.interpreters.mlir.TokenSet object at 0x7f1d182fee10&gt;, tokens_out=None, axis_size_env=None, dim_var_values=[], jaxpr_eqn_ctx=JaxprEqnContext(compute_type=None, threefry_partitionable=True, cur_abstract_mesh=AbstractMesh((), axis_types=()), xla_metadata=None), platforms=None), Value(%0 = &quot;stablehlo.constant&quot;() &lt;{value = dense&lt;1.000000e+00&gt; : tensor&lt;f32&gt;}&gt; : () -&gt; tensor&lt;f32&gt;), Value(&lt;block argument&gt; of type &#39;tensor&lt;f32&gt;&#39; at index: 0), Value(%1 = &quot;stablehlo.constant&quot;() &lt;{value = dense&lt;0.000000e+00&gt; : tensor&lt;f32&gt;}&gt; : () -&gt; tensor&lt;f32&gt;))
|&lt;- multiply_add_lowering = [&lt;jaxlib.mlir._mlir_libs._mlir.ir.OpResult object at 0x7f1d381575b0&gt;]
call multiply_add_lowering(LoweringRuleContext(module_context=ModuleContext(context=&lt;jax._src.interpreters.mlir.JaxIrContext object at 0x7f1d381f23c0&gt;, module=&lt;jaxlib.mlir._mlir_libs._mlir.ir.Module object at 0x7f1d182f9fd0&gt;, ip=&lt;jaxlib.mlir._mlir_libs._mlir.ir.InsertionPoint object at 0x7f1d182fa1a0&gt;, symbol_table=&lt;jaxlib.mlir._mlir_libs._mlir.ir.SymbolTable object at 0x7f1d3816dce0&gt;, platforms=(&#39;cpu&#39;,), backend=&lt;jaxlib._jax.Client object at 0x7f1d53bef5e0&gt;, axis_context=ShardingContext(num_devices=1, device_assignment=None, abstract_mesh=None), keepalives=[], channel_iterator=count(1), host_callbacks=[], shape_poly_state=&lt;jax._src.interpreters.mlir.ShapePolyLoweringState object at 0x7f1d182fe610&gt;, all_default_mem_kind=True, cached_primitive_lowerings={}, traceback_caches=TracebackCaches(traceback_cache={&lt;jaxlib._jax.Traceback object at 0x55898b59dfa0&gt;: loc(callsite(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;multiply_add_value_and_jvp&quot;(&quot;/tmp/ipykernel_229732/347789876.py&quot;:41:19 to :106) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;square_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:17:9 to :35) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;&lt;module&gt;&quot;(&quot;/tmp/ipykernel_229732/3085343041.py&quot;:1:7 to :50) at &quot;_run_code&quot;(&quot;&lt;frozen runpy&gt;&quot;:88:4 to :27))))))))))), &lt;jaxlib._jax.Traceback object at 0x55898b6780d0&gt;: loc(callsite(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;multiply_add_value_and_jvp&quot;(&quot;/tmp/ipykernel_229732/347789876.py&quot;:41:55 to :105) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;square_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:17:9 to :35) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;&lt;module&gt;&quot;(&quot;/tmp/ipykernel_229732/3085343041.py&quot;:1:7 to :50) at &quot;_run_code&quot;(&quot;&lt;frozen runpy&gt;&quot;:88:4 to :27)))))))))))}, location_cache={(&lt;code object multiply_add_prim at 0x7f1d53ce3730, file &quot;/tmp/ipykernel_229732/2637569133.py&quot;, line 5&gt;, 54): loc(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37)), (&lt;code object func_wrapper at 0x7f1d53d71230, file &quot;/tmp/ipykernel_229732/2803309189.py&quot;, line 45&gt;, 98): loc(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23)), (&lt;code object multiply_add_value_and_jvp at 0x7f1d53c5c1f0, file &quot;/tmp/ipykernel_229732/347789876.py&quot;, line 3&gt;, 246): loc(&quot;multiply_add_value_and_jvp&quot;(&quot;/tmp/ipykernel_229732/347789876.py&quot;:41:19 to :106)), (&lt;code object square_add_prim at 0x7f1d500ee950, file &quot;/tmp/ipykernel_229732/2637569133.py&quot;, line 14&gt;, 32): loc(&quot;square_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:17:9 to :35)), (&lt;code object &lt;module&gt; at 0x7f1d53d83210, file &quot;/tmp/ipykernel_229732/3085343041.py&quot;, line 1&gt;, 90): loc(&quot;&lt;module&gt;&quot;(&quot;/tmp/ipykernel_229732/3085343041.py&quot;:1:7 to :50)), (&lt;code object _run_code at 0x558966317d00, file &quot;&lt;frozen runpy&gt;&quot;, line 65&gt;, 202): loc(&quot;_run_code&quot;(&quot;&lt;frozen runpy&gt;&quot;:88:4 to :27)), (&lt;code object multiply_add_value_and_jvp at 0x7f1d53c5c1f0, file &quot;/tmp/ipykernel_229732/347789876.py&quot;, line 3&gt;, 232): loc(&quot;multiply_add_value_and_jvp&quot;(&quot;/tmp/ipykernel_229732/347789876.py&quot;:41:55 to :105))}, canonical_name_cache={&#39;/tmp/ipykernel_229732/2637569133.py&#39;: &#39;/tmp/ipykernel_229732/2637569133.py&#39;, &#39;/tmp/ipykernel_229732/2803309189.py&#39;: &#39;/tmp/ipykernel_229732/2803309189.py&#39;, &#39;/tmp/ipykernel_229732/347789876.py&#39;: &#39;/tmp/ipykernel_229732/347789876.py&#39;, &#39;/tmp/ipykernel_229732/3085343041.py&#39;: &#39;/tmp/ipykernel_229732/3085343041.py&#39;, &#39;&lt;frozen runpy&gt;&#39;: &#39;&lt;frozen runpy&gt;&#39;}, is_user_file_cache={&#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/source_info_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/interpreters/partial_eval.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/core.py&#39;: False, &#39;/tmp/ipykernel_229732/2637569133.py&#39;: True, &#39;/tmp/ipykernel_229732/2803309189.py&#39;: True, &#39;/tmp/ipykernel_229732/347789876.py&#39;: True, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/interpreters/ad.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/linear_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/api_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/profiler.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/api.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/traceback_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/pjit.py&#39;: False, &#39;/tmp/ipykernel_229732/3085343041.py&#39;: True, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/IPython/core/interactiveshell.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/IPython/core/async_helpers.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/ipykernel/zmqshell.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/ipykernel/ipkernel.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/ipykernel/kernelbase.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/asyncio/events.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/asyncio/base_events.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/tornado/platform/asyncio.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/ipykernel/kernelapp.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/traitlets/config/application.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/ipykernel_launcher.py&#39;: False, &#39;&lt;frozen runpy&gt;&#39;: True}), lowering_parameters=LoweringParameters(override_lowering_rules=None, global_constant_computation=False, for_export=False, export_ignore_forward_compatibility=False)), name_stack=NameStack(stack=(Scope(name=&#39;jit(square_add_prim)&#39;), Scope(name=&#39;jit(main)&#39;), Transform(name=&#39;transpose&#39;), Transform(name=&#39;jvp&#39;))), primitive=multiply_add, avals_in=[ShapedArray(float32[], weak_type=True), ShapedArray(float32[]), ShapedArray(float32[], weak_type=True)], avals_out=[ShapedArray(float32[])], tokens_in=&lt;jax._src.interpreters.mlir.TokenSet object at 0x7f1d182fe350&gt;, tokens_out=None, axis_size_env=None, dim_var_values=[], jaxpr_eqn_ctx=JaxprEqnContext(compute_type=None, threefry_partitionable=True, cur_abstract_mesh=AbstractMesh((), axis_types=()), xla_metadata=None), platforms=None), Value(&lt;block argument&gt; of type &#39;tensor&lt;f32&gt;&#39; at index: 0), Value(%0 = &quot;stablehlo.constant&quot;() &lt;{value = dense&lt;1.000000e+00&gt; : tensor&lt;f32&gt;}&gt; : () -&gt; tensor&lt;f32&gt;), Value(%1 = &quot;stablehlo.constant&quot;() &lt;{value = dense&lt;0.000000e+00&gt; : tensor&lt;f32&gt;}&gt; : () -&gt; tensor&lt;f32&gt;))
|&lt;- multiply_add_lowering = [&lt;jaxlib.mlir._mlir_libs._mlir.ir.OpResult object at 0x7f1d182fee30&gt;]
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="batching">
<h3>Batching<a class="headerlink" href="#batching" title="Link to this heading">#</a></h3>
<p>The batching transformation takes a point-wise computation and turns it into a computation on vectors. If you try it right now, you will get a <code class="docutils literal notranslate"><span class="pre">NotImplementedError</span></code>:</p>
<div class="cell tag_raises-exception docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># The arguments are two vectors instead of two scalars.</span>
<span class="k">with</span> <span class="n">expectNotImplementedError</span><span class="p">():</span>
  <span class="n">api</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">square_add_prim</span><span class="p">,</span> <span class="n">in_axes</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">out_axes</span><span class="o">=</span><span class="mi">0</span><span class="p">)(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]),</span>
                                               <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">10.</span><span class="p">,</span> <span class="mf">20.</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(Traced&lt;float32[]&gt;, Traced&lt;float32[]&gt;)
  call multiply_add_prim(Traced&lt;float32[]&gt;, Traced&lt;float32[]&gt;, Traced&lt;float32[]&gt;)

Found expected exception:
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Traceback (most recent call last):
  File &quot;/tmp/ipykernel_229732/1080163607.py&quot;, line 3, in &lt;module&gt;
    api.vmap(square_add_prim, in_axes=0, out_axes=0)(np.array([2., 3.]),
  File &quot;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/traceback_util.py&quot;, line 182, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File &quot;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/api.py&quot;, line 1129, in vmap_f
    out_flat = batching.batch(
               ^^^^^^^^^^^^^^^
NotImplementedError: Batching rule for &#39;multiply_add&#39; not implemented
</pre></div>
</div>
</div>
</div>
<p>You need to instruct JAX how to evaluate the batched version of the primitive. In this particular case, the <code class="docutils literal notranslate"><span class="pre">multiply_add_prim</span></code> already operates pointwise for any dimension of input vectors, so the batched version can use the same <code class="docutils literal notranslate"><span class="pre">multiply_add_prim</span></code> implementation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">jax.interpreters</span> <span class="kn">import</span> <span class="n">batching</span>

<span class="nd">@trace</span><span class="p">(</span><span class="s2">&quot;multiply_add_batch&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">multiply_add_batch</span><span class="p">(</span><span class="n">vector_arg_values</span><span class="p">,</span> <span class="n">batch_axes</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Computes the batched version of the primitive.</span>
<span class="sd">  </span>
<span class="sd">  This must be a JAX-traceable function.</span>
<span class="sd">  </span>
<span class="sd">  Since the `multiply_add primitive` already operates point-wise on arbitrary</span>
<span class="sd">  dimension tensors, to batch it you can use the primitive itself. This works as</span>
<span class="sd">  long as both the inputs have the same dimensions and are batched along the</span>
<span class="sd">  same axes. The result is batched along the axis that the inputs are batched.</span>

<span class="sd">  Args:</span>
<span class="sd">    vector_arg_values: A tuple of two arguments, each being a tensor of matching</span>
<span class="sd">      shape.</span>
<span class="sd">    batch_axes: The axes that are being batched. See vmap documentation.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple of the result, and the result axis that was batched. </span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">assert</span> <span class="n">batch_axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">batch_axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
  <span class="k">assert</span> <span class="n">batch_axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">batch_axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
  <span class="n">_trace</span><span class="p">(</span><span class="s2">&quot;Using multiply_add to compute the batch:&quot;</span><span class="p">)</span>
  <span class="n">res</span> <span class="o">=</span> <span class="n">multiply_add_prim</span><span class="p">(</span><span class="o">*</span><span class="n">vector_arg_values</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">res</span><span class="p">,</span> <span class="n">batch_axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>


<span class="n">batching</span><span class="o">.</span><span class="n">primitive_batchers</span><span class="p">[</span><span class="n">multiply_add_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">multiply_add_batch</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">api</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">square_add_prim</span><span class="p">,</span> <span class="n">in_axes</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">out_axes</span><span class="o">=</span><span class="mi">0</span><span class="p">)(</span>
  <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]),</span>
  <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">10.</span><span class="p">,</span> <span class="mf">20.</span><span class="p">])),</span>
  <span class="p">[</span><span class="mf">14.</span><span class="p">,</span> <span class="mf">29.</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(Traced&lt;float32[]&gt;, Traced&lt;float32[]&gt;)
  call multiply_add_prim(Traced&lt;float32[]&gt;, Traced&lt;float32[]&gt;, Traced&lt;float32[]&gt;)
    call multiply_add_batch(([2. 3.], [2. 3.], [10. 20.]), (0, 0, 0))
      Using multiply_add to compute the batch:
      call multiply_add_prim([2. 3.], [2. 3.], [10. 20.])
        call multiply_add_impl([2. 3.], [2. 3.], [10. 20.])
        |&lt;- multiply_add_impl = [14. 29.]
      |&lt;- multiply_add_prim = [14. 29.]
    |&lt;- multiply_add_batch = ([14. 29.], 0)
  |&lt;- multiply_add_prim = Traced&lt;float32[]&gt;
|&lt;- square_add_prim = Traced&lt;float32[]&gt;
</pre></div>
</div>
</div>
</div>
<section id="jit-of-batching">
<h4>JIT of batching<a class="headerlink" href="#jit-of-batching" title="Link to this heading">#</a></h4>
<p>Below is an example of applying JIT to batching:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">api</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span><span class="n">api</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">square_add_prim</span><span class="p">,</span> <span class="n">in_axes</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">out_axes</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
                    <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]),</span>
                     <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">10.</span><span class="p">,</span> <span class="mf">20.</span><span class="p">])),</span>
                    <span class="p">[</span><span class="mf">14.</span><span class="p">,</span> <span class="mf">29.</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>call square_add_prim(Traced&lt;float32[]&gt;, Traced&lt;float32[]&gt;)
  call multiply_add_prim(Traced&lt;float32[]&gt;, Traced&lt;float32[]&gt;, Traced&lt;float32[]&gt;)
    call multiply_add_batch((Traced&lt;float32[2]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;float32[2]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;float32[2]&gt;with&lt;DynamicJaxprTrace&gt;), (0, 0, 0))
      Using multiply_add to compute the batch:
      call multiply_add_prim(Traced&lt;float32[2]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;float32[2]&gt;with&lt;DynamicJaxprTrace&gt;, Traced&lt;float32[2]&gt;with&lt;DynamicJaxprTrace&gt;)
        call multiply_add_abstract_eval(float32[2], float32[2], float32[2])
        |&lt;- multiply_add_abstract_eval = float32[2]
      |&lt;- multiply_add_prim = Traced&lt;float32[2]&gt;with&lt;DynamicJaxprTrace&gt;
    |&lt;- multiply_add_batch = (Traced&lt;float32[2]&gt;with&lt;DynamicJaxprTrace&gt;, 0)
  |&lt;- multiply_add_prim = Traced&lt;float32[]&gt;
|&lt;- square_add_prim = Traced&lt;float32[]&gt;
call multiply_add_lowering(LoweringRuleContext(module_context=ModuleContext(context=&lt;jax._src.interpreters.mlir.JaxIrContext object at 0x7f1d381f2600&gt;, module=&lt;jaxlib.mlir._mlir_libs._mlir.ir.Module object at 0x7f1d182fab10&gt;, ip=&lt;jaxlib.mlir._mlir_libs._mlir.ir.InsertionPoint object at 0x7f1d182fab50&gt;, symbol_table=&lt;jaxlib.mlir._mlir_libs._mlir.ir.SymbolTable object at 0x7f1d3816ca50&gt;, platforms=(&#39;cpu&#39;,), backend=&lt;jaxlib._jax.Client object at 0x7f1d53bef5e0&gt;, axis_context=ShardingContext(num_devices=1, device_assignment=None, abstract_mesh=None), keepalives=[], channel_iterator=count(1), host_callbacks=[], shape_poly_state=&lt;jax._src.interpreters.mlir.ShapePolyLoweringState object at 0x7f1d18305310&gt;, all_default_mem_kind=True, cached_primitive_lowerings={}, traceback_caches=TracebackCaches(traceback_cache={&lt;jaxlib._jax.Traceback object at 0x558989ce6410&gt;: loc(callsite(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;multiply_add_batch&quot;(&quot;/tmp/ipykernel_229732/1827752256.py&quot;:25:8 to :45) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;square_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:17:9 to :35) at callsite(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23) at callsite(&quot;&lt;module&gt;&quot;(&quot;/tmp/ipykernel_229732/1392464762.py&quot;:1:19 to 3:42) at &quot;_run_code&quot;(&quot;&lt;frozen runpy&gt;&quot;:88:4 to :27)))))))))))}, location_cache={(&lt;code object multiply_add_prim at 0x7f1d53ce3730, file &quot;/tmp/ipykernel_229732/2637569133.py&quot;, line 5&gt;, 54): loc(&quot;multiply_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:12:9 to :37)), (&lt;code object func_wrapper at 0x7f1d53d71230, file &quot;/tmp/ipykernel_229732/2803309189.py&quot;, line 45&gt;, 98): loc(&quot;trace.&lt;locals&gt;.trace_func.&lt;locals&gt;.func_wrapper&quot;(&quot;/tmp/ipykernel_229732/2803309189.py&quot;:48:12 to :23)), (&lt;code object multiply_add_batch at 0x7f1d53cfd680, file &quot;/tmp/ipykernel_229732/1827752256.py&quot;, line 3&gt;, 126): loc(&quot;multiply_add_batch&quot;(&quot;/tmp/ipykernel_229732/1827752256.py&quot;:25:8 to :45)), (&lt;code object square_add_prim at 0x7f1d500ee950, file &quot;/tmp/ipykernel_229732/2637569133.py&quot;, line 14&gt;, 32): loc(&quot;square_add_prim&quot;(&quot;/tmp/ipykernel_229732/2637569133.py&quot;:17:9 to :35)), (&lt;code object &lt;module&gt; at 0x7f1d53ec81e0, file &quot;/tmp/ipykernel_229732/1392464762.py&quot;, line 1&gt;, 204): loc(&quot;&lt;module&gt;&quot;(&quot;/tmp/ipykernel_229732/1392464762.py&quot;:1:19 to 3:42)), (&lt;code object _run_code at 0x558966317d00, file &quot;&lt;frozen runpy&gt;&quot;, line 65&gt;, 202): loc(&quot;_run_code&quot;(&quot;&lt;frozen runpy&gt;&quot;:88:4 to :27))}, canonical_name_cache={&#39;/tmp/ipykernel_229732/2637569133.py&#39;: &#39;/tmp/ipykernel_229732/2637569133.py&#39;, &#39;/tmp/ipykernel_229732/2803309189.py&#39;: &#39;/tmp/ipykernel_229732/2803309189.py&#39;, &#39;/tmp/ipykernel_229732/1827752256.py&#39;: &#39;/tmp/ipykernel_229732/1827752256.py&#39;, &#39;/tmp/ipykernel_229732/1392464762.py&#39;: &#39;/tmp/ipykernel_229732/1392464762.py&#39;, &#39;&lt;frozen runpy&gt;&#39;: &#39;&lt;frozen runpy&gt;&#39;}, is_user_file_cache={&#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/source_info_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/interpreters/partial_eval.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/core.py&#39;: False, &#39;/tmp/ipykernel_229732/2637569133.py&#39;: True, &#39;/tmp/ipykernel_229732/2803309189.py&#39;: True, &#39;/tmp/ipykernel_229732/1827752256.py&#39;: True, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/interpreters/batching.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/linear_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/api.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/traceback_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/api_util.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/profiler.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/jax/_src/pjit.py&#39;: False, &#39;/tmp/ipykernel_229732/1392464762.py&#39;: True, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/IPython/core/interactiveshell.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/IPython/core/async_helpers.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/ipykernel/zmqshell.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/ipykernel/ipkernel.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/ipykernel/kernelbase.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/asyncio/events.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/asyncio/base_events.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/tornado/platform/asyncio.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/ipykernel/kernelapp.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/traitlets/config/application.py&#39;: False, &#39;/home/melissa/micromamba/envs/jax-dev/lib/python3.11/site-packages/ipykernel_launcher.py&#39;: False, &#39;&lt;frozen runpy&gt;&#39;: True}), lowering_parameters=LoweringParameters(override_lowering_rules=None, global_constant_computation=False, for_export=False, export_ignore_forward_compatibility=False)), name_stack=NameStack(stack=(Scope(name=&#39;jit(square_add_prim)&#39;), Scope(name=&#39;jit(main)&#39;), Transform(name=&#39;vmap&#39;))), primitive=multiply_add, avals_in=[ShapedArray(float32[2]), ShapedArray(float32[2]), ShapedArray(float32[2])], avals_out=[ShapedArray(float32[2])], tokens_in=&lt;jax._src.interpreters.mlir.TokenSet object at 0x7f1d18305e90&gt;, tokens_out=None, axis_size_env=None, dim_var_values=[], jaxpr_eqn_ctx=JaxprEqnContext(compute_type=None, threefry_partitionable=True, cur_abstract_mesh=AbstractMesh((), axis_types=()), xla_metadata=None), platforms=None), Value(&lt;block argument&gt; of type &#39;tensor&lt;2xf32&gt;&#39; at index: 0), Value(&lt;block argument&gt; of type &#39;tensor&lt;2xf32&gt;&#39; at index: 0), Value(&lt;block argument&gt; of type &#39;tensor&lt;2xf32&gt;&#39; at index: 1))
|&lt;- multiply_add_lowering = [&lt;jaxlib.mlir._mlir_libs._mlir.ir.OpResult object at 0x7f1d381575b0&gt;]
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="sharded-computation.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Introduction to parallel programming</p>
      </div>
    </a>
    <a class="right-next"
       href="jaxpr.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">JAX internals: The jaxpr language</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-jax-primitives">Introduction to JAX primitives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-existing-jax-primitives">Using existing JAX primitives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-new-jax-primitives">Defining new JAX primitives</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#primal-evaluation-rules">Primal evaluation rules</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-happens-when-you-use-jit">What happens when you use <code class="docutils literal notranslate"><span class="pre">jit</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#abstract-evaluation-rules">Abstract evaluation rules</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#xla-compilation-rules">XLA Compilation rules</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#forward-differentiation">Forward differentiation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#jit-of-forward-differentiation">JIT of forward differentiation</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reverse-differentiation">Reverse differentiation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#transposition">Transposition</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#jit-of-reverse-differentiation">JIT of reverse differentiation</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#batching">Batching</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#jit-of-batching">JIT of batching</a></li>
</ul>
</li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The JAX authors
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright 2024, The JAX Authors.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>