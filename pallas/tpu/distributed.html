
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Distributed Computing in Pallas for TPUs &#8212; JAX  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/style.css?v=7143c0a5" />
    <link rel="stylesheet" href="../../_static/style.css" type="text/css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=30646c52"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'pallas/tpu/distributed';</script>
    <link rel="icon" href="../../_static/favicon.png"/>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Pallas:Mosaic GPU" href="../gpu/index.html" />
    <link rel="prev" title="Scalar Prefetch and Block-Sparse Computation" href="sparse.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/jax_logo_250px.png" class="logo__image only-light" alt="JAX  documentation - Home"/>
    <script>document.write(`<img src="../../_static/jax_logo_250px.png" class="logo__image only-dark" alt="JAX  documentation - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/thinking_in_jax.html">Quickstart: How to think in JAX</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/Common_Gotchas_in_JAX.html">🔪 JAX - The Sharp Bits 🔪</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials.html">Tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../jit-compilation.html">Just-in-time compilation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../automatic-vectorization.html">Automatic vectorization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../automatic-differentiation.html">Automatic differentiation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../random-numbers.html">Pseudorandom numbers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../stateful-computations.html">Stateful computations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../control-flow.html">Control flow and logical operators with JIT</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../pytrees.html">Pytrees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../working-with-pytrees.html">Working with pytrees</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Resources, guides, and references</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../key-concepts.html">Key concepts</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../../advanced_guides.html">Resources and Advanced Guides</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/autodiff_cookbook.html">The Autodiff Cookbook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/Custom_derivative_rules_for_Python_code.html">Custom derivative rules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/autodiff_remat.html">Control autodiff’s saved values with <code class="docutils literal notranslate"><span class="pre">jax.checkpoint</span></code> (aka <code class="docutils literal notranslate"><span class="pre">jax.remat</span></code>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../advanced-autodiff.html">Advanced automatic differentiation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../errors.html">Errors</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../debugging.html">Introduction to debugging</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../debugging/print_breakpoint.html">Compiled prints and breakpoints</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../debugging/checkify_guide.html">The <code class="docutils literal notranslate"><span class="pre">checkify</span></code> transformation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../debugging/flags.html">JAX debugging flags</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../debugging/flags.html">JAX debugging flags</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../transfer_guard.html">Transfer guard</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../persistent_compilation_cache.html">Persistent compilation cache</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../gpu_performance_tips.html">GPU performance tips</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../profiling.html">Profiling computation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../device_memory_profiling.html">Profiling device memory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/Distributed_arrays_and_automatic_parallelization.html">Distributed arrays and automatic parallelization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/explicit-sharding.html">Explicit sharding (a.k.a. “sharding in types”)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/shard_map.html">Manual parallelism with <code class="docutils literal notranslate"><span class="pre">shard_map</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/layout.html">Device-local array layout control</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/host-offloading.html">JAX Memories and Host Offloading</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../multi_process.html">Introduction to multi-controller JAX (aka multi-process/multi-host JAX)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../distributed_data_loading.html">Distributed data loading</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../external-callbacks.html">External callbacks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../ffi.html">Foreign function interface (FFI)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../gradient-checkpointing.html">Gradient checkpointing with <code class="docutils literal notranslate"><span class="pre">jax.checkpoint</span></code> (<code class="docutils literal notranslate"><span class="pre">jax.remat</span></code>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../aot.html">Ahead-of-time lowering and compilation</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../export/index.html">Exporting and serialization</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../export/export.html">Exporting and serializing staged-out computations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../export/shape_poly.html">Shape polymorphism</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../export/jax2tf.html">Interoperation with TensorFlow</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../type_promotion.html">Type promotion semantics</a></li>
<li class="toctree-l2 current active has-children"><a class="reference internal" href="../index.html">Pallas: a JAX kernel language</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../quickstart.html">Pallas Quickstart</a></li>
<li class="toctree-l3"><a class="reference internal" href="../pipelining.html">Software Pipelining</a></li>
<li class="toctree-l3"><a class="reference internal" href="../grid_blockspec.html">Grids and BlockSpecs</a></li>
<li class="toctree-l3 current active has-children"><a class="reference internal" href="index.html">Pallas TPU</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="details.html">Writing TPU kernels with Pallas</a></li>
<li class="toctree-l4"><a class="reference internal" href="pipelining.html">TPU Pipelining</a></li>
<li class="toctree-l4"><a class="reference internal" href="matmul.html">Matrix Multiplication</a></li>
<li class="toctree-l4"><a class="reference internal" href="sparse.html">Scalar Prefetch and Block-Sparse Computation</a></li>
<li class="toctree-l4 current active"><a class="current reference internal" href="#">Distributed Computing in Pallas for TPUs</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../gpu/index.html">Pallas:Mosaic GPU</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../gpu/reference.html">Writing Mosaic GPU kernels with Pallas</a></li>
<li class="toctree-l4"><a class="reference internal" href="../gpu/pipelining.html">Mosaic GPU Pipelining</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../design/index.html">Pallas Design Notes</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../design/design.html">Pallas Design</a></li>
<li class="toctree-l4"><a class="reference internal" href="../design/async_note.html">Pallas Async Operations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../CHANGELOG.html">Pallas Changelog</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/neural_network_with_tfds_data.html">Training a simple neural network, with tensorflow/datasets data loading</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/Neural_Network_and_Data_Loading.html">Training a simple neural network, with PyTorch data loading</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/vmapped_log_probs.html">Autobatching for Bayesian inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/convolutions.html">Generalized convolutions in JAX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../xla_flags.html">XLA compiler flags</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../sharded-computation.html">Introduction to parallel programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../jax-primitives.html">JAX Internals: primitives</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../jaxpr.html">JAX internals: The jaxpr language</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../contributor_guide.html">Developer notes</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../contributing.html">Contributing to JAX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../developer.html">Building from source</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../investigating_a_regression.html">Investigating a regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../autodidax.html">Autodidax: JAX core from scratch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../autodidax2_part1.html">Autodidax2, part 1: JAX from scratch, again</a></li>

<li class="toctree-l2 has-children"><a class="reference internal" href="../../jep/index.html">JAX Enhancement Proposals (JEPs)</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../jep/263-prng.html">263: JAX PRNG Design</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jep/2026-custom-derivatives.html">2026: Custom JVP/VJP rules for JAX-transformable functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jep/4008-custom-vjp-update.html">4008: Custom VJP and `nondiff_argnums` update</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jep/4410-omnistaging.html">4410: Omnistaging</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jep/9263-typed-keys.html">9263: Typed keys &amp; pluggable RNGs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jep/9407-type-promotion.html">9407: Design of Type Promotion Semantics for JAX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jep/9419-jax-versioning.html">9419: Jax and Jaxlib versioning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jep/10657-sequencing-effects.html">10657: Sequencing side-effects in JAX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jep/11830-new-remat-checkpoint.html">11830: `jax.remat` / `jax.checkpoint` new implementation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jep/12049-type-annotations.html">12049: Type Annotation Roadmap for JAX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jep/14273-shard-map.html">14273: `shard_map` (`shmap`) for simple per-device code</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jep/15856-jex.html">15856: `jax.extend`, an extensions module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jep/17111-shmap-transpose.html">17111: Efficient transposition of `shard_map` (and other maps)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jep/18137-numpy-scipy-scope.html">18137: Scope of JAX NumPy &amp; SciPy Wrappers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jep/25516-effver.html">25516: Effort-based versioning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jep/28661-jax-array-protocol.html">28661: Supporting the `__jax_array__` protocol</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../extensions.html">Extension guides</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks/Writing_custom_interpreters_in_Jax.html">Writing custom Jaxpr interpreters in JAX</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../jax.extend.html"><code class="docutils literal notranslate"><span class="pre">jax.extend</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../jax.extend.core.html"><code class="docutils literal notranslate"><span class="pre">jax.extend.core</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jax.extend.linear_util.html"><code class="docutils literal notranslate"><span class="pre">jax.extend.linear_util</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jax.extend.mlir.html"><code class="docutils literal notranslate"><span class="pre">jax.extend.mlir</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jax.extend.random.html"><code class="docutils literal notranslate"><span class="pre">jax.extend.random</span></code> module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../building_on_jax.html">Building on JAX</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../notes.html">Notes</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../api_compatibility.html">API compatibility</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../deprecation.html">Python and NumPy version support policy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../async_dispatch.html">Asynchronous dispatch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../concurrency.html">Concurrency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../gpu_memory_allocation.html">GPU memory allocation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../rank_promotion_warning.html">Rank promotion warning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../type_promotion.html">Type promotion semantics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../default_dtypes.html">Default dtypes and the X64 flag</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../jax.html">Public API: <code class="docutils literal notranslate"><span class="pre">jax</span></code> package</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../jax.numpy.html"><code class="docutils literal notranslate"><span class="pre">jax.numpy</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../_autosummary/jax.numpy.fft.fft.html">jax.numpy.fft.fft</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../_autosummary/jax.numpy.fft.fft2.html">jax.numpy.fft.fft2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../_autosummary/jax.numpy.fft.fftfreq.html">jax.numpy.fft.fftfreq</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../_autosummary/jax.numpy.fft.fftn.html">jax.numpy.fft.fftn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../_autosummary/jax.numpy.fft.fftshift.html">jax.numpy.fft.fftshift</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../_autosummary/jax.numpy.fft.hfft.html">jax.numpy.fft.hfft</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../_autosummary/jax.numpy.fft.ifft.html">jax.numpy.fft.ifft</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../_autosummary/jax.numpy.fft.ifft2.html">jax.numpy.fft.ifft2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../_autosummary/jax.numpy.fft.ifftn.html">jax.numpy.fft.ifftn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../_autosummary/jax.numpy.fft.ifftshift.html">jax.numpy.fft.ifftshift</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../_autosummary/jax.numpy.fft.ihfft.html">jax.numpy.fft.ihfft</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../_autosummary/jax.numpy.fft.irfft.html">jax.numpy.fft.irfft</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../_autosummary/jax.numpy.fft.irfft2.html">jax.numpy.fft.irfft2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../_autosummary/jax.numpy.fft.irfftn.html">jax.numpy.fft.irfftn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../_autosummary/jax.numpy.fft.rfft.html">jax.numpy.fft.rfft</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../_autosummary/jax.numpy.fft.rfft2.html">jax.numpy.fft.rfft2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../_autosummary/jax.numpy.fft.rfftfreq.html">jax.numpy.fft.rfftfreq</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../_autosummary/jax.numpy.fft.rfftn.html">jax.numpy.fft.rfftn</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../jax.scipy.html"><code class="docutils literal notranslate"><span class="pre">jax.scipy</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../_autosummary/jax.scipy.stats.bernoulli.logpmf.html">jax.scipy.stats.bernoulli.logpmf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../_autosummary/jax.scipy.stats.bernoulli.pmf.html">jax.scipy.stats.bernoulli.pmf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../_autosummary/jax.scipy.stats.bernoulli.cdf.html">jax.scipy.stats.bernoulli.cdf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../_autosummary/jax.scipy.stats.bernoulli.ppf.html">jax.scipy.stats.bernoulli.ppf</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../jax.lax.html"><code class="docutils literal notranslate"><span class="pre">jax.lax</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../jax.random.html"><code class="docutils literal notranslate"><span class="pre">jax.random</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../jax.sharding.html"><code class="docutils literal notranslate"><span class="pre">jax.sharding</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../jax.debug.html"><code class="docutils literal notranslate"><span class="pre">jax.debug</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../jax.dlpack.html"><code class="docutils literal notranslate"><span class="pre">jax.dlpack</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../jax.distributed.html"><code class="docutils literal notranslate"><span class="pre">jax.distributed</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../jax.dtypes.html"><code class="docutils literal notranslate"><span class="pre">jax.dtypes</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../jax.ffi.html"><code class="docutils literal notranslate"><span class="pre">jax.ffi</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../jax.flatten_util.html"><code class="docutils literal notranslate"><span class="pre">jax.flatten_util</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../jax.image.html"><code class="docutils literal notranslate"><span class="pre">jax.image</span></code> module</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../jax.nn.html"><code class="docutils literal notranslate"><span class="pre">jax.nn</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../jax.nn.initializers.html"><code class="docutils literal notranslate"><span class="pre">jax.nn.initializers</span></code> module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../jax.ops.html"><code class="docutils literal notranslate"><span class="pre">jax.ops</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../jax.profiler.html"><code class="docutils literal notranslate"><span class="pre">jax.profiler</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../jax.stages.html"><code class="docutils literal notranslate"><span class="pre">jax.stages</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../jax.test_util.html"><code class="docutils literal notranslate"><span class="pre">jax.test_util</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../jax.tree.html"><code class="docutils literal notranslate"><span class="pre">jax.tree</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../jax.tree_util.html"><code class="docutils literal notranslate"><span class="pre">jax.tree_util</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../jax.typing.html"><code class="docutils literal notranslate"><span class="pre">jax.typing</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../jax.export.html"><code class="docutils literal notranslate"><span class="pre">jax.export</span></code> module</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../jax.extend.html"><code class="docutils literal notranslate"><span class="pre">jax.extend</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../jax.extend.core.html"><code class="docutils literal notranslate"><span class="pre">jax.extend.core</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jax.extend.linear_util.html"><code class="docutils literal notranslate"><span class="pre">jax.extend.linear_util</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jax.extend.mlir.html"><code class="docutils literal notranslate"><span class="pre">jax.extend.mlir</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jax.extend.random.html"><code class="docutils literal notranslate"><span class="pre">jax.extend.random</span></code> module</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../jax.example_libraries.html"><code class="docutils literal notranslate"><span class="pre">jax.example_libraries</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../jax.example_libraries.optimizers.html"><code class="docutils literal notranslate"><span class="pre">jax.example_libraries.optimizers</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jax.example_libraries.stax.html"><code class="docutils literal notranslate"><span class="pre">jax.example_libraries.stax</span></code> module</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../jax.experimental.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-20"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../jax.experimental.checkify.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.checkify</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jax.experimental.compilation_cache.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.compilation_cache</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jax.experimental.custom_dce.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.custom_dce</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jax.experimental.custom_partitioning.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.custom_partitioning</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jax.experimental.jet.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.jet</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jax.experimental.key_reuse.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.key_reuse</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jax.experimental.mesh_utils.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.mesh_utils</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jax.experimental.multihost_utils.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.multihost_utils</span></code> module</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../jax.experimental.pallas.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.pallas</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-21"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../jax.experimental.pallas.mosaic_gpu.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.pallas.mosaic_gpu</span></code> module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../jax.experimental.pallas.triton.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.pallas.triton</span></code> module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../jax.experimental.pallas.tpu.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.pallas.tpu</span></code> module</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../jax.experimental.pjit.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.pjit</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jax.experimental.serialize_executable.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.serialize_executable</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../jax.experimental.shard_map.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.shard_map</span></code> module</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../jax.experimental.sparse.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.sparse</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-22"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../_autosummary/jax.experimental.sparse.BCOO.html">jax.experimental.sparse.BCOO</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../_autosummary/jax.experimental.sparse.bcoo_broadcast_in_dim.html">jax.experimental.sparse.bcoo_broadcast_in_dim</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../_autosummary/jax.experimental.sparse.bcoo_concatenate.html">jax.experimental.sparse.bcoo_concatenate</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../_autosummary/jax.experimental.sparse.bcoo_dot_general.html">jax.experimental.sparse.bcoo_dot_general</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../_autosummary/jax.experimental.sparse.bcoo_dot_general_sampled.html">jax.experimental.sparse.bcoo_dot_general_sampled</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../_autosummary/jax.experimental.sparse.bcoo_dynamic_slice.html">jax.experimental.sparse.bcoo_dynamic_slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../_autosummary/jax.experimental.sparse.bcoo_extract.html">jax.experimental.sparse.bcoo_extract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../_autosummary/jax.experimental.sparse.bcoo_fromdense.html">jax.experimental.sparse.bcoo_fromdense</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../_autosummary/jax.experimental.sparse.bcoo_gather.html">jax.experimental.sparse.bcoo_gather</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../_autosummary/jax.experimental.sparse.bcoo_multiply_dense.html">jax.experimental.sparse.bcoo_multiply_dense</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../_autosummary/jax.experimental.sparse.bcoo_multiply_sparse.html">jax.experimental.sparse.bcoo_multiply_sparse</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../_autosummary/jax.experimental.sparse.bcoo_update_layout.html">jax.experimental.sparse.bcoo_update_layout</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../_autosummary/jax.experimental.sparse.bcoo_reduce_sum.html">jax.experimental.sparse.bcoo_reduce_sum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../_autosummary/jax.experimental.sparse.bcoo_reshape.html">jax.experimental.sparse.bcoo_reshape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../_autosummary/jax.experimental.sparse.bcoo_slice.html">jax.experimental.sparse.bcoo_slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../_autosummary/jax.experimental.sparse.bcoo_sort_indices.html">jax.experimental.sparse.bcoo_sort_indices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../_autosummary/jax.experimental.sparse.bcoo_squeeze.html">jax.experimental.sparse.bcoo_squeeze</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../_autosummary/jax.experimental.sparse.bcoo_sum_duplicates.html">jax.experimental.sparse.bcoo_sum_duplicates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../_autosummary/jax.experimental.sparse.bcoo_todense.html">jax.experimental.sparse.bcoo_todense</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../_autosummary/jax.experimental.sparse.bcoo_transpose.html">jax.experimental.sparse.bcoo_transpose</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../jax.lib.html"><code class="docutils literal notranslate"><span class="pre">jax.lib</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.addressable_shards.html">jax.Array.addressable_shards</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.all.html">jax.Array.all</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.any.html">jax.Array.any</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.argmax.html">jax.Array.argmax</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.argmin.html">jax.Array.argmin</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.argpartition.html">jax.Array.argpartition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.argsort.html">jax.Array.argsort</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.astype.html">jax.Array.astype</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.at.html">jax.Array.at</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.choose.html">jax.Array.choose</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.clip.html">jax.Array.clip</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.compress.html">jax.Array.compress</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.committed.html">jax.Array.committed</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.conj.html">jax.Array.conj</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.conjugate.html">jax.Array.conjugate</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.copy.html">jax.Array.copy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.copy_to_host_async.html">jax.Array.copy_to_host_async</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.cumprod.html">jax.Array.cumprod</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.cumsum.html">jax.Array.cumsum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.device.html">jax.Array.device</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.diagonal.html">jax.Array.diagonal</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.dot.html">jax.Array.dot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.dtype.html">jax.Array.dtype</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.flat.html">jax.Array.flat</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.flatten.html">jax.Array.flatten</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.global_shards.html">jax.Array.global_shards</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.imag.html">jax.Array.imag</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.is_fully_addressable.html">jax.Array.is_fully_addressable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.is_fully_replicated.html">jax.Array.is_fully_replicated</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.item.html">jax.Array.item</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.itemsize.html">jax.Array.itemsize</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.max.html">jax.Array.max</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.mean.html">jax.Array.mean</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.min.html">jax.Array.min</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.nbytes.html">jax.Array.nbytes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.ndim.html">jax.Array.ndim</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.nonzero.html">jax.Array.nonzero</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.prod.html">jax.Array.prod</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.ptp.html">jax.Array.ptp</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.ravel.html">jax.Array.ravel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.real.html">jax.Array.real</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.repeat.html">jax.Array.repeat</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.reshape.html">jax.Array.reshape</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.round.html">jax.Array.round</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.searchsorted.html">jax.Array.searchsorted</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.shape.html">jax.Array.shape</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.sharding.html">jax.Array.sharding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.size.html">jax.Array.size</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.sort.html">jax.Array.sort</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.squeeze.html">jax.Array.squeeze</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.std.html">jax.Array.std</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.sum.html">jax.Array.sum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.swapaxes.html">jax.Array.swapaxes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.take.html">jax.Array.take</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.to_device.html">jax.Array.to_device</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.trace.html">jax.Array.trace</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.transpose.html">jax.Array.transpose</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.var.html">jax.Array.var</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.view.html">jax.Array.view</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.T.html">jax.Array.T</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../_autosummary/jax.Array.mT.html">jax.Array.mT</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../about.html">About the project</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../faq.html">Frequently asked questions (FAQ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changelog.html">Change log</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../glossary.html">Glossary of terms</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../config_options.html">Configuration Options</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
        <div class="header-article-item">





<nav aria-label="Breadcrumb">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../advanced_guides.html" class="nav-link">Resources and Advanced Guides</a></li>
    
    
    <li class="breadcrumb-item"><i class="fa-solid fa-ellipsis"></i></li>
    
    
    <li class="breadcrumb-item"><a href="index.html" class="nav-link">Pallas TPU</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Distributed...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/jax-ml/jax" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/pallas/tpu/distributed.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Distributed Computing in Pallas for TPUs</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tpu-topologies">TPU Topologies</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#remote-direct-memory-access-rdma-model">Remote Direct Memory Access (RDMA) Model</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#async-remote-copy-operation">Async Remote Copy Operation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dma-semaphores">DMA Semaphores</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#routing">Routing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#failure-modes">Failure modes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-right-permute-lax-ppermute">Example: Right Permute (<code class="docutils literal notranslate"><span class="pre">lax.ppermute</span></code>)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-all-gather-lax-all-gather">Example: All-gather (<code class="docutils literal notranslate"><span class="pre">lax.all_gather</span></code>)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#ring-communication-pattern">Ring Communication Pattern</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#advanced-techniques">Advanced Techniques</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#synchronization-regular-and-barrier-semaphores">Synchronization: Regular and Barrier Semaphores</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#regular-semaphores">Regular Semaphores</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#barrier-semaphores">Barrier Semaphores</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#double-buffering">Double-buffering</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-all-reduce-sum-lax-psum">Example: All-Reduce Sum (<code class="docutils literal notranslate"><span class="pre">lax.psum</span></code>)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#putting-it-all-together">Putting it all together</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#run-ahead-and-race-conditions">Run-ahead and Race Conditions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bi-directional-communication">Bi-directional Communication</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-bi-directional-reduce-scatter-lax-psum-scatter">Example: Bi-directional Reduce-Scatter (<code class="docutils literal notranslate"><span class="pre">lax.psum_scatter</span></code>)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#nested-remote-and-local-dma-pipelines">Nested Remote and Local DMA Pipelines</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-reduce-scatter-with-large-hbm-blocks">Example: Reduce-Scatter with large HBM blocks</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#final-notes">Final Notes</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#megacore">Megacore</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interaction-with-xla">Interaction with XLA</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#next-steps">Next Steps</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="distributed-computing-in-pallas-for-tpus">
<h1>Distributed Computing in Pallas for TPUs<a class="headerlink" href="#distributed-computing-in-pallas-for-tpus" title="Link to this heading">#</a></h1>
<p>In this tutorial, we will cover the basics of distributed computing in Pallas on TPUs. We will learn about TPU topologies, communication using the remote DMA primitive, and calling a distributed kernel from JAX using <code class="docutils literal notranslate"><span class="pre">jax.shard_map</span></code>. We will also cover some more advanced kernel writing techniques, such as double-buffering, bi-directional bandwidth optimization, and nested pipelining. As educational examples, we will learn how to implement various collective primitives from JAX, such as <code class="docutils literal notranslate"><span class="pre">lax.ppermute</span></code>, <code class="docutils literal notranslate"><span class="pre">lax.all_gather</span></code>, <code class="docutils literal notranslate"><span class="pre">lax.psum</span></code>, and <code class="docutils literal notranslate"><span class="pre">lax.psum_scatter</span></code>.</p>
<p>Some recommended readings beforehand:</p>
<ul class="simple">
<li><p><a class="reference internal" href="pipelining.html#pallas-tpu-pipelining"><span class="std std-ref">Pallas Pipelining on TPU</span></a></p></li>
<li><p><a class="reference internal" href="../../notebooks/shard_map.html#shard-map-collectives-tutorial"><span class="std std-ref">Collectives with <code class="docutils literal notranslate"><span class="pre">jax.shard_map</span></code></span></a></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">functools</span>
<span class="kn">import</span> <span class="nn">jax</span>
<span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">lax</span>
<span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">jnp</span>
<span class="kn">from</span> <span class="nn">jax.experimental</span> <span class="kn">import</span> <span class="n">pallas</span> <span class="k">as</span> <span class="n">pl</span>
<span class="kn">from</span> <span class="nn">jax.experimental.pallas</span> <span class="kn">import</span> <span class="n">tpu</span> <span class="k">as</span> <span class="n">pltpu</span>

<span class="n">P</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">sharding</span><span class="o">.</span><span class="n">PartitionSpec</span>

<span class="n">num_devices</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">local_device_count</span><span class="p">()</span>
<span class="k">assert</span> <span class="n">num_devices</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;Please run this notebook with more than one device.&quot;</span>
<span class="k">assert</span> <span class="s2">&quot;TPU&quot;</span> <span class="ow">in</span> <span class="n">jax</span><span class="o">.</span><span class="n">devices</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device_kind</span><span class="p">,</span> <span class="s2">&quot;Please run this notebook with TPU devices.&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Running with </span><span class="si">{</span><span class="n">num_devices</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">jax</span><span class="o">.</span><span class="n">devices</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device_kind</span><span class="si">}</span><span class="s2"> devices.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Running with 4 TPU v4 devices.
</pre></div>
</div>
</div>
</div>
<section id="tpu-topologies">
<h2>TPU Topologies<a class="headerlink" href="#tpu-topologies" title="Link to this heading">#</a></h2>
<p>TPUs are typically deployed in pods of multiple devices connected via a high-bandwidth interchip interconnect (ICI) for communication within the pod that is much faster than a typical network connection. For example, the specifications sheet for a <a class="reference external" href="https://cloud.google.com/tpu/docs/v5p">TPU v5p</a> states an ICI bandwidth of 4.8Tb/s per chip (for reference, TPU v5p also has 21Tb/s of <em>local</em> HBM bandwidth). The ICI allows us to implement fast and performant distributed kernels that require high-bandwidth communication within a pod, and use the datacenter network for parallelization over less bandwidth-intensive operations, such as data-parallelism over a batch dimension.</p>
<p>TPUs pods are typically arranged in an ND torus topology. The following graphic gives several examples of configurations of different sizes.</p>
<p><img alt="tpu_topologies" src="https://cloud.google.com/static/tpu/docs/images/v4-topologies.png" /></p>
<p>Flattened as a graph, the torus can be visualized as follows. Each edge (orange or black) is a bidirectional connection between two devices. You will commonly hear about rings in conjunction with discussion about device topologies — a key feature of a torus is that when taking a slice along an axis of the pod, such as the nodes <code class="docutils literal notranslate"><span class="pre">[(0,1),</span> <span class="pre">(1,</span> <span class="pre">1),</span> <span class="pre">(2,</span> <span class="pre">1),</span> <span class="pre">(3,</span> <span class="pre">1)]</span></code> or <code class="docutils literal notranslate"><span class="pre">[(0,</span> <span class="pre">1),</span> <span class="pre">(1,</span> <span class="pre">1)]</span></code>, we have a ring of devices. This is a feature we can use to simplify communication patterns within the pod.</p>
<p><img alt="tpu_torus" src="https://cloud.google.com/static/tpu/docs/images/untwisted-tori.png" /></p>
</section>
<section id="remote-direct-memory-access-rdma-model">
<h2>Remote Direct Memory Access (RDMA) Model<a class="headerlink" href="#remote-direct-memory-access-rdma-model" title="Link to this heading">#</a></h2>
<p>TPUs communicate via a push-only model known as a remote direct memory access (RDMA). A TPU is allowed to issue copy instruction to push from a local buffer to any buffer on another device within the same pod that executes asynchronously from the main program thread. However, a TPU can only read data that is stored locally. This is in contrast to more traditional multi-core programming where it is possible to both read from and write to values to a shared memory.</p>
<section id="async-remote-copy-operation">
<h3>Async Remote Copy Operation<a class="headerlink" href="#async-remote-copy-operation" title="Link to this heading">#</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">pltpu.make_async_remote_copy</span></code> function is used to create a remote DMA descriptor object which parameterizes both a “send” operation and a “receive” operation. Here’s its signature:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span> <span class="k">def</span> <span class="nf">make_async_remote_copy</span><span class="p">(</span>
     <span class="n">src_ref</span><span class="p">:</span> <span class="n">Ref</span><span class="p">,</span>
     <span class="n">dst_ref</span><span class="p">:</span> <span class="n">Ref</span><span class="p">,</span>
     <span class="n">send_sem</span><span class="p">:</span> <span class="n">Ref</span><span class="p">[</span><span class="n">SemaphoreType</span><span class="p">],</span>
     <span class="n">recv_sem</span><span class="p">:</span> <span class="n">Ref</span><span class="p">[</span><span class="n">SemaphoreType</span><span class="p">],</span>
     <span class="n">device_id</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
     <span class="n">device_id_type</span><span class="p">:</span> <span class="n">DeviceIdType</span>
 <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AsyncCopyDescriptor</span><span class="p">:</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">src_ref</span></code> is the local <code class="docutils literal notranslate"><span class="pre">Ref</span></code> (in any memory space) containing the data you wish to send to <code class="docutils literal notranslate"><span class="pre">dst_ref</span></code> on another device.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dst_ref</span></code> is the remote <code class="docutils literal notranslate"><span class="pre">Ref</span></code> (in any memory space) at which data will be copied to on the target device.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">send_sem</span></code> is a DMA semaphore used to block until all data has been sent from <code class="docutils literal notranslate"><span class="pre">src_ref</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">recv_sem</span></code> is a DMA semaphore used to block until the expected number of bytes have been received at <code class="docutils literal notranslate"><span class="pre">dst_ref</span></code>. The sender of the DMA will write to the receiver’s <code class="docutils literal notranslate"><span class="pre">recv_sem</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">device_id</span></code> is the device ID of the target device to send to.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">device_id_type</span></code> specifies the format of <code class="docutils literal notranslate"><span class="pre">device_id</span></code>, which can either be in LOGICAL format (integer device ID), or in MESH format (an ND-tuple index into the logical device mesh). The default mode is MESH.</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">make_async_remote_copy</span></code> returns a descriptor object on which you use the <code class="docutils literal notranslate"><span class="pre">.start()</span></code> method to initiate the DMA, and the <code class="docutils literal notranslate"><span class="pre">.wait_send()</span></code> to block on <code class="docutils literal notranslate"><span class="pre">send_sem</span></code> and <code class="docutils literal notranslate"><span class="pre">.wait_recv()</span></code> to block on <code class="docutils literal notranslate"><span class="pre">recv_sem</span></code> (or <code class="docutils literal notranslate"><span class="pre">.wait()</span></code> to block on both). If a device is only expected to send data, it is sufficient to only call <code class="docutils literal notranslate"><span class="pre">.start()</span></code> and <code class="docutils literal notranslate"><span class="pre">.wait_send()</span></code>, and likewise if a device is only receiving it is sufficient to only call <code class="docutils literal notranslate"><span class="pre">.wait_recv()</span></code>. If using a SPMD pattern where all devices execute the DMA, each device will generally call both <code class="docutils literal notranslate"><span class="pre">.start()</span></code> and <code class="docutils literal notranslate"><span class="pre">.wait()</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dma_descriptor</span> <span class="o">=</span> <span class="n">make_async_remote_copy</span><span class="p">(</span><span class="n">src_ref</span><span class="p">,</span> <span class="n">dst_ref</span><span class="p">,</span> <span class="n">send_sem</span><span class="p">,</span> <span class="n">recv_sem</span><span class="p">,</span> <span class="n">device_id</span><span class="p">)</span>
<span class="n">dma_descriptor</span><span class="o">.</span><span class="n">start</span><span class="p">()</span> <span class="c1"># Initiate the DMA (non-blocking).</span>
<span class="c1"># ... do other work</span>
<span class="n">dma_descriptor</span><span class="o">.</span><span class="n">wait_send</span><span class="p">()</span> <span class="c1"># Block until all data has been sent.</span>
<span class="n">dma_descriptor</span><span class="o">.</span><span class="n">wait_recv</span><span class="p">()</span> <span class="c1"># Block until all data has been received.</span>
</pre></div>
</div>
<p>As an example, let’s visualize a DMA where we consider 4 devices (indexed 0, 1, 2, 3). We consider a scheme where device 0 copies to device 1, and device 2 &amp; 3 copy to each other. In practice, we can create such an asymmetric communication pattern by using <code class="docutils literal notranslate"><span class="pre">&#64;pl.when</span></code> to branch on the device ID.</p>
<p>(1) Each device creates the DMA descriptor. Devices 0, 2, and 3 call <code class="docutils literal notranslate"><span class="pre">.start()</span></code> to initiate the DMA from <code class="docutils literal notranslate"><span class="pre">src_ref</span></code>. Device 1 is skips the <code class="docutils literal notranslate"><span class="pre">.start()</span></code> and does nothing, e.g. by using <code class="docutils literal notranslate"><span class="pre">pl.when</span></code>.</p>
<p><img alt="rdma_start" src="../../_images/rdma_start.svg" /></p>
<p>(2) As <code class="docutils literal notranslate"><span class="pre">.start()</span></code> is non-blocking, each device is free to do other computation while the DMA is in flight. Devices 0, 2, and 3 call <code class="docutils literal notranslate"><span class="pre">.wait_send()</span></code> to wait on <code class="docutils literal notranslate"><span class="pre">send_sem</span></code> which blocks until all data has been sent.</p>
<p><img alt="rdma_send" src="../../_images/rdma_send.svg" /></p>
<p>(3) Finally, devices 1, 2, and 3 will call <code class="docutils literal notranslate"><span class="pre">.wait_recv()</span></code> to wait on <code class="docutils literal notranslate"><span class="pre">recv_sem</span></code> until all data has arrived at <code class="docutils literal notranslate"><span class="pre">dst_ref</span></code>.</p>
<p><img alt="rdma_recv" src="../../_images/rdma_recv.svg" /></p>
<p>The above communication pattern can be written as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">example_kernel</span><span class="p">(</span><span class="n">input_ref</span><span class="p">,</span> <span class="n">output_ref</span><span class="p">,</span> <span class="n">send_sem</span><span class="p">,</span> <span class="n">recv_sem</span><span class="p">):</span>
    <span class="n">device_id</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">axis_index</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="n">copy_0_to_1</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">make_async_remote_copy</span><span class="p">(</span>
        <span class="n">src_ref</span><span class="o">=</span><span class="n">input_ref</span><span class="p">,</span>
        <span class="n">dst_ref</span><span class="o">=</span><span class="n">output_ref</span><span class="p">,</span>
        <span class="n">send_sem</span><span class="o">=</span><span class="n">send_sem</span><span class="p">,</span>
        <span class="n">recv_sem</span><span class="o">=</span><span class="n">recv_sem</span><span class="p">,</span>
        <span class="n">device_id</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">copy_2_to_3</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">make_async_remote_copy</span><span class="p">(</span>
        <span class="n">src_ref</span><span class="o">=</span><span class="n">input_ref</span><span class="p">,</span>
        <span class="n">dst_ref</span><span class="o">=</span><span class="n">output_ref</span><span class="p">,</span>
        <span class="n">send_sem</span><span class="o">=</span><span class="n">send_sem</span><span class="p">,</span>
        <span class="n">recv_sem</span><span class="o">=</span><span class="n">recv_sem</span><span class="p">,</span>
        <span class="n">device_id</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">copy_3_to_2</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">make_async_remote_copy</span><span class="p">(</span>
        <span class="n">src_ref</span><span class="o">=</span><span class="n">input_ref</span><span class="p">,</span>
        <span class="n">dst_ref</span><span class="o">=</span><span class="n">output_ref</span><span class="p">,</span>
        <span class="n">send_sem</span><span class="o">=</span><span class="n">send_sem</span><span class="p">,</span>
        <span class="n">recv_sem</span><span class="o">=</span><span class="n">recv_sem</span><span class="p">,</span>
        <span class="n">device_id</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">device_id</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
      <span class="n">copy_0_to_1</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
      <span class="n">copy_0_to_1</span><span class="o">.</span><span class="n">wait_send</span><span class="p">()</span>
    <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">device_id</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
      <span class="n">copy_0_to_1</span><span class="o">.</span><span class="n">wait_recv</span><span class="p">()</span>
    <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">device_id</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
      <span class="n">copy_2_to_3</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
      <span class="n">copy_2_to_3</span><span class="o">.</span><span class="n">wait_send</span><span class="p">()</span>
      <span class="n">copy_3_to_2</span><span class="o">.</span><span class="n">wait_recv</span><span class="p">()</span>
    <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">device_id</span> <span class="o">==</span> <span class="mi">3</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
      <span class="n">copy_3_to_2</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
      <span class="n">copy_3_to_2</span><span class="o">.</span><span class="n">wait_send</span><span class="p">()</span>
      <span class="n">copy_2_to_3</span><span class="o">.</span><span class="n">wait_recv</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="dma-semaphores">
<h3>DMA Semaphores<a class="headerlink" href="#dma-semaphores" title="Link to this heading">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">send_sem</span></code> and <code class="docutils literal notranslate"><span class="pre">recv_sem</span></code> are instances of a special type of semaphore reserved exclusively for use with DMAs. They must be allocated with the <code class="docutils literal notranslate"><span class="pre">tpu.SemaphoreType.DMA</span></code> type when specifying input specs to <code class="docutils literal notranslate"><span class="pre">pallas_call</span></code>.</p>
<p>Internally, DMA semaphores can be thought of as integer-valued progress trackers. On DMA start, the local device will begin to increment the value of <code class="docutils literal notranslate"><span class="pre">send_sem</span></code> and the receiver’s <code class="docutils literal notranslate"><span class="pre">recv_sem</span></code> asynchronously. Waiting on a semaphore will block until the value of the semaphore reaches the total bytes of data sent/received; when the value is reached, waiting threads are released and the semaphore’s value is decremented by the same amount. This means that either all data has been sent (for <code class="docutils literal notranslate"><span class="pre">send_sem</span></code>) or all data has been received (for <code class="docutils literal notranslate"><span class="pre">recv_sem</span></code>). The value of the semaphore can be read with <code class="docutils literal notranslate"><span class="pre">pl.semaphore_read</span></code>, but note that the underlying semantics of the value could change between hardware generations (e.g. the value may not represent exactly the number of bytes sent, although this is a useful mental model to have when reasoning about the behavior of the semaphore).</p>
</section>
<section id="routing">
<h3>Routing<a class="headerlink" href="#routing" title="Link to this heading">#</a></h3>
<p>A sender is allowed to send data to any receiver within the same pod, even if they do not share a direct connection (the exception to this rule is for TPU v5e, where devices can only route to a power of 2 offset from themselves). TPUs have an internal routing mechanism which can pass data along to the next device on the path to the destination. However, communicating in this way is not recommended as you have no control over network contention as a kernel writer. The examples we will cover in this tutorial minimize inefficient communication by only transferring data to neighboring devices.</p>
</section>
<section id="failure-modes">
<h3>Failure modes<a class="headerlink" href="#failure-modes" title="Link to this heading">#</a></h3>
<p>If using remote DMAs incorrectly, you may encounter several failure modes which can be difficult to debug. The general symptoms of buggy DMA usage are crashes, hanging, or silent data corruption:</p>
<ul class="simple">
<li><p>If semaphores exit the program with an invalid non-zero value, Pallas will crash and exit the program.</p></li>
<li><p>If semaphores are waited on but an insufficient number of bytes are received (i.e. there is no sender, or if the sent data is less than the size of <code class="docutils literal notranslate"><span class="pre">dst_ref</span></code> on the receiving device), the program may hang indefinitely waiting for bytes that are never sent. In this case the program would need to be restarted.</p></li>
<li><p>If encountering a race condition, there could be silent data corruption if two simultaneous writes or a simultaneous read and write occur.</p></li>
</ul>
<p>Some common causes of the above include:</p>
<ul class="simple">
<li><p>If a device calls <code class="docutils literal notranslate"><span class="pre">.wait_recv()</span></code> but no other device sends to it, the kernel may hang.</p></li>
<li><p>If a device is sent a more bytes than it expected to receive, it may also crash due to non-zero semaphore states. If sent less, it may hang indefinitely.</p></li>
<li><p>If DMAs are started but the semaphores are not waited on, the program may crash due to non-zero semaphore states.</p></li>
<li><p>If two devices copy to the same destination, you may encounter non-deterministic results due to a race condition, or crashing due to  non-zero semaphore states.</p></li>
</ul>
</section>
<section id="example-right-permute-lax-ppermute">
<h3>Example: Right Permute (<code class="docutils literal notranslate"><span class="pre">lax.ppermute</span></code>)<a class="headerlink" href="#example-right-permute-lax-ppermute" title="Link to this heading">#</a></h3>
<p>Let’s dive into a very basic example. We will implement a kernel that performs a right permutation, where each device sends its slice of the data to its right neighbor.</p>
<p>Suppose we had an array with 512 elements, which we shard into slices of size 128 across 4 devices. Each device will pass its slice to the next device, and the output will consist of the same data, but with the slices rotated by 1. This is identical to the <code class="docutils literal notranslate"><span class="pre">lax.ppermute</span></code> operation where the permutation is set to <code class="docutils literal notranslate"><span class="pre">(n,</span> <span class="pre">(n+1)</span> <span class="pre">%</span> <span class="pre">4)</span></code>.</p>
<p>In order to call the kernel in distributed mode, we wrap the <code class="docutils literal notranslate"><span class="pre">pallas_call</span></code> in a <code class="docutils literal notranslate"><span class="pre">shard_map</span></code> transformation. From there, we can write the kernel the same way as you would write a normal single-device Pallas kernel, except we now have access to remote DMA instructions. JAX collective primitives such as <code class="docutils literal notranslate"><span class="pre">lax.axis_index</span></code> can be used to obtain a <code class="docutils literal notranslate"><span class="pre">device_id</span></code> that can be used to compute which target devices to copy to, by referencing the same named axes names passed into <code class="docutils literal notranslate"><span class="pre">shard_map</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">partition</span> <span class="o">=</span> <span class="n">P</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">mesh</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">make_mesh</span><span class="p">((</span><span class="n">num_devices</span><span class="p">,),</span> <span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,))</span>
<span class="n">sharding</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">sharding</span><span class="o">.</span><span class="n">NamedSharding</span><span class="p">(</span><span class="n">mesh</span><span class="p">,</span> <span class="n">partition</span><span class="p">)</span>

<span class="c1"># Create an input array that shards the last dimension across</span>
<span class="c1"># all devices.</span>
<span class="n">input_arr</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">key</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">128</span> <span class="o">*</span> <span class="n">num_devices</span><span class="p">))</span>
<span class="n">input_arr</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">device_put</span><span class="p">(</span><span class="n">input_arr</span><span class="p">,</span> <span class="n">sharding</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">right_permute_kernel</span><span class="p">(</span><span class="n">input_ref</span><span class="p">,</span> <span class="n">output_ref</span><span class="p">,</span> <span class="n">send_sem</span><span class="p">,</span> <span class="n">recv_sem</span><span class="p">):</span>
  <span class="n">my_id</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">axis_index</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
  <span class="n">right_neighbor</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">rem</span><span class="p">(</span><span class="n">my_id</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">)</span>
  <span class="n">remote_copy_op</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">make_async_remote_copy</span><span class="p">(</span>
      <span class="n">src_ref</span><span class="o">=</span><span class="n">input_ref</span><span class="p">,</span>
      <span class="n">dst_ref</span><span class="o">=</span><span class="n">output_ref</span><span class="p">,</span>
      <span class="n">send_sem</span><span class="o">=</span><span class="n">send_sem</span><span class="p">,</span>
      <span class="n">recv_sem</span><span class="o">=</span><span class="n">recv_sem</span><span class="p">,</span>
      <span class="n">device_id</span><span class="o">=</span><span class="p">(</span><span class="n">right_neighbor</span><span class="p">,),</span>
      <span class="n">device_id_type</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">DeviceIdType</span><span class="o">.</span><span class="n">MESH</span><span class="p">,</span>
  <span class="p">)</span>
  <span class="n">remote_copy_op</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
  <span class="n">remote_copy_op</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>


<span class="n">out_shape</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">ShapeDtypeStruct</span><span class="p">((</span><span class="mi">8</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">grid_spec</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">PrefetchScalarGridSpec</span><span class="p">(</span>
    <span class="n">num_scalar_prefetch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="c1"># MemorySpace.ANY will (usually) place the tensor in HBM.</span>
    <span class="n">in_specs</span><span class="o">=</span><span class="p">[</span>
        <span class="n">pl</span><span class="o">.</span><span class="n">BlockSpec</span><span class="p">(</span><span class="n">memory_space</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">MemorySpace</span><span class="o">.</span><span class="n">ANY</span><span class="p">),</span>
    <span class="p">],</span>
    <span class="n">out_specs</span><span class="o">=</span><span class="n">pl</span><span class="o">.</span><span class="n">BlockSpec</span><span class="p">(</span><span class="n">memory_space</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">MemorySpace</span><span class="o">.</span><span class="n">ANY</span><span class="p">),</span>
    <span class="n">scratch_shapes</span><span class="o">=</span><span class="p">(</span>
        <span class="c1"># We allocate DMA semaphores in scratch memory.</span>
        <span class="p">[</span><span class="n">pltpu</span><span class="o">.</span><span class="n">SemaphoreType</span><span class="o">.</span><span class="n">DMA</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span>
    <span class="p">),</span>
<span class="p">)</span>
<span class="n">right_permute</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">pallas_call</span><span class="p">(</span>
    <span class="n">right_permute_kernel</span><span class="p">,</span>
    <span class="n">out_shape</span><span class="o">=</span><span class="n">out_shape</span><span class="p">,</span>
    <span class="n">grid_spec</span><span class="o">=</span><span class="n">grid_spec</span><span class="p">,</span>
<span class="p">)</span>
<span class="c1"># Wrap the kernel within a shard_map to call.</span>
<span class="n">pallas_result</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span>
    <span class="n">jax</span><span class="o">.</span><span class="n">shard_map</span><span class="p">(</span>
        <span class="n">right_permute</span><span class="p">,</span>
        <span class="n">mesh</span><span class="o">=</span><span class="n">mesh</span><span class="p">,</span>
        <span class="n">in_specs</span><span class="o">=</span><span class="n">partition</span><span class="p">,</span>
        <span class="n">out_specs</span><span class="o">=</span><span class="n">partition</span><span class="p">,</span>
        <span class="n">check_vma</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)(</span><span class="n">input_arr</span><span class="p">)</span>

<span class="c1"># Compare Pallas result to XLA shard_map result.</span>
<span class="n">perm</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">((</span><span class="n">src</span><span class="p">,</span> <span class="p">(</span><span class="n">src</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">num_devices</span><span class="p">)</span> <span class="k">for</span> <span class="n">src</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_devices</span><span class="p">))</span>

<span class="n">xla_result</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span>
    <span class="n">jax</span><span class="o">.</span><span class="n">shard_map</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">lax</span><span class="o">.</span><span class="n">ppermute</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">perm</span><span class="p">),</span>
        <span class="n">mesh</span><span class="o">=</span><span class="n">mesh</span><span class="p">,</span> <span class="n">in_specs</span><span class="o">=</span><span class="n">partition</span><span class="p">,</span> <span class="n">out_specs</span><span class="o">=</span><span class="n">partition</span><span class="p">)</span>
<span class="p">)(</span><span class="n">input_arr</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Input = &#39;</span><span class="p">,</span> <span class="n">input_arr</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">::</span><span class="mi">128</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Pallas Result = &#39;</span><span class="p">,</span> <span class="n">pallas_result</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">::</span><span class="mi">128</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;lax.ppermute Result = &#39;</span><span class="p">,</span> <span class="n">xla_result</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">::</span><span class="mi">128</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s1">&#39;Difference |Pallas - lax.ppermute| = &#39;</span><span class="p">,</span>
    <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">pallas_result</span> <span class="o">-</span> <span class="n">xla_result</span><span class="p">)),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Input =  [0.9858954  0.11763906 0.9955574  0.775211  ]
Pallas Result =  [0.775211   0.9858954  0.11763906 0.9955574 ]
lax.ppermute Result =  [0.775211   0.9858954  0.11763906 0.9955574 ]
Difference |Pallas - lax.ppermute| =  0.0
</pre></div>
</div>
</div>
</div>
</section>
<section id="example-all-gather-lax-all-gather">
<h3>Example: All-gather (<code class="docutils literal notranslate"><span class="pre">lax.all_gather</span></code>)<a class="headerlink" href="#example-all-gather-lax-all-gather" title="Link to this heading">#</a></h3>
<p>In this next example we will implement the all-gather collective operation, which has a JAX equivalent in <code class="docutils literal notranslate"><span class="pre">lax.all_gather</span></code>. In contrast with the right-permute example from above which only involves a pair of source and destination neighbors, an all-gather operation requires communication between all devices and therefore we must think about how data is routed between them. The specifics of how we implement this are dictated by the device topology, for which we assume is a ring.</p>
<section id="ring-communication-pattern">
<h4>Ring Communication Pattern<a class="headerlink" href="#ring-communication-pattern" title="Link to this heading">#</a></h4>
<p>We will write our kernel assuming a ring topology. Rings are a natural fit for TPUs as slicing along any dimension of a torus produces a ring. When writing collectives, we often only need to think about 1D slices of our torus at a time because the different dimensions of the torus are reserved for different types of parallelism (data vs. model, for example).</p>
<p>The strategy we will use is to write a looped kernel, where on each iteration a device receives one slice of the sharded array from its left neighbor, and copies the previously received slice to its right neighbor. After <code class="docutils literal notranslate"><span class="pre">num_devices</span></code> iterations, each device will have a copy of the entire array in its local HBM.</p>
<p><img alt="all_gather" src="../../_images/all_gather.svg" /></p>
<p>We can re-purpose Pallas’s <code class="docutils literal notranslate"><span class="pre">grid</span></code> argument to implement the loop. Rather than iterating over tiles of an array as we have done in previous tutorials, we instead set the grid to <code class="docutils literal notranslate"><span class="pre">(num_devices,)</span></code> to indicate that we want to loop over the number of devices and use <code class="docutils literal notranslate"><span class="pre">pl.program_id</span></code> to obtain the loop iteration inside of the Pallas kernel. The following code snippet demonstrates how to implement this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">partition</span> <span class="o">=</span> <span class="n">P</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="n">mesh</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">make_mesh</span><span class="p">((</span><span class="n">num_devices</span><span class="p">,),</span> <span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,))</span>
<span class="n">sharding</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">sharding</span><span class="o">.</span><span class="n">NamedSharding</span><span class="p">(</span><span class="n">mesh</span><span class="p">,</span> <span class="n">partition</span><span class="p">)</span>

<span class="c1"># Create an input array that shards the first dimension across</span>
<span class="c1"># all devices.</span>
<span class="n">input_arr</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">key</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">8</span> <span class="o">*</span> <span class="n">num_devices</span><span class="p">,</span> <span class="mi">128</span><span class="p">))</span>
<span class="n">input_arr</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">device_put</span><span class="p">(</span><span class="n">input_arr</span><span class="p">,</span> <span class="n">sharding</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">all_gather_kernel</span><span class="p">(</span><span class="n">input_ref</span><span class="p">,</span>
                      <span class="n">output_ref</span><span class="p">,</span>
                      <span class="n">local_copy_sem</span><span class="p">,</span>
                      <span class="n">send_sem</span><span class="p">,</span>
                      <span class="n">recv_sems</span><span class="p">):</span>
  <span class="n">outer_step</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">program_id</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">my_id</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">axis_index</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
  <span class="n">right_neighbor</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">rem</span><span class="p">(</span><span class="n">my_id</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">)</span>
  <span class="n">copy_slot</span> <span class="o">=</span> <span class="n">my_id</span> <span class="o">-</span> <span class="n">outer_step</span>
  <span class="n">copy_slot</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">rem</span><span class="p">(</span><span class="n">copy_slot</span> <span class="o">+</span> <span class="n">num_devices</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">)</span>

  <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">outer_step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
    <span class="n">local_copy_op</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">make_async_copy</span><span class="p">(</span>
      <span class="n">src_ref</span><span class="o">=</span><span class="n">input_ref</span><span class="p">,</span>
      <span class="n">dst_ref</span><span class="o">=</span><span class="n">output_ref</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">my_id</span><span class="p">],</span>
      <span class="n">sem</span><span class="o">=</span><span class="n">local_copy_sem</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">local_copy_op</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
    <span class="n">local_copy_op</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

  <span class="c1"># Copy to our right neighbor.</span>
  <span class="c1"># Note that we will also be receiving data from our left neighbor,</span>
  <span class="c1"># but at `copy_slot-1` rather than `copy_slot`! This makes use of the fact</span>
  <span class="c1"># that the indices do not need to be symmetric between remote DMAs.</span>
  <span class="n">remote_copy_op</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">make_async_remote_copy</span><span class="p">(</span>
      <span class="n">src_ref</span><span class="o">=</span><span class="n">output_ref</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">copy_slot</span><span class="p">],</span>
      <span class="n">dst_ref</span><span class="o">=</span><span class="n">output_ref</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">copy_slot</span><span class="p">],</span>
      <span class="n">send_sem</span><span class="o">=</span><span class="n">send_sem</span><span class="p">,</span>
      <span class="n">recv_sem</span><span class="o">=</span><span class="n">recv_sems</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">outer_step</span><span class="p">],</span>
      <span class="n">device_id</span><span class="o">=</span><span class="p">(</span><span class="n">right_neighbor</span><span class="p">,),</span>
      <span class="n">device_id_type</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">DeviceIdType</span><span class="o">.</span><span class="n">MESH</span><span class="p">,</span>
  <span class="p">)</span>
  <span class="n">remote_copy_op</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
  <span class="n">remote_copy_op</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

<span class="n">out_shape</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">ShapeDtypeStruct</span><span class="p">((</span><span class="n">num_devices</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">grid_spec</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">PrefetchScalarGridSpec</span><span class="p">(</span>
            <span class="n">num_scalar_prefetch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">in_specs</span><span class="o">=</span><span class="p">[</span>
                <span class="c1"># MemorySpace.ANY will (usually) place the tensor in HBM.</span>
                <span class="n">pl</span><span class="o">.</span><span class="n">BlockSpec</span><span class="p">(</span><span class="n">memory_space</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">MemorySpace</span><span class="o">.</span><span class="n">ANY</span><span class="p">),</span>
            <span class="p">],</span>
            <span class="n">out_specs</span><span class="o">=</span><span class="n">pl</span><span class="o">.</span><span class="n">BlockSpec</span><span class="p">(</span><span class="n">memory_space</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">MemorySpace</span><span class="o">.</span><span class="n">ANY</span><span class="p">),</span>
            <span class="n">scratch_shapes</span><span class="o">=</span><span class="p">(</span>
              <span class="c1"># DMA semaphores are allocated in scratch memory.</span>
              <span class="c1"># We allocated one semaphore for a local HBM-VMEM copy,</span>
              <span class="c1"># and one for the remote send semaphore.</span>
              <span class="p">[</span><span class="n">pltpu</span><span class="o">.</span><span class="n">SemaphoreType</span><span class="o">.</span><span class="n">DMA</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span>
              <span class="c1"># We additionally allocate one receive semaphore per device.</span>
              <span class="c1"># This is to avoid situations where we have multiple</span>
              <span class="c1"># DMAs in flight, as we do not want to share a receive</span>
              <span class="c1"># semaphore between the DMAs.</span>
              <span class="o">+</span> <span class="p">[</span><span class="n">pltpu</span><span class="o">.</span><span class="n">SemaphoreType</span><span class="o">.</span><span class="n">DMA</span><span class="p">((</span><span class="n">num_devices</span><span class="o">-</span><span class="mi">1</span><span class="p">,))]</span>

            <span class="p">),</span>
            <span class="n">grid</span><span class="o">=</span><span class="p">(</span><span class="n">num_devices</span><span class="o">-</span><span class="mi">1</span><span class="p">,)</span>
        <span class="p">)</span>

<span class="n">all_gather</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">pallas_call</span><span class="p">(</span>
      <span class="n">all_gather_kernel</span><span class="p">,</span>
      <span class="n">out_shape</span><span class="o">=</span><span class="n">out_shape</span><span class="p">,</span>
      <span class="n">grid_spec</span><span class="o">=</span><span class="n">grid_spec</span><span class="p">,</span>
  <span class="p">)</span>

<span class="c1"># Wrap the kernel within a shard_map to call.</span>
<span class="n">pallas_result</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span>
      <span class="n">jax</span><span class="o">.</span><span class="n">shard_map</span><span class="p">(</span>
          <span class="n">all_gather</span><span class="p">,</span>
          <span class="n">mesh</span><span class="o">=</span><span class="n">mesh</span><span class="p">,</span>
          <span class="n">in_specs</span><span class="o">=</span><span class="n">partition</span><span class="p">,</span>
          <span class="n">out_specs</span><span class="o">=</span><span class="n">partition</span><span class="p">,</span>
          <span class="n">check_vma</span><span class="o">=</span><span class="kc">False</span>
      <span class="p">)</span>
<span class="p">)(</span><span class="n">input_arr</span><span class="p">)</span>

<span class="c1"># Compare Pallas result to XLA shard_map result.</span>
<span class="n">xla_result</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span>
    <span class="n">jax</span><span class="o">.</span><span class="n">shard_map</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">lax</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;x&#39;</span><span class="p">),</span>
        <span class="n">mesh</span><span class="o">=</span><span class="n">mesh</span><span class="p">,</span> <span class="n">in_specs</span><span class="o">=</span><span class="n">partition</span><span class="p">,</span> <span class="n">out_specs</span><span class="o">=</span><span class="n">partition</span>
    <span class="p">)</span>
<span class="p">)(</span><span class="n">input_arr</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Input: &#39;</span><span class="p">,</span> <span class="n">input_arr</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">input_arr</span><span class="p">[::</span><span class="mi">8</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Pallas Result: &#39;</span><span class="p">,</span> <span class="n">pallas_result</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">pallas_result</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;lax.all_gather Result: &#39;</span><span class="p">,</span> <span class="n">xla_result</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">xla_result</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Difference |Pallas - lax.all_gather| = &#39;</span><span class="p">,</span>
      <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">pallas_result</span> <span class="o">-</span> <span class="n">xla_result</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Input:  (32, 128) [0.9858954  0.54248166 0.9547038  0.954962  ]
Pallas Result:  (16, 8, 128) [0.9858954  0.54248166 0.9547038  0.954962   0.9858954  0.54248166
 0.9547038  0.954962   0.9858954  0.54248166 0.9547038  0.954962
 0.9858954  0.54248166 0.9547038  0.954962  ]
lax.all_gather Result:  (16, 8, 128) [0.9858954  0.54248166 0.9547038  0.954962   0.9858954  0.54248166
 0.9547038  0.954962   0.9858954  0.54248166 0.9547038  0.954962
 0.9858954  0.54248166 0.9547038  0.954962  ]
Difference |Pallas - lax.all_gather| =  0.0
</pre></div>
</div>
</div>
</div>
<p>A detail worth mentioning here is the use of multiple receive semaphores. Because we only block on the receiving device, it is still possible for a sender to have sent multiple DMAs in flight before the receiver has finished processing the first one (see the next section and reduce-sum example which discusses race conditions in more detail). In this situation we may hit a situation where the same semaphore is being used for multiple DMAs occurring simultaneously. To avoid this, we allocate <code class="docutils literal notranslate"><span class="pre">num_devices-1</span></code> semaphores so there is no risk of reuse. While this race condition is unlikely to happen on such a small kernel, on larger kernels there is more chance for devices to fall out of sync and potentially cause a silent failure.</p>
</section>
</section>
</section>
<section id="advanced-techniques">
<h2>Advanced Techniques<a class="headerlink" href="#advanced-techniques" title="Link to this heading">#</a></h2>
<p>Now that we have seen how to write several basic kernels using remote DMA operations, we will go over more advanced techniques for synchronization and writing efficient kernels.</p>
<section id="synchronization-regular-and-barrier-semaphores">
<h3>Synchronization: Regular and Barrier Semaphores<a class="headerlink" href="#synchronization-regular-and-barrier-semaphores" title="Link to this heading">#</a></h3>
<p>The examples we implemented in the basic tutorial do not require special handling of synchronization as all necessary communication writes to disjoint buffers. However, other operations may require more complex communication patterns that need additional synchronization primitives to avoid race conditions. Pallas provides two additional primitives to help with this: regular and barrier semaphores.</p>
<section id="regular-semaphores">
<h4>Regular Semaphores<a class="headerlink" href="#regular-semaphores" title="Link to this heading">#</a></h4>
<p>Regular semaphores are the standard tool used to synchronize across multiple devices. Semaphores are fundamentally counters - they can be incremented by any device after which a device can block until the value of the semaphore reaches a specific value (and then decrement the value).</p>
<p>The three main operations that can be used on regular semaphores are signal, wait, and read:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">semaphore_signal</span><span class="p">(</span>
    <span class="n">sem</span><span class="p">:</span> <span class="n">Ref</span><span class="p">[</span><span class="n">SemaphoreType</span><span class="p">],</span>
    <span class="n">inc</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">device_id</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
    <span class="n">device_id_type</span><span class="p">:</span> <span class="n">DeviceIdType</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
  <span class="o">...</span> <span class="c1"># Increments the semaphore `sem` on the target device `device_id` by `inc`.</span>
  
<span class="k">def</span> <span class="nf">semaphore_wait</span><span class="p">(</span>
    <span class="n">semaphore</span><span class="p">:</span> <span class="n">Ref</span><span class="p">[</span><span class="n">SemaphoreType</span><span class="p">],</span>
    <span class="n">value</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
  <span class="o">...</span> <span class="c1"># Blocks until the locally allocated copy of `sem` reaches `value`, then decrement by `value` and proceed.</span>
    
<span class="k">def</span> <span class="nf">semaphore_read</span><span class="p">(</span>
    <span class="n">sem</span><span class="p">:</span> <span class="n">Ref</span><span class="p">[</span><span class="n">SemaphoreType</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">jax</span><span class="o">.</span><span class="n">Array</span><span class="p">:</span>
  <span class="o">...</span>  <span class="c1"># Returns the current value of `sem` as an `int32[]`.</span>
</pre></div>
</div>
<p>In order to use regular semaphores, they can be allocated in the same way as a DMA semaphore, but by specifying <code class="docutils literal notranslate"><span class="pre">pltpu.SemaphoreType.REGULAR</span></code> rather than <code class="docutils literal notranslate"><span class="pre">pltpu.SemaphoreType.DMA</span></code>.</p>
<p>Semaphores must be zero at the end of a Pallas program to complete successfully. There are two error cases where this may happen:</p>
<ul class="simple">
<li><p>If a semaphore is over-signaled, the program will end with non-zero (&gt;0) semaphores. In this case, the program will crash upon completion. This is useful for debugging as non-zero semaphores typically means there is a bug somewhere inside of the program.</p></li>
<li><p>If a semaphore is over-waited, the program will hang on the blocking <code class="docutils literal notranslate"><span class="pre">semaphore_wait</span></code> call while it waits for the semaphore to be incremented. In this case the device or program will need to be restarted.</p></li>
</ul>
</section>
<section id="barrier-semaphores">
<h4>Barrier Semaphores<a class="headerlink" href="#barrier-semaphores" title="Link to this heading">#</a></h4>
<p>Barrier semaphores are globally-allocated semaphores used to synchronize devices across an entire program and ensure that all devices have entered the Pallas kernel.</p>
<p>If a Pallas kernel is executed within the context of a larger XLA program, we need to ensure that all devices that communicate have entered the kernel. However, DMA and regular semaphores are both locally scoped - they are only understood by other devices that have entered the kernel. Barrier semaphores serve as a globally understood semaphore that can be used for synchronization no matter where in the XLA program the device is currently executing.</p>
<p>By default, if you do not specify a barrier semaphore, Pallas will automatically insert a barrier semaphore at the beginning of your program. However, it can be more efficient to write your own. Barrier semaphores are similar to regular semaphores in that they are counters that can be incremented via <code class="docutils literal notranslate"><span class="pre">semaphore_signal</span></code> and can be decremented via <code class="docutils literal notranslate"><span class="pre">semaphore_wait</span></code>. They are created by calling <code class="docutils literal notranslate"><span class="pre">get_barrier_semaphore()</span></code> within a kernel. Typically, we use barriers once at the beginning of a kernel to synchronize with all devices we are communicating with.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">jax.experimental.pallas</span> <span class="kn">import</span> <span class="n">tpu</span> <span class="k">as</span> <span class="n">pltpu</span>

<span class="k">def</span> <span class="nf">example_kernel</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
  <span class="c1"># Use barrier semaphores at the beginning of a kernel.</span>
  <span class="c1"># is_start_of_kernel = ...</span>
  <span class="c1"># right_neighbor = ...</span>
  <span class="c1"># ...</span>
  <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">is_start_of_kernel</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
    <span class="n">barrier_sem</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">get_barrier_semaphore</span><span class="p">()</span>
    <span class="c1"># Increment the semaphore of your right neighbor.</span>
    <span class="n">pltpu</span><span class="o">.</span><span class="n">semaphore_signal</span><span class="p">(</span>
          <span class="n">barrier_sem</span><span class="p">,</span>
          <span class="n">device_id</span><span class="o">=</span><span class="n">right_neighbor</span><span class="p">,</span>
          <span class="n">device_id_type</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">DeviceIdType</span><span class="o">.</span><span class="n">LOGICAL</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="c1"># Wait until your left neighbor has incremented your semaphore</span>
    <span class="n">pltpu</span><span class="o">.</span><span class="n">semaphore_wait</span><span class="p">(</span><span class="n">barrier_sem</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
  <span class="c1"># ...</span>
</pre></div>
</div>
<p>When using barrier semaphores, the <code class="docutils literal notranslate"><span class="pre">collective_id</span></code> compiler parameter must be passed to <code class="docutils literal notranslate"><span class="pre">pallas_call</span></code> to specify which barrier semaphore is being used. A TPU has a small, fixed number of barrier semaphores available (typically on the order of 20-30) and therefore they should be used sparingly. In order to ensure correctness, only kernels that share the same communication pattern should use the same <code class="docutils literal notranslate"><span class="pre">collective_id</span></code>. For example, if two kernels synchronize only with neighbors on the same mesh axis, they are allowed to share the same <code class="docutils literal notranslate"><span class="pre">collective_id</span></code>. However, if two kernels synchronize along different axes, they must have different <code class="docutils literal notranslate"><span class="pre">collective_id</span></code>s. Failure to do so may result in race conditions that are difficult to debug.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">kernel</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">pallas_call</span><span class="p">(</span>
      <span class="n">example_kernel</span><span class="p">,</span>
      <span class="o">...</span><span class="p">,</span>
      <span class="n">compiler_params</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">CompilerParams</span><span class="p">(</span><span class="n">collective_id</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="double-buffering">
<h3>Double-buffering<a class="headerlink" href="#double-buffering" title="Link to this heading">#</a></h3>
<p>In order to avoid reading from a local <code class="docutils literal notranslate"><span class="pre">Ref</span></code> that is also being written into by another device and creating a race condition, a useful technique is the “double-buffered” strategy where we allocate a two <code class="docutils literal notranslate"><span class="pre">Ref</span></code>s for each destination value. On each iteration, one <code class="docutils literal notranslate"><span class="pre">Ref</span></code> will be designated as a “working” slot, and the other will be designated as a “receiving” slot. The device is free to use the working slot for computation, but will only copy data into its neighbor’s receiving slot. The working and receiving slots alternate every iteration, so that once a copy is finished, the old receiving slot becomes the new working slot, and vice versa. Using this scheme properly, data is never read from and written to the same buffer.</p>
<p>The following code skeleton demonstrates how double-buffering can be used. We keep a running iteration counter in the variable <code class="docutils literal notranslate"><span class="pre">iteration</span></code>, and the <code class="docutils literal notranslate"><span class="pre">working_slot</span></code> and <code class="docutils literal notranslate"><span class="pre">receiving_slot</span></code> alternate between 0 and 1 every iteration. <code class="docutils literal notranslate"><span class="pre">dst_ref</span></code> is allocated as a double-buffer and has the size <code class="docutils literal notranslate"><span class="pre">[2,</span> <span class="pre">...]</span></code>. On each iteration, we read from the working slot using <code class="docutils literal notranslate"><span class="pre">dst_ref.at[working_slot,</span> <span class="pre">...]</span></code> and use the value to perform computation. Simultaneously, we copy to our neighbor’s <code class="docutils literal notranslate"><span class="pre">dst_ref.at[receiving_slot]</span></code> to avoid overwriting their <code class="docutils literal notranslate"><span class="pre">working_slot</span></code> value. By structuring our communication in this fashion it is possible to overlap the communication latency of the remote DMA with local computation while minimizing the risk of race conditions.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">kernel</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
  <span class="c1"># ...</span>
  <span class="n">iteration</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">program_id</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">working_slot</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">rem</span><span class="p">(</span><span class="n">iteration</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
  <span class="n">receiving_slot</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">working_slot</span>
  <span class="c1"># ...</span>

  <span class="n">local_copy_op</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">make_async_copy</span><span class="p">(</span>
    <span class="n">src_ref</span><span class="o">=</span><span class="n">dst_ref</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">working_slot</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
    <span class="n">dst_ref</span><span class="o">=</span><span class="n">local_scratch_ref</span><span class="p">,</span>
    <span class="n">sem</span><span class="o">=</span><span class="n">local_copy_sem</span><span class="p">,</span>
  <span class="p">)</span>
  <span class="n">local_copy_op</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
  <span class="n">remote_copy_op</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">make_async_remote_copy</span><span class="p">(</span>
    <span class="n">src_ref</span><span class="o">=</span><span class="n">src_ref</span><span class="p">,</span>
    <span class="n">dst_ref</span><span class="o">=</span><span class="n">dst_ref</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">receiving_slot</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
    <span class="n">send_sem</span><span class="o">=</span><span class="n">send_sem</span><span class="p">,</span>
    <span class="n">recv_sem</span><span class="o">=</span><span class="n">recv_sem</span><span class="p">,</span>
    <span class="n">device_id</span><span class="o">=</span><span class="n">target_device</span><span class="p">,</span>
    <span class="n">device_id_type</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">DeviceIdType</span><span class="o">.</span><span class="n">MESH</span><span class="p">,</span>
  <span class="p">)</span>
  <span class="n">remote_copy_op</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
  
  <span class="n">local_copy_op</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
  <span class="c1"># ... do work on local_scratch while waiting for async_copy_op to finish.</span>
  <span class="n">remote_copy_op</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

</pre></div>
</div>
<p>In terms of synchronization, the double-buffered construction works if all devices are executing on the same iteration. If a sender manages to get one iteration ahead of its receiver, it’s <code class="docutils literal notranslate"><span class="pre">working_slot</span></code> and <code class="docutils literal notranslate"><span class="pre">receiving_slot</span></code> indices will be flipped compared to the receiver, meaning that it could be writing into the <code class="docutils literal notranslate"><span class="pre">working_slot</span></code> at the same time the receiver is reading from it. In order to avoid this, it may be necessary to use a semaphore to synchronize the sender with the receiver, or add additional buffering slots (“triple”, “quadruple”, or N-buffered) to allow additional run-ahead at the cost of more memory. In our previous <code class="docutils literal notranslate"><span class="pre">all_gather</span></code> example, note that the kernel contained a receiving buffer with N slots, which avoids race conditions altogether. In our next kernel, we will instead go through an example which uses a double-buffer with explicit synchronization.</p>
</section>
<section id="example-all-reduce-sum-lax-psum">
<h3>Example: All-Reduce Sum (<code class="docutils literal notranslate"><span class="pre">lax.psum</span></code>)<a class="headerlink" href="#example-all-reduce-sum-lax-psum" title="Link to this heading">#</a></h3>
<p>We will now implement an all-reduce sum kernel using double-buffering and semaphores for synchronization. For those familiar with collective operations in JAX, the equivalent operation is <code class="docutils literal notranslate"><span class="pre">lax.psum</span></code>. All-reduce is a standard collective operation where the objective is to reduce along an axis of an array, but the array is sharded across multiple devices.</p>
<p><img alt="reduce_sum_1" src="../../_images/reduce_sum_1.svg" /></p>
<p>In the above example, we have the array [5, 2, 1, 3] sharded across 4 devices. An all-reduce sum operation would sum all values and replicate the result on each device, leading to the result [11, 11, 11, 11] sharded across all 4 devices.</p>
<p>The naive implementation of all-reduce would be to gather all required values onto each device, and then reduce. However, we can improve the performance of this implementation by interleaving communication with computation. An interleaved, single-direction all-reduce can be visualized as follows. On each iteration, we receive an input value from our left neighbor, and concurrently pass input along to our next neighbor while incrementing it with our local accumulator. After N-1 iterations, each device will have a copy of the full sum in it’s memory.</p>
<p><img alt="reduce_sum_2" src="../../_images/reduce_sum_2.svg" /></p>
<section id="putting-it-all-together">
<h4>Putting it all together<a class="headerlink" href="#putting-it-all-together" title="Link to this heading">#</a></h4>
<p>The following kernel demonstrates how to combine these principles into a functional kernel.</p>
<p>The prologue (executed when <code class="docutils literal notranslate"><span class="pre">outer_step==0</span></code>) first initiates a barrier with both neighbors to ensure that they have also entered the kernel. It also handles initialization for all <code class="docutils literal notranslate"><span class="pre">Ref</span></code>s and handles the first remote copy to the right neighbor’s “working” slot.</p>
<p>The main body assumes that a value has already been copied into our local working slot, either from the previous iteration or from the prologue. A complicating factor is that our destination buffers live in HBM, but we need to load values to VMEM before we perform arithmetic. Therefore, we simultaneously copy the working slot value into our VMEM (<code class="docutils literal notranslate"><span class="pre">receive_scratch</span></code>) and pass the value on to our right neighbor’s receiving slot. Once the value has been copied into our VMEM, we can accumulate it into our result (contained in <code class="docutils literal notranslate"><span class="pre">o_ref</span></code>).</p>
<p>A subtle race condition can occur if one device runs one loop ahead of it’s right neighbor. In this case, it could copy into the receiver’s <code class="docutils literal notranslate"><span class="pre">working_slot</span></code> at the same time the receiver is reading from it. In order to avoid this, each device will block on a <code class="docutils literal notranslate"><span class="pre">REGULAR</span></code> semaphore before copying into the right neighbor’s <code class="docutils literal notranslate"><span class="pre">dst_ref</span></code> until it has signaled that it is done reading from its <code class="docutils literal notranslate"><span class="pre">working_slot</span></code>. This race condition is rarely triggered for a small kernel such as this example, but can it can be explicitly triggered if for example using a <code class="docutils literal notranslate"><span class="pre">pltpu.delay</span></code> instruction to artificially hang a device.</p>
<p>Note that this is not an optimal or fully general kernel, as the block sizes must entirely fit in VMEM and we could better interleave communication and accumulation. We will discuss these optimizations in later sections.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">partition</span> <span class="o">=</span> <span class="n">P</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">mesh</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">make_mesh</span><span class="p">((</span><span class="n">num_devices</span><span class="p">,),</span> <span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,))</span>
<span class="n">sharding</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">sharding</span><span class="o">.</span><span class="n">NamedSharding</span><span class="p">(</span><span class="n">mesh</span><span class="p">,</span> <span class="n">partition</span><span class="p">)</span>

<span class="n">input_arr</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">key</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">128</span> <span class="o">*</span> <span class="n">num_devices</span><span class="p">))</span>
<span class="n">input_arr</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">device_put</span><span class="p">(</span><span class="n">input_arr</span><span class="p">,</span> <span class="n">sharding</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">local_barrier</span><span class="p">(</span><span class="n">left_neighbor</span><span class="p">,</span> <span class="n">right_neighbor</span><span class="p">,</span> <span class="n">double_barrier</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Performs a barrier with neighbors on the global barrier semaphore.</span>

<span class="sd">  Optionally performs a second barrier, which prevents a potential race</span>
<span class="sd">  when reusing the same collective_id across kernel invocations.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">barrier_sem</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">get_barrier_semaphore</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">neighbor</span> <span class="ow">in</span> <span class="p">[</span><span class="n">left_neighbor</span><span class="p">,</span> <span class="n">right_neighbor</span><span class="p">]:</span>
    <span class="n">pltpu</span><span class="o">.</span><span class="n">semaphore_signal</span><span class="p">(</span>
      <span class="n">barrier_sem</span><span class="p">,</span>
      <span class="n">inc</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
      <span class="n">device_id</span><span class="o">=</span><span class="p">(</span><span class="n">neighbor</span><span class="p">,),</span>
      <span class="n">device_id_type</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">DeviceIdType</span><span class="o">.</span><span class="n">MESH</span><span class="p">,</span>
    <span class="p">)</span>
  <span class="n">pltpu</span><span class="o">.</span><span class="n">semaphore_wait</span><span class="p">(</span><span class="n">barrier_sem</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">double_barrier</span><span class="p">:</span>
    <span class="c1"># The double-barrier prevents a race condition where one neighbor can</span>
    <span class="c1"># re-enter the kernel again on a subsequent call and increment the</span>
    <span class="c1"># barrier semaphore a second time. This would unblock the current device</span>
    <span class="c1"># even if the other neighbor is not ready yet.</span>
    <span class="c1"># To implement a double-barrier, we stack-allocate a second REGULAR</span>
    <span class="c1"># semaphore using run_scoped.</span>
    <span class="nd">@functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">run_scoped</span><span class="p">,</span>
                       <span class="n">second_barrier</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">SemaphoreType</span><span class="o">.</span><span class="n">REGULAR</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_</span><span class="p">(</span><span class="n">second_barrier</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">neighbor</span> <span class="ow">in</span> <span class="p">[</span><span class="n">left_neighbor</span><span class="p">,</span> <span class="n">right_neighbor</span><span class="p">]:</span>
        <span class="n">pltpu</span><span class="o">.</span><span class="n">semaphore_signal</span><span class="p">(</span>
          <span class="n">second_barrier</span><span class="p">,</span>
          <span class="n">inc</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
          <span class="n">device_id</span><span class="o">=</span><span class="p">(</span><span class="n">neighbor</span><span class="p">,),</span>
          <span class="n">device_id_type</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">DeviceIdType</span><span class="o">.</span><span class="n">MESH</span><span class="p">,</span>
        <span class="p">)</span>
      <span class="n">pltpu</span><span class="o">.</span><span class="n">semaphore_wait</span><span class="p">(</span><span class="n">second_barrier</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">all_reduce_kernel</span><span class="p">(</span>
    <span class="n">x_ref</span><span class="p">,</span>
    <span class="n">o_ref</span><span class="p">,</span>
    <span class="n">hbm_scratch</span><span class="p">,</span>
    <span class="n">copy_sem</span><span class="p">,</span>
    <span class="n">remote_recv_sem</span><span class="p">,</span>
    <span class="n">remote_send_sem</span><span class="p">,</span>
    <span class="n">capacity_sem</span><span class="p">,</span>
    <span class="n">receive_scratch</span><span class="p">,</span>
<span class="p">):</span>
  <span class="n">outer_step</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">program_id</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">working_slot</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">rem</span><span class="p">(</span><span class="n">outer_step</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
  <span class="n">receiving_slot</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">working_slot</span>

  <span class="n">my_id</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">axis_index</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
  <span class="n">right_neighbor</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">rem</span><span class="p">(</span><span class="n">my_id</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">)</span>
  <span class="n">left_neighbor</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">rem</span><span class="p">(</span><span class="n">my_id</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">num_devices</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">)</span>

  <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">outer_step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
    <span class="c1"># Barrier with both neighbors at the start, since we will be</span>
    <span class="c1"># communicating with both.</span>
    <span class="n">local_barrier</span><span class="p">(</span><span class="n">left_neighbor</span><span class="p">,</span> <span class="n">right_neighbor</span><span class="p">)</span>

    <span class="c1"># Initialize o_ref, acc_scratch, and hbm_scratch.</span>
    <span class="n">o_ref</span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">o_ref</span><span class="p">)</span>
    <span class="n">receive_scratch</span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">receive_scratch</span><span class="p">)</span>
    <span class="n">initial_copy</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">make_async_remote_copy</span><span class="p">(</span>
        <span class="n">src_ref</span><span class="o">=</span><span class="n">x_ref</span><span class="p">,</span>
        <span class="n">dst_ref</span><span class="o">=</span><span class="n">hbm_scratch</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">working_slot</span><span class="p">],</span>
        <span class="n">send_sem</span><span class="o">=</span><span class="n">remote_send_sem</span><span class="p">,</span>
        <span class="n">recv_sem</span><span class="o">=</span><span class="n">remote_recv_sem</span><span class="p">,</span>
        <span class="n">device_id</span><span class="o">=</span><span class="p">(</span><span class="n">right_neighbor</span><span class="p">,),</span>
        <span class="n">device_id_type</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">DeviceIdType</span><span class="o">.</span><span class="n">MESH</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">initial_copy</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
    <span class="n">initial_copy</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

  <span class="c1"># Signal to our left neighbor that we are ready to receive.</span>
  <span class="c1"># Without this signal, our left neighbor can be &gt;=1 iteration ahead,</span>
  <span class="c1"># meaning it could write into our working slot.</span>
  <span class="n">pltpu</span><span class="o">.</span><span class="n">semaphore_signal</span><span class="p">(</span>
      <span class="n">capacity_sem</span><span class="p">,</span>
      <span class="n">inc</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
      <span class="n">device_id</span><span class="o">=</span><span class="p">(</span><span class="n">left_neighbor</span><span class="p">,),</span>
      <span class="n">device_id_type</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">DeviceIdType</span><span class="o">.</span><span class="n">MESH</span><span class="p">,</span>
  <span class="p">)</span>

  <span class="c1"># Copy the partial result our left neighbor sent to us into VMEM for</span>
  <span class="c1"># computation.</span>
  <span class="n">local_copy</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">make_async_copy</span><span class="p">(</span>
      <span class="n">src_ref</span><span class="o">=</span><span class="n">hbm_scratch</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">working_slot</span><span class="p">],</span>
      <span class="n">dst_ref</span><span class="o">=</span><span class="n">receive_scratch</span><span class="p">,</span>
      <span class="n">sem</span><span class="o">=</span><span class="n">copy_sem</span><span class="p">,</span>
  <span class="p">)</span>
  <span class="n">local_copy</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

  <span class="c1"># Block until our right neighbor is ready to receive.</span>
  <span class="n">pltpu</span><span class="o">.</span><span class="n">semaphore_wait</span><span class="p">(</span><span class="n">capacity_sem</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
  <span class="c1"># Pass the value to our right neighbor.</span>
  <span class="n">remote_copy</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">make_async_remote_copy</span><span class="p">(</span>
      <span class="n">src_ref</span><span class="o">=</span><span class="n">hbm_scratch</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">working_slot</span><span class="p">],</span>
      <span class="n">dst_ref</span><span class="o">=</span><span class="n">hbm_scratch</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">receiving_slot</span><span class="p">],</span>
      <span class="n">send_sem</span><span class="o">=</span><span class="n">remote_send_sem</span><span class="p">,</span>
      <span class="n">recv_sem</span><span class="o">=</span><span class="n">remote_recv_sem</span><span class="p">,</span>
      <span class="n">device_id</span><span class="o">=</span><span class="p">(</span><span class="n">right_neighbor</span><span class="p">,),</span>
      <span class="n">device_id_type</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">DeviceIdType</span><span class="o">.</span><span class="n">MESH</span><span class="p">,</span>
  <span class="p">)</span>
  <span class="n">remote_copy</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
  <span class="c1"># Finish local copy and accumulate while remote_copy is happening.</span>
  <span class="n">local_copy</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
  <span class="n">o_ref</span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="o">+=</span> <span class="n">receive_scratch</span><span class="p">[</span><span class="o">...</span><span class="p">]</span>
  <span class="c1"># Block until remote copy finishes.</span>
  <span class="n">remote_copy</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>


<span class="n">out_shape</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">jax</span><span class="o">.</span><span class="n">ShapeDtypeStruct</span><span class="p">((</span><span class="mi">8</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
    <span class="c1"># We allocate the double-buffer as a Pallas output so that it is</span>
    <span class="c1"># resident in HBM.</span>
    <span class="n">jax</span><span class="o">.</span><span class="n">ShapeDtypeStruct</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>  <span class="c1"># hbm_scratch</span>
<span class="p">)</span>

<span class="n">grid_spec</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">PrefetchScalarGridSpec</span><span class="p">(</span>
    <span class="n">num_scalar_prefetch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">in_specs</span><span class="o">=</span><span class="p">[</span>
        <span class="c1"># Our input lives in VMEM</span>
        <span class="n">pl</span><span class="o">.</span><span class="n">BlockSpec</span><span class="p">(</span><span class="n">memory_space</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">MemorySpace</span><span class="o">.</span><span class="n">VMEM</span><span class="p">),</span>
    <span class="p">],</span>
    <span class="n">out_specs</span><span class="o">=</span><span class="p">[</span>
        <span class="c1"># Our output lives in VMEM</span>
        <span class="n">pl</span><span class="o">.</span><span class="n">BlockSpec</span><span class="p">(</span><span class="n">memory_space</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">MemorySpace</span><span class="o">.</span><span class="n">VMEM</span><span class="p">),</span>
        <span class="c1"># Our double-buffer lives in HBM</span>
        <span class="n">pl</span><span class="o">.</span><span class="n">BlockSpec</span><span class="p">(</span><span class="n">memory_space</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">MemorySpace</span><span class="o">.</span><span class="n">ANY</span><span class="p">),</span>
    <span class="p">],</span>
    <span class="n">grid</span><span class="o">=</span><span class="p">(</span><span class="n">num_devices</span><span class="p">,),</span>
    <span class="n">scratch_shapes</span><span class="o">=</span><span class="p">(</span>
        <span class="p">[</span><span class="n">pltpu</span><span class="o">.</span><span class="n">SemaphoreType</span><span class="o">.</span><span class="n">DMA</span><span class="p">]</span> <span class="o">*</span> <span class="mi">3</span>
        <span class="o">+</span> <span class="p">[</span><span class="n">pltpu</span><span class="o">.</span><span class="n">SemaphoreType</span><span class="o">.</span><span class="n">REGULAR</span><span class="p">]</span>  <span class="c1"># capacity_sem</span>
        <span class="o">+</span> <span class="p">[</span><span class="n">pltpu</span><span class="o">.</span><span class="n">VMEM</span><span class="p">((</span><span class="mi">8</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">)]</span>  <span class="c1"># receive_scratch</span>
    <span class="p">),</span>
<span class="p">)</span>

<span class="n">kernel</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">pallas_call</span><span class="p">(</span>
    <span class="n">all_reduce_kernel</span><span class="p">,</span>
    <span class="n">out_shape</span><span class="o">=</span><span class="n">out_shape</span><span class="p">,</span>
    <span class="n">grid_spec</span><span class="o">=</span><span class="n">grid_spec</span><span class="p">,</span>
    <span class="n">compiler_params</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">CompilerParams</span><span class="p">(</span><span class="n">collective_id</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">pallas_result</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span>
    <span class="n">jax</span><span class="o">.</span><span class="n">shard_map</span><span class="p">(</span>
        <span class="n">kernel</span><span class="p">,</span>
        <span class="n">mesh</span><span class="o">=</span><span class="n">mesh</span><span class="p">,</span>
        <span class="n">in_specs</span><span class="o">=</span><span class="n">partition</span><span class="p">,</span>
        <span class="n">out_specs</span><span class="o">=</span><span class="n">partition</span><span class="p">,</span>
        <span class="n">check_vma</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)(</span><span class="n">input_arr</span><span class="p">)</span>
<span class="n">pallas_result</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">block_until_ready</span><span class="p">(</span><span class="n">pallas_result</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">lax_sum</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">lax</span><span class="o">.</span><span class="n">psum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;x&#39;</span><span class="p">)</span>


<span class="n">xla_result</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span>
    <span class="n">jax</span><span class="o">.</span><span class="n">shard_map</span><span class="p">(</span>
        <span class="n">lax_sum</span><span class="p">,</span> <span class="n">mesh</span><span class="o">=</span><span class="n">mesh</span><span class="p">,</span> <span class="n">in_specs</span><span class="o">=</span><span class="n">P</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;x&#39;</span><span class="p">),</span> <span class="n">out_specs</span><span class="o">=</span><span class="n">P</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;x&#39;</span><span class="p">)</span>
    <span class="p">)</span>
<span class="p">)(</span><span class="n">input_arr</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Input = &#39;</span><span class="p">,</span> <span class="n">input_arr</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">::</span><span class="mi">128</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Pallas result = &#39;</span><span class="p">,</span> <span class="n">pallas_result</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">::</span><span class="mi">128</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;lax.psum result = &#39;</span><span class="p">,</span> <span class="n">xla_result</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">::</span><span class="mi">128</span><span class="p">])</span>
<span class="n">difference</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">pallas_result</span> <span class="o">-</span> <span class="n">xla_result</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Difference |Pallas - lax.psum| = &#39;</span><span class="p">,</span> <span class="n">difference</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Input =  [0.9858954  0.11763906 0.9955574  0.775211  ]
Pallas result =  [2.8743029 2.8743029 2.8743029 2.8743029]
lax.psum result =  [2.8743029 2.8743029 2.8743029 2.8743029]
Difference |Pallas - lax.psum| =  1.0535587e-08
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="run-ahead-and-race-conditions">
<h3>Run-ahead and Race Conditions<a class="headerlink" href="#run-ahead-and-race-conditions" title="Link to this heading">#</a></h3>
<p>As a general rule of thumb, to maximize performance we want to allow a device to run-ahead of other devices without synchronization as much as possible without sacrificing correctness of the program. While we could enforce a barrier across all devices at the beginning of each iteration, this bottlenecks the performance of the program to the slowest device on each loop. By relaxing synchronization and allowing a moderate amount of run-ahead, we can better accommodate variance in latency between iterations and devices because a device that is slow on one iteration could catch up on the next iteration.</p>
<p>In the all-reduce kernel we wrote previously, we allow devices to run ahead but by less than one iteration compared to its neighbors (however, non-neighboring devices could be more than 1 iteration apart). To see why the semaphore synchronization is necessary, consider the case when one device (say device 2) hangs and falls behind the other devices. An RDMA has no “handshake” — only the receiver is blocked while waiting for the data to arrive. Therefore, each device can run up to one iteration ahead before it becomes blocked waiting for the next RDMA to arrive. If we have N devices, this means that the final device can be up to N iterations ahead of the first device.</p>
<p><img alt="race_condition" src="../../_images/race_condition.svg" /></p>
<p>Without adding synchronization in the other direction (forcing senders to block), device 1 could potentially run up to <code class="docutils literal notranslate"><span class="pre">N</span></code> iterations (<code class="docutils literal notranslate"><span class="pre">N</span> <span class="pre">=</span> <span class="pre">num_devices</span></code>) ahead of device 2, sending multiple writes and overwriting values in the process. To solve this in the <code class="docutils literal notranslate"><span class="pre">all_reduce</span></code> kernel we wrote previously we implemented a “handshake” protocol where the receiver signals back to the sender that it is ready to receive, and only then does the sender begin issuing the next RDMA.</p>
</section>
<section id="bi-directional-communication">
<h3>Bi-directional Communication<a class="headerlink" href="#bi-directional-communication" title="Link to this heading">#</a></h3>
<p>In our previous kernels, we communicated in a single direction around a ring from left-to-right. However, as ICI connections are bi-directional, we are effectively wasting half of the total bandwidth by not sending values in the opposite direction from right-to-left. In this next kernel we will demonstrate an example which communicates in both directions to maximize ICI bandwidth.</p>
</section>
<section id="example-bi-directional-reduce-scatter-lax-psum-scatter">
<h3>Example: Bi-directional Reduce-Scatter (<code class="docutils literal notranslate"><span class="pre">lax.psum_scatter</span></code>)<a class="headerlink" href="#example-bi-directional-reduce-scatter-lax-psum-scatter" title="Link to this heading">#</a></h3>
<p>A reduce-scatter operation is the combination of an all-reduce followed by a scatter. Or alternatively, an all-reduce is the combination of a reduce-scatter followed by all-gather.</p>
<p>The following graphic depicts the semantics of this operation. We assume that each device starts with a collection of partial sums (denoted by a letter + number, such as <code class="docutils literal notranslate"><span class="pre">A0</span></code>). The goal is to reduce along one axis (numbers), while sharding along the other axis (letters).</p>
<p><img alt="reduce_scatter_1" src="../../_images/reduce_scatter_1.svg" /></p>
<p>In order to implement a bi-directional communication strategy, we slice each input block in half, and designate a direction for each half. The top half of each block will be passed from right-to-left, and the bottom half will be passed from left-to-right. A second deviation from the communication patterns of our previous all-reduce and all-gather kernels is that we will also pass around accumulators or partial sums and keep the inputs local to each device. This is in contrast to the previous examples where we passed around inputs but kept the accumulator local to the device. Passing around the accumulator is a more natural fit for this problem as in contrast to all-reduce, most of the data in the inputs are not part of the output that will be stored locally on the device. (e.g. <code class="docutils literal notranslate"><span class="pre">B0</span></code>, <code class="docutils literal notranslate"><span class="pre">C0</span></code>, and <code class="docutils literal notranslate"><span class="pre">D0</span></code> in the above graphic will not be stored on the device holding <code class="docutils literal notranslate"><span class="pre">A</span></code> at the end).</p>
<p>The following diagram illustrates this communication pattern, where the colored boxes represent accumulators (not inputs!). Initially, the accumulator is simply the value that was contained in the input. At each iteration of the algorithm, we will receive a partial sum from our neighbors in each direction. We then compute the correct slice of our input to accumulate into the partial buffer, then pass the new partial sum along to our next neighbor. After N iterations, the accumulator will have passed through each device, meaning that it will hold the full sum in the end.</p>
<p><img alt="reduce_scatter_2" src="../../_images/reduce_scatter_2.svg" /></p>
<p>In terms of construction of the kernel, we introduce an additional <code class="docutils literal notranslate"><span class="pre">phase</span></code> dimension to the Pallas grid, which denotes which accumulator (left or right) we are currently computing on. We let <code class="docutils literal notranslate"><span class="pre">phase=0</span></code> denote the accumulator moving to the left, and <code class="docutils literal notranslate"><span class="pre">phase=1</span></code> denote the accumulator moving to the right. We then pipeline the two phases, such that while computing the result for one phase we are transferring our previously computed values in the opposite direction in preparation for the next phase. For example, when we are on <code class="docutils literal notranslate"><span class="pre">phase=0</span></code> (left), we first begin a DMA to transfer results we computed in the previous iteration to our right neighbor (right-DMA). Then, we accumulate into the left-buffer and save the result to HBM. We then wait for the right-DMA to complete so that it is ready for <code class="docutils literal notranslate"><span class="pre">phase=1</span></code> (right).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">partition</span> <span class="o">=</span> <span class="n">P</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">mesh</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">make_mesh</span><span class="p">((</span><span class="n">num_devices</span><span class="p">,),</span> <span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,))</span>
<span class="n">sharding</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">sharding</span><span class="o">.</span><span class="n">NamedSharding</span><span class="p">(</span><span class="n">mesh</span><span class="p">,</span> <span class="n">partition</span><span class="p">)</span>

<span class="c1"># We need a block size of (16, 128) to ensure that a half-slice is at least</span>
<span class="c1"># of size (8, 128), which is the size of a VREG. This makes tiling easier</span>
<span class="c1"># for the compiler.</span>
<span class="n">block_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
<span class="n">input_arr</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span>
    <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">key</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
    <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">block_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_devices</span><span class="p">,</span> <span class="n">block_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_devices</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">input_arr</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">device_put</span><span class="p">(</span><span class="n">input_arr</span><span class="p">,</span> <span class="n">sharding</span><span class="p">)</span>

<span class="n">LEFT</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">RIGHT</span> <span class="o">=</span> <span class="mi">1</span>


<span class="k">def</span> <span class="nf">mod</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">lax</span><span class="o">.</span><span class="n">rem</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">signal</span><span class="p">(</span><span class="n">left_or_right</span><span class="p">,</span> <span class="n">semaphore</span><span class="p">):</span>
  <span class="n">my_id</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">axis_index</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">left_or_right</span> <span class="o">==</span> <span class="n">LEFT</span><span class="p">:</span>
    <span class="n">neighbor</span> <span class="o">=</span> <span class="n">mod</span><span class="p">(</span><span class="n">my_id</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">neighbor</span> <span class="o">=</span> <span class="n">mod</span><span class="p">(</span><span class="n">my_id</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">)</span>
  <span class="n">pltpu</span><span class="o">.</span><span class="n">semaphore_signal</span><span class="p">(</span>
      <span class="n">semaphore</span><span class="p">,</span>
      <span class="n">inc</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
      <span class="n">device_id</span><span class="o">=</span><span class="p">(</span><span class="n">neighbor</span><span class="p">,),</span>
      <span class="n">device_id_type</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">DeviceIdType</span><span class="o">.</span><span class="n">MESH</span><span class="p">,</span>
  <span class="p">)</span>


<span class="k">def</span> <span class="nf">reduce_scatter_kernel</span><span class="p">(</span>
    <span class="n">x_ref</span><span class="p">,</span>
    <span class="n">o_ref</span><span class="p">,</span>
    <span class="n">hbm_scratch</span><span class="p">,</span>
    <span class="n">local_copy_sem</span><span class="p">,</span>
    <span class="n">left_recv_sem</span><span class="p">,</span>
    <span class="n">left_send_sem</span><span class="p">,</span>
    <span class="n">right_recv_sem</span><span class="p">,</span>
    <span class="n">right_send_sem</span><span class="p">,</span>
    <span class="n">left_capacity_sem</span><span class="p">,</span>
    <span class="n">right_capacity_sem</span><span class="p">,</span>
    <span class="n">accum_scratch</span><span class="p">,</span>
<span class="p">):</span>
  <span class="n">outer_step</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">program_id</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">phase</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">program_id</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">is_start</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">outer_step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="n">phase</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
  <span class="n">last_iteration</span> <span class="o">=</span> <span class="n">outer_step</span> <span class="o">==</span> <span class="n">pl</span><span class="o">.</span><span class="n">num_programs</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>

  <span class="n">working_slot</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">rem</span><span class="p">(</span><span class="n">outer_step</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
  <span class="n">receiving_slot</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">working_slot</span>
  <span class="n">my_id</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">axis_index</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
  <span class="n">right_neighbor</span> <span class="o">=</span> <span class="n">mod</span><span class="p">(</span><span class="n">my_id</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">)</span>
  <span class="n">left_neighbor</span> <span class="o">=</span> <span class="n">mod</span><span class="p">(</span><span class="n">my_id</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">)</span>

  <span class="n">left_copy_device</span> <span class="o">=</span> <span class="n">mod</span><span class="p">(</span><span class="n">my_id</span> <span class="o">+</span> <span class="n">outer_step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">)</span>
  <span class="n">right_copy_device</span> <span class="o">=</span> <span class="n">mod</span><span class="p">(</span><span class="n">my_id</span> <span class="o">-</span> <span class="n">outer_step</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">)</span>
  <span class="c1"># Slices can be specified using pl.ds(start, size)</span>
  <span class="n">left_copy_slice</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">ds</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">block_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
  <span class="n">right_copy_slice</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">ds</span><span class="p">(</span><span class="n">block_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">block_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
  <span class="n">current_phase_slice</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">ds</span><span class="p">(</span><span class="n">phase</span> <span class="o">*</span> <span class="p">(</span><span class="n">block_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">),</span> <span class="n">block_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>

  <span class="n">initial_left_copy</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">make_async_remote_copy</span><span class="p">(</span>
      <span class="n">src_ref</span><span class="o">=</span><span class="n">x_ref</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">my_id</span><span class="p">,</span> <span class="n">left_copy_slice</span><span class="p">],</span>
      <span class="n">dst_ref</span><span class="o">=</span><span class="n">hbm_scratch</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">working_slot</span><span class="p">,</span> <span class="n">left_copy_slice</span><span class="p">],</span>
      <span class="n">send_sem</span><span class="o">=</span><span class="n">left_send_sem</span><span class="p">,</span>
      <span class="n">recv_sem</span><span class="o">=</span><span class="n">left_recv_sem</span><span class="p">,</span>
      <span class="n">device_id</span><span class="o">=</span><span class="p">(</span><span class="n">left_neighbor</span><span class="p">,),</span>
      <span class="n">device_id_type</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">DeviceIdType</span><span class="o">.</span><span class="n">MESH</span><span class="p">,</span>
  <span class="p">)</span>

  <span class="n">initial_right_copy</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">make_async_remote_copy</span><span class="p">(</span>
      <span class="n">src_ref</span><span class="o">=</span><span class="n">x_ref</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">my_id</span><span class="p">,</span> <span class="n">right_copy_slice</span><span class="p">],</span>
      <span class="n">dst_ref</span><span class="o">=</span><span class="n">hbm_scratch</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">working_slot</span><span class="p">,</span> <span class="n">right_copy_slice</span><span class="p">],</span>
      <span class="n">send_sem</span><span class="o">=</span><span class="n">right_send_sem</span><span class="p">,</span>
      <span class="n">recv_sem</span><span class="o">=</span><span class="n">right_recv_sem</span><span class="p">,</span>
      <span class="n">device_id</span><span class="o">=</span><span class="p">(</span><span class="n">right_neighbor</span><span class="p">,),</span>
      <span class="n">device_id_type</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">DeviceIdType</span><span class="o">.</span><span class="n">MESH</span><span class="p">,</span>
  <span class="p">)</span>

  <span class="n">left_copy</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">make_async_remote_copy</span><span class="p">(</span>
      <span class="n">src_ref</span><span class="o">=</span><span class="n">hbm_scratch</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">working_slot</span><span class="p">,</span> <span class="n">left_copy_slice</span><span class="p">],</span>
      <span class="n">dst_ref</span><span class="o">=</span><span class="n">hbm_scratch</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">receiving_slot</span><span class="p">,</span> <span class="n">left_copy_slice</span><span class="p">],</span>
      <span class="n">send_sem</span><span class="o">=</span><span class="n">left_send_sem</span><span class="p">,</span>
      <span class="n">recv_sem</span><span class="o">=</span><span class="n">left_recv_sem</span><span class="p">,</span>
      <span class="n">device_id</span><span class="o">=</span><span class="p">(</span><span class="n">left_neighbor</span><span class="p">,),</span>
      <span class="n">device_id_type</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">DeviceIdType</span><span class="o">.</span><span class="n">MESH</span><span class="p">,</span>
  <span class="p">)</span>
  <span class="n">right_copy</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">make_async_remote_copy</span><span class="p">(</span>
      <span class="c1"># Note: Right copy is flipped with regards to slots since we are copying</span>
      <span class="c1"># to the next outer_step iteration.</span>
      <span class="n">src_ref</span><span class="o">=</span><span class="n">hbm_scratch</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">receiving_slot</span><span class="p">,</span> <span class="n">right_copy_slice</span><span class="p">],</span>
      <span class="n">dst_ref</span><span class="o">=</span><span class="n">hbm_scratch</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">working_slot</span><span class="p">,</span> <span class="n">right_copy_slice</span><span class="p">],</span>
      <span class="n">send_sem</span><span class="o">=</span><span class="n">right_send_sem</span><span class="p">,</span>
      <span class="n">recv_sem</span><span class="o">=</span><span class="n">right_recv_sem</span><span class="p">,</span>
      <span class="n">device_id</span><span class="o">=</span><span class="p">(</span><span class="n">right_neighbor</span><span class="p">,),</span>
      <span class="n">device_id_type</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">DeviceIdType</span><span class="o">.</span><span class="n">MESH</span><span class="p">,</span>
  <span class="p">)</span>

  <span class="c1"># --- Prologue ---</span>
  <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">is_start</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
    <span class="c1"># Barrier with both neighbors at the start, since we will be</span>
    <span class="c1"># communicating with both.</span>
    <span class="n">local_barrier</span><span class="p">(</span><span class="n">left_neighbor</span><span class="p">,</span> <span class="n">right_neighbor</span><span class="p">)</span>

    <span class="c1"># Initialize o_ref, acc_scratch, and hbm_scratch with initial copies.</span>
    <span class="n">o_ref</span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">o_ref</span><span class="p">[</span><span class="o">...</span><span class="p">])</span>
    <span class="n">accum_scratch</span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">accum_scratch</span><span class="p">[</span><span class="o">...</span><span class="p">])</span>

    <span class="n">initial_left_copy</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
    <span class="n">initial_left_copy</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
    <span class="n">initial_right_copy</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

    <span class="c1"># We tell our left neighbor that it is allowed to send to the right.</span>
    <span class="c1"># (and vice versa for right neighbor)</span>
    <span class="n">signal</span><span class="p">(</span><span class="n">LEFT</span><span class="p">,</span> <span class="n">right_capacity_sem</span><span class="p">)</span>
    <span class="n">signal</span><span class="p">(</span><span class="n">RIGHT</span><span class="p">,</span> <span class="n">left_capacity_sem</span><span class="p">)</span>

  <span class="c1"># --- Body ---</span>
  <span class="c1"># At the beginning of our kernel body, we start a DMA which copies</span>
  <span class="c1"># the result we computed in the previous phase to our neighbor.</span>
  <span class="c1"># This allows us to overlap the communication of sending our previous phase</span>
  <span class="c1"># with the computation for the current phase.</span>
  <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="o">~</span><span class="n">is_start</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
    <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">phase</span> <span class="o">==</span> <span class="n">LEFT</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
      <span class="c1"># We block here until our right neighbor tells use we can send to</span>
      <span class="c1"># the right.</span>
      <span class="n">pltpu</span><span class="o">.</span><span class="n">semaphore_wait</span><span class="p">(</span><span class="n">right_capacity_sem</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
      <span class="n">right_copy</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

    <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">phase</span> <span class="o">==</span> <span class="n">RIGHT</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
      <span class="c1"># We block here until our left neighbor tells use we can send to</span>
      <span class="c1"># the left.</span>
      <span class="n">pltpu</span><span class="o">.</span><span class="n">semaphore_wait</span><span class="p">(</span><span class="n">left_capacity_sem</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
      <span class="n">left_copy</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

  <span class="n">local_copy</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">make_async_copy</span><span class="p">(</span>
      <span class="n">src_ref</span><span class="o">=</span><span class="n">hbm_scratch</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">working_slot</span><span class="p">,</span> <span class="n">current_phase_slice</span><span class="p">],</span>
      <span class="n">dst_ref</span><span class="o">=</span><span class="n">accum_scratch</span><span class="p">,</span>
      <span class="n">sem</span><span class="o">=</span><span class="n">local_copy_sem</span><span class="p">,</span>
  <span class="p">)</span>
  <span class="n">local_copy</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
  <span class="n">local_copy</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

  <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="o">~</span><span class="n">last_iteration</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
    <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">phase</span> <span class="o">==</span> <span class="n">LEFT</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
      <span class="n">accum_scratch</span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="o">+=</span> <span class="n">x_ref</span><span class="p">[</span><span class="n">left_copy_device</span><span class="p">,</span> <span class="n">left_copy_slice</span><span class="p">]</span>

    <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">phase</span> <span class="o">==</span> <span class="n">RIGHT</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
      <span class="n">accum_scratch</span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="o">+=</span> <span class="n">x_ref</span><span class="p">[</span><span class="n">right_copy_device</span><span class="p">,</span> <span class="n">right_copy_slice</span><span class="p">]</span>

  <span class="n">local_copy</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">make_async_copy</span><span class="p">(</span>
      <span class="n">src_ref</span><span class="o">=</span><span class="n">accum_scratch</span><span class="p">,</span>
      <span class="n">dst_ref</span><span class="o">=</span><span class="n">hbm_scratch</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">working_slot</span><span class="p">,</span> <span class="n">current_phase_slice</span><span class="p">],</span>
      <span class="n">sem</span><span class="o">=</span><span class="n">local_copy_sem</span><span class="p">,</span>
  <span class="p">)</span>
  <span class="n">local_copy</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
  <span class="n">local_copy</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

  <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">is_start</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
    <span class="n">initial_right_copy</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

  <span class="c1"># At the end of our kernel body, we wait on the DMA of the previous phase</span>
  <span class="c1"># to make sure the results are ready for the next phase.</span>
  <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="o">~</span><span class="n">is_start</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
    <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">phase</span> <span class="o">==</span> <span class="n">LEFT</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
      <span class="n">right_copy</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
      <span class="n">signal</span><span class="p">(</span><span class="n">LEFT</span><span class="p">,</span> <span class="n">right_capacity_sem</span><span class="p">)</span>

    <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">phase</span> <span class="o">==</span> <span class="n">RIGHT</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
      <span class="n">left_copy</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
      <span class="n">signal</span><span class="p">(</span><span class="n">RIGHT</span><span class="p">,</span> <span class="n">left_capacity_sem</span><span class="p">)</span>

  <span class="c1"># --- Epilogue ---</span>
  <span class="c1"># Store result on last iteration.</span>
  <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">last_iteration</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
    <span class="c1"># Clean up semaphores so that they exit with a value of 0.</span>
    <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">phase</span> <span class="o">==</span> <span class="n">LEFT</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
      <span class="n">o_ref</span><span class="p">[</span><span class="n">left_copy_slice</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="n">accum_scratch</span><span class="p">[</span><span class="o">...</span><span class="p">]</span>
      <span class="n">pltpu</span><span class="o">.</span><span class="n">semaphore_wait</span><span class="p">(</span><span class="n">right_capacity_sem</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">phase</span> <span class="o">==</span> <span class="n">RIGHT</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
      <span class="n">o_ref</span><span class="p">[</span><span class="n">right_copy_slice</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="n">accum_scratch</span><span class="p">[</span><span class="o">...</span><span class="p">]</span>
      <span class="n">pltpu</span><span class="o">.</span><span class="n">semaphore_wait</span><span class="p">(</span><span class="n">left_capacity_sem</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>


<span class="n">out_shape</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">jax</span><span class="o">.</span><span class="n">ShapeDtypeStruct</span><span class="p">((</span><span class="n">block_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">block_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>  <span class="c1"># output</span>
    <span class="c1"># Shape: [working/recv, block[0], block[1]]</span>
    <span class="n">jax</span><span class="o">.</span><span class="n">ShapeDtypeStruct</span><span class="p">(</span>
        <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">block_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">block_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span>
    <span class="p">),</span>  <span class="c1"># hbm_scratch</span>
<span class="p">)</span>

<span class="n">grid_spec</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">PrefetchScalarGridSpec</span><span class="p">(</span>
    <span class="n">num_scalar_prefetch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">in_specs</span><span class="o">=</span><span class="p">[</span>
        <span class="n">pl</span><span class="o">.</span><span class="n">BlockSpec</span><span class="p">(</span><span class="n">memory_space</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">MemorySpace</span><span class="o">.</span><span class="n">VMEM</span><span class="p">),</span>
    <span class="p">],</span>
    <span class="n">out_specs</span><span class="o">=</span><span class="p">[</span>
        <span class="n">pl</span><span class="o">.</span><span class="n">BlockSpec</span><span class="p">(</span><span class="n">memory_space</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">MemorySpace</span><span class="o">.</span><span class="n">VMEM</span><span class="p">),</span>
        <span class="n">pl</span><span class="o">.</span><span class="n">BlockSpec</span><span class="p">(</span><span class="n">memory_space</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">MemorySpace</span><span class="o">.</span><span class="n">ANY</span><span class="p">),</span>
    <span class="p">],</span>
    <span class="n">grid</span><span class="o">=</span><span class="p">(</span><span class="n">num_devices</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
    <span class="n">scratch_shapes</span><span class="o">=</span><span class="p">(</span>
        <span class="p">[</span><span class="n">pltpu</span><span class="o">.</span><span class="n">SemaphoreType</span><span class="o">.</span><span class="n">DMA</span><span class="p">]</span> <span class="o">*</span> <span class="mi">5</span>
        <span class="o">+</span> <span class="p">[</span><span class="n">pltpu</span><span class="o">.</span><span class="n">SemaphoreType</span><span class="o">.</span><span class="n">REGULAR</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span>  <span class="c1"># Capacity semaphores</span>
        <span class="o">+</span> <span class="p">[</span>
            <span class="n">pltpu</span><span class="o">.</span><span class="n">VMEM</span><span class="p">((</span><span class="n">block_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">block_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="p">]</span>  <span class="c1"># accum_scratch</span>
    <span class="p">),</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">pallas_reduce_scatter</span><span class="p">(</span><span class="n">input_arr</span><span class="p">):</span>
  <span class="n">input_arr</span> <span class="o">=</span> <span class="n">input_arr</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">num_devices</span><span class="p">,</span> <span class="n">block_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">block_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
  <span class="k">return</span> <span class="n">pl</span><span class="o">.</span><span class="n">pallas_call</span><span class="p">(</span>
      <span class="n">reduce_scatter_kernel</span><span class="p">,</span>
      <span class="n">out_shape</span><span class="o">=</span><span class="n">out_shape</span><span class="p">,</span>
      <span class="n">grid_spec</span><span class="o">=</span><span class="n">grid_spec</span><span class="p">,</span>
      <span class="n">compiler_params</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">CompilerParams</span><span class="p">(</span><span class="n">collective_id</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
  <span class="p">)(</span><span class="n">input_arr</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>


<span class="n">pallas_result</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span>
    <span class="n">jax</span><span class="o">.</span><span class="n">shard_map</span><span class="p">(</span>
        <span class="n">pallas_reduce_scatter</span><span class="p">,</span>
        <span class="n">mesh</span><span class="o">=</span><span class="n">mesh</span><span class="p">,</span>
        <span class="n">in_specs</span><span class="o">=</span><span class="n">P</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;x&#39;</span><span class="p">),</span>
        <span class="n">out_specs</span><span class="o">=</span><span class="n">P</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
        <span class="n">check_vma</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)(</span><span class="n">input_arr</span><span class="p">)</span>

<span class="n">pallas_result</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">block_until_ready</span><span class="p">(</span><span class="n">pallas_result</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compare our result to XLA.</span>
<span class="k">def</span> <span class="nf">lax_reduce_sum_scatter</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">num_devices</span><span class="p">,</span> <span class="n">block_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">block_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
  <span class="k">return</span> <span class="n">lax</span><span class="o">.</span><span class="n">psum_scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;x&#39;</span><span class="p">)</span>


<span class="n">xla_result</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span>
    <span class="n">jax</span><span class="o">.</span><span class="n">shard_map</span><span class="p">(</span>
        <span class="n">lax_reduce_sum_scatter</span><span class="p">,</span>
        <span class="n">mesh</span><span class="o">=</span><span class="n">mesh</span><span class="p">,</span>
        <span class="n">in_specs</span><span class="o">=</span><span class="n">P</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;x&#39;</span><span class="p">),</span>
        <span class="n">out_specs</span><span class="o">=</span><span class="n">P</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
    <span class="p">)</span>
<span class="p">)(</span><span class="n">input_arr</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Input:&#39;</span><span class="p">,</span> <span class="n">input_arr</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">input_arr</span><span class="p">[::</span><span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Pallas Result:&#39;</span><span class="p">,</span> <span class="n">pallas_result</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">pallas_result</span><span class="p">[::</span><span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;lax.psum_scatter Result:&#39;</span><span class="p">,</span> <span class="n">xla_result</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">xla_result</span><span class="p">[::</span><span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s1">&#39;Difference |Pallas - lax.psum_scatter|:&#39;</span><span class="p">,</span>
    <span class="n">jnp</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">pallas_result</span> <span class="o">-</span> <span class="n">xla_result</span><span class="p">)),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Input: (64, 512) [0.78051674 0.3524047  0.59993696 0.9714314  0.24692321 0.01347649
 0.01857424 0.24841607 0.86097646 0.8261659  0.9753758  0.6902338
 0.4431417  0.963323   0.3158517  0.535548  ]
Pallas Result: (64, 128) [1.3593563 1.6274805 1.0979297 3.082869  1.4194957 1.4163033 1.2401303
 1.1892898 2.6545286 2.221559  2.7995253 2.08431   2.2509837 3.0726733
 2.4662397 1.9542246]
lax.psum_scatter Result: (64, 128) [1.3593563 1.6274805 1.0979297 3.082869  1.4194957 1.4163033 1.2401303
 1.1892898 2.6545286 2.221559  2.7995253 2.08431   2.2509837 3.0726733
 2.4662397 1.9542246]
Difference |Pallas - lax.psum_scatter|: 2.3841858e-07
</pre></div>
</div>
</div>
</div>
</section>
<section id="nested-remote-and-local-dma-pipelines">
<h3>Nested Remote and Local DMA Pipelines<a class="headerlink" href="#nested-remote-and-local-dma-pipelines" title="Link to this heading">#</a></h3>
<p>A limitation of the previous all-reduce and reduce-scatter kernels that we wrote is that the blocks we copy via remote DMA must be small enough to fit in our working VMEM that we use for accumulation. For some kernels it may be advantageous to use larger block sizes to better utilize the TPU. For example, a matrix multiplication requires on the order of <span class="math notranslate nohighlight">\(O(N^3)\)</span> compute operations, but only <span class="math notranslate nohighlight">\(O(N^2)\)</span> memory transfers. Therefore, we want each block of work transferred between devices to be large enough such that the operation becomes compute bound and we can hide the communication cost using pipelining. For reference, the VMEM of a TPU (for generations v4/v5) is typically on the order of 10-100MB, whereas HBM ranges from 10-100GB.</p>
<p>To address this problem, we need to be able to write an “inner kernel” that handles local HBM-VMEM pipelining inside of the “outer kernel” that handles pipelining larger HBM-HBM transfers between devices. Pallas offers an API for constructing nested pipelines using the <code class="docutils literal notranslate"><span class="pre">emit_pipeline</span></code> function. The basic call signature for <code class="docutils literal notranslate"><span class="pre">emit_pipeline</span></code> follows that of a standard <code class="docutils literal notranslate"><span class="pre">pallas_call</span></code> by specifying a <code class="docutils literal notranslate"><span class="pre">grid</span></code> and <code class="docutils literal notranslate"><span class="pre">BlockSpec</span></code>s for the inputs and outputs:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">emit_pipeline</span><span class="p">(</span>
    <span class="n">kernel</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">grid</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">in_specs</span><span class="p">:</span> <span class="n">PyTree</span><span class="p">[</span><span class="n">BlockSpec</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">out_specs</span><span class="p">:</span> <span class="n">PyTree</span><span class="p">[</span><span class="n">BlockSpec</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">should_accumulate_out</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">dimension_semantics</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">GridDimensionSemantics</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">:</span>
  <span class="o">...</span> <span class="c1"># Returns a custom pipeline given an inner kernel and BlockSpecs.</span>
</pre></div>
</div>
<p>Indeed, one can view <code class="docutils literal notranslate"><span class="pre">pallas_call</span></code> itself as simply a wrapper around <code class="docutils literal notranslate"><span class="pre">emit_pipeline</span></code>. Because our outer kernel only involves remote HBM-HBM transfers, we are not using any of the built-in pipelining that <code class="docutils literal notranslate"><span class="pre">pallas_call</span></code> provides for HBM-VMEM transfers. The following code skeleton demonstrates what a typical program structure would look like using this pattern:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="k">def</span> <span class="nf">outer_kernel</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
  <span class="c1"># ... do work to pipeline remote HBM-HBM transfers (outer kernel)</span>

  <span class="k">def</span> <span class="nf">inner_kernel</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
    <span class="c1"># ... do work (inner kernel)</span>
  <span class="n">pltpu</span><span class="o">.</span><span class="n">emit_pipeline</span><span class="p">(</span>
          <span class="n">inner_kernel</span><span class="p">,</span>
          <span class="n">grid</span><span class="o">=</span><span class="n">inner_grid</span><span class="p">,</span>
          <span class="n">in_specs</span><span class="o">=...</span><span class="p">,</span>
          <span class="n">out_specs</span><span class="o">=...</span><span class="p">,</span>
  <span class="p">)(</span><span class="n">inner_kernel_args</span><span class="p">)</span>
  <span class="c1"># ... do more work (outer kernel)</span>

<span class="n">pl</span><span class="o">.</span><span class="n">pallas_call</span><span class="p">(</span>
  <span class="n">outer_kernel</span><span class="p">,</span>
  <span class="n">grid</span><span class="o">=</span><span class="n">outer_grid</span><span class="p">,</span>
  <span class="n">in_specs</span><span class="o">=...</span>
  <span class="n">out_specs</span><span class="o">=...</span>
  <span class="n">scratch</span><span class="o">=</span><span class="n">inner_kernel_allocs</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="example-reduce-scatter-with-large-hbm-blocks">
<h3>Example: Reduce-Scatter with large HBM blocks<a class="headerlink" href="#example-reduce-scatter-with-large-hbm-blocks" title="Link to this heading">#</a></h3>
<p>In this next example we will modify our previous reduce-scatter example to utilize a nested inner pipeline. Note that the communication and computation costs of <code class="docutils literal notranslate"><span class="pre">reduce_scatter</span></code> both scale linearly with the size of the input, so we do not necessarily expect to see the operation become compute-bound with larger block sizes. This example is purely for demonstration purposes on how to use the pipeline emitter.</p>
<p>We will increase the block sizes of the outer kernel such that they would be undesirable to place inside of VMEM, and allocate all inputs and outputs in HBM (<code class="docutils literal notranslate"><span class="pre">memory_space=MemorySpace.ANY</span></code>). The only major change from our previous kernel is the body of the kernel where accumulation is done. Rather than manually copying from HBM to VMEM, accumulating, and copying back to HBM, we use <code class="docutils literal notranslate"><span class="pre">emit_pipeline</span></code> to handle the memory transfers for us. Accumulation is done in an inner kernel with a much smaller, VMEM-friendly block size.</p>
<p>In our previous kernel we had the following kernel body to copy data from HBM to the VMEM accumulator, increment, and then copy the results back to HBM:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">local_copy</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">make_async_copy</span><span class="p">(</span>
    <span class="n">src_ref</span><span class="o">=</span><span class="n">hbm_scratch</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">working_slot</span><span class="p">,</span> <span class="n">current_phase_slice</span><span class="p">],</span>
    <span class="n">dst_ref</span><span class="o">=</span><span class="n">accum_scratch</span><span class="p">,</span>
    <span class="n">sem</span><span class="o">=</span><span class="n">local_copy_sem</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">local_copy</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="n">local_copy</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
<span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="o">~</span><span class="n">last_iteration</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
  <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">phase</span> <span class="o">==</span> <span class="n">LEFT</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
    <span class="n">accum_scratch</span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="o">+=</span> <span class="n">x_ref</span><span class="p">[</span><span class="n">left_copy_device</span><span class="p">,</span> <span class="n">left_copy_slice</span><span class="p">]</span>
  <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">phase</span> <span class="o">==</span> <span class="n">RIGHT</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
    <span class="n">accum_scratch</span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="o">+=</span> <span class="n">x_ref</span><span class="p">[</span><span class="n">right_copy_device</span><span class="p">,</span> <span class="n">right_copy_slice</span><span class="p">]</span>
<span class="n">local_copy</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">make_async_copy</span><span class="p">(</span>
    <span class="n">src_ref</span><span class="o">=</span><span class="n">accum_scratch</span><span class="p">,</span>
    <span class="n">dst_ref</span><span class="o">=</span><span class="n">hbm_scratch</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">working_slot</span><span class="p">,</span> <span class="n">current_phase_slice</span><span class="p">],</span>
    <span class="n">sem</span><span class="o">=</span><span class="n">local_copy_sem</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">local_copy</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="n">local_copy</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
</pre></div>
</div>
<p>Our new kernel replaces it with the following <code class="docutils literal notranslate"><span class="pre">emit_pipeline</span></code> call:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">inner_kernel</span><span class="p">(</span><span class="n">input_ref</span><span class="p">,</span> <span class="n">accum_ref</span><span class="p">):</span>
  <span class="n">accum_ref</span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_ref</span><span class="p">[</span><span class="o">...</span><span class="p">]</span>
<span class="n">accum_pipeline</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">emit_pipeline</span><span class="p">(</span><span class="n">inner_kernel</span><span class="p">,</span>
                                     <span class="n">in_specs</span><span class="o">=</span><span class="p">[</span><span class="n">inner_block_spec</span><span class="p">],</span>
                                     <span class="n">out_specs</span><span class="o">=</span><span class="n">inner_block_spec</span><span class="p">,</span>
                                     <span class="n">should_accumulate_out</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                     <span class="n">grid</span><span class="o">=</span><span class="n">inner_grid</span><span class="p">)</span>
<span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="o">~</span><span class="n">last_iteration</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
  <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">phase</span> <span class="o">==</span> <span class="n">LEFT</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
    <span class="n">accum_pipeline</span><span class="p">(</span><span class="n">x_ref</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">left_copy_device</span><span class="p">,</span> <span class="n">left_copy_slice</span><span class="p">],</span>
                   <span class="n">hbm_scratch</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">working_slot</span><span class="p">,</span> <span class="n">left_copy_slice</span><span class="p">],</span>
    <span class="p">)</span>
  <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">phase</span> <span class="o">==</span> <span class="n">RIGHT</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
    <span class="n">accum_pipeline</span><span class="p">(</span><span class="n">x_ref</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">right_copy_device</span><span class="p">,</span> <span class="n">right_copy_slice</span><span class="p">],</span>
                   <span class="n">hbm_scratch</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">working_slot</span><span class="p">,</span> <span class="n">right_copy_slice</span><span class="p">],</span>
    <span class="p">)</span>
</pre></div>
</div>
<p>The full kernel is as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">partition</span> <span class="o">=</span> <span class="n">P</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">mesh</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">make_mesh</span><span class="p">((</span><span class="n">num_devices</span><span class="p">,),</span> <span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,))</span>
<span class="n">sharding</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">sharding</span><span class="o">.</span><span class="n">NamedSharding</span><span class="p">(</span><span class="n">mesh</span><span class="p">,</span> <span class="n">partition</span><span class="p">)</span>

<span class="c1"># We pick a large outer kernel block size that we do not want to place</span>
<span class="c1"># in VMEM. For pedagogical purposes we use (4096, 4096), although in</span>
<span class="c1"># principle this can be much larger.</span>
<span class="n">outer_block_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="mi">4096</span><span class="p">)</span>
<span class="c1"># We pick a smaller VMEM block size for the inner kernel.</span>
<span class="n">inner_block_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
<span class="n">input_arr</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span>
    <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">key</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
    <span class="n">shape</span><span class="o">=</span><span class="p">(</span>
        <span class="n">outer_block_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_devices</span><span class="p">,</span>
        <span class="n">outer_block_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_devices</span><span class="p">,</span>
    <span class="p">),</span>
<span class="p">)</span>
<span class="n">input_arr</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">device_put</span><span class="p">(</span><span class="n">input_arr</span><span class="p">,</span> <span class="n">sharding</span><span class="p">)</span>


<span class="n">inner_grid</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">outer_block_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">inner_block_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">outer_block_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="n">inner_block_size</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
<span class="p">)</span>
<span class="n">inner_block_spec</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">BlockSpec</span><span class="p">(</span>
    <span class="n">index_map</span><span class="o">=</span><span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">),</span>
    <span class="n">block_shape</span><span class="o">=</span><span class="n">inner_block_size</span><span class="p">,</span>
    <span class="n">memory_space</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">MemorySpace</span><span class="o">.</span><span class="n">ANY</span><span class="p">,</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">reduce_scatter_kernel</span><span class="p">(</span>
    <span class="n">x_ref</span><span class="p">,</span>
    <span class="n">o_ref</span><span class="p">,</span>
    <span class="n">hbm_scratch</span><span class="p">,</span>
    <span class="n">left_recv_sem</span><span class="p">,</span>
    <span class="n">left_send_sem</span><span class="p">,</span>
    <span class="n">copy_sem</span><span class="p">,</span>
    <span class="n">right_recv_sem</span><span class="p">,</span>
    <span class="n">right_send_sem</span><span class="p">,</span>
    <span class="n">left_capacity_sem</span><span class="p">,</span>
    <span class="n">right_capacity_sem</span><span class="p">,</span>
<span class="p">):</span>
  <span class="n">outer_step</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">program_id</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">phase</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">program_id</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">is_start</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">outer_step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="n">phase</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
  <span class="n">last_iteration</span> <span class="o">=</span> <span class="n">outer_step</span> <span class="o">==</span> <span class="n">pl</span><span class="o">.</span><span class="n">num_programs</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>

  <span class="n">working_slot</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">rem</span><span class="p">(</span><span class="n">outer_step</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
  <span class="n">receiving_slot</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">working_slot</span>
  <span class="n">my_id</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">axis_index</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
  <span class="n">right_neighbor</span> <span class="o">=</span> <span class="n">mod</span><span class="p">(</span><span class="n">my_id</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">)</span>
  <span class="n">left_neighbor</span> <span class="o">=</span> <span class="n">mod</span><span class="p">(</span><span class="n">my_id</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">)</span>

  <span class="n">left_copy_device</span> <span class="o">=</span> <span class="n">mod</span><span class="p">(</span><span class="n">my_id</span> <span class="o">+</span> <span class="n">outer_step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">)</span>
  <span class="n">right_copy_device</span> <span class="o">=</span> <span class="n">mod</span><span class="p">(</span><span class="n">my_id</span> <span class="o">-</span> <span class="n">outer_step</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_devices</span><span class="p">)</span>
  <span class="n">left_copy_slice</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">ds</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">outer_block_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
  <span class="n">right_copy_slice</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">ds</span><span class="p">(</span><span class="n">outer_block_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">outer_block_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
  <span class="n">current_phase_slice</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">ds</span><span class="p">(</span>
      <span class="n">phase</span> <span class="o">*</span> <span class="p">(</span><span class="n">outer_block_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span><span class="p">),</span> <span class="n">outer_block_size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">2</span>
  <span class="p">)</span>

  <span class="n">initial_left_copy</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">make_async_remote_copy</span><span class="p">(</span>
      <span class="n">src_ref</span><span class="o">=</span><span class="n">x_ref</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">my_id</span><span class="p">,</span> <span class="n">left_copy_slice</span><span class="p">],</span>
      <span class="n">dst_ref</span><span class="o">=</span><span class="n">hbm_scratch</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">working_slot</span><span class="p">,</span> <span class="n">left_copy_slice</span><span class="p">],</span>
      <span class="n">send_sem</span><span class="o">=</span><span class="n">left_send_sem</span><span class="p">,</span>
      <span class="n">recv_sem</span><span class="o">=</span><span class="n">left_recv_sem</span><span class="p">,</span>
      <span class="n">device_id</span><span class="o">=</span><span class="p">(</span><span class="n">left_neighbor</span><span class="p">,),</span>
      <span class="n">device_id_type</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">DeviceIdType</span><span class="o">.</span><span class="n">MESH</span><span class="p">,</span>
  <span class="p">)</span>

  <span class="n">initial_right_copy</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">make_async_remote_copy</span><span class="p">(</span>
      <span class="n">src_ref</span><span class="o">=</span><span class="n">x_ref</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">my_id</span><span class="p">,</span> <span class="n">right_copy_slice</span><span class="p">],</span>
      <span class="n">dst_ref</span><span class="o">=</span><span class="n">hbm_scratch</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">working_slot</span><span class="p">,</span> <span class="n">right_copy_slice</span><span class="p">],</span>
      <span class="n">send_sem</span><span class="o">=</span><span class="n">right_send_sem</span><span class="p">,</span>
      <span class="n">recv_sem</span><span class="o">=</span><span class="n">right_recv_sem</span><span class="p">,</span>
      <span class="n">device_id</span><span class="o">=</span><span class="p">(</span><span class="n">right_neighbor</span><span class="p">,),</span>
      <span class="n">device_id_type</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">DeviceIdType</span><span class="o">.</span><span class="n">MESH</span><span class="p">,</span>
  <span class="p">)</span>

  <span class="n">left_copy</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">make_async_remote_copy</span><span class="p">(</span>
      <span class="n">src_ref</span><span class="o">=</span><span class="n">hbm_scratch</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">working_slot</span><span class="p">,</span> <span class="n">left_copy_slice</span><span class="p">],</span>
      <span class="n">dst_ref</span><span class="o">=</span><span class="n">hbm_scratch</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">receiving_slot</span><span class="p">,</span> <span class="n">left_copy_slice</span><span class="p">],</span>
      <span class="n">send_sem</span><span class="o">=</span><span class="n">left_send_sem</span><span class="p">,</span>
      <span class="n">recv_sem</span><span class="o">=</span><span class="n">left_recv_sem</span><span class="p">,</span>
      <span class="n">device_id</span><span class="o">=</span><span class="p">(</span><span class="n">left_neighbor</span><span class="p">,),</span>
      <span class="n">device_id_type</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">DeviceIdType</span><span class="o">.</span><span class="n">MESH</span><span class="p">,</span>
  <span class="p">)</span>
  <span class="n">right_copy</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">make_async_remote_copy</span><span class="p">(</span>
      <span class="n">src_ref</span><span class="o">=</span><span class="n">hbm_scratch</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">receiving_slot</span><span class="p">,</span> <span class="n">right_copy_slice</span><span class="p">],</span>
      <span class="n">dst_ref</span><span class="o">=</span><span class="n">hbm_scratch</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">working_slot</span><span class="p">,</span> <span class="n">right_copy_slice</span><span class="p">],</span>
      <span class="n">send_sem</span><span class="o">=</span><span class="n">right_send_sem</span><span class="p">,</span>
      <span class="n">recv_sem</span><span class="o">=</span><span class="n">right_recv_sem</span><span class="p">,</span>
      <span class="n">device_id</span><span class="o">=</span><span class="p">(</span><span class="n">right_neighbor</span><span class="p">,),</span>
      <span class="n">device_id_type</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">DeviceIdType</span><span class="o">.</span><span class="n">MESH</span><span class="p">,</span>
  <span class="p">)</span>

  <span class="c1"># --- Prologue ---</span>
  <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">is_start</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
    <span class="c1"># Barrier with both neighbors at the start, since we will be</span>
    <span class="c1"># communicating with both.</span>
    <span class="n">local_barrier</span><span class="p">(</span><span class="n">left_neighbor</span><span class="p">,</span> <span class="n">right_neighbor</span><span class="p">)</span>

    <span class="n">initial_left_copy</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
    <span class="n">initial_left_copy</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
    <span class="n">initial_right_copy</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

    <span class="c1"># We tell our left neighbor that it is allowed to send to the right.</span>
    <span class="c1"># (and vice versa for right neighbor)</span>
    <span class="n">signal</span><span class="p">(</span><span class="n">LEFT</span><span class="p">,</span> <span class="n">right_capacity_sem</span><span class="p">)</span>
    <span class="n">signal</span><span class="p">(</span><span class="n">RIGHT</span><span class="p">,</span> <span class="n">left_capacity_sem</span><span class="p">)</span>

  <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="o">~</span><span class="n">is_start</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
    <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">phase</span> <span class="o">==</span> <span class="n">LEFT</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
      <span class="c1"># We block here until our right neighbor tells use we can send to</span>
      <span class="c1"># the right.</span>
      <span class="n">pltpu</span><span class="o">.</span><span class="n">semaphore_wait</span><span class="p">(</span><span class="n">right_capacity_sem</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
      <span class="n">right_copy</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

    <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">phase</span> <span class="o">==</span> <span class="n">RIGHT</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
      <span class="c1"># We block here until our left neighbor tells use we can send to</span>
      <span class="c1"># the left.</span>
      <span class="n">pltpu</span><span class="o">.</span><span class="n">semaphore_wait</span><span class="p">(</span><span class="n">left_capacity_sem</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
      <span class="n">left_copy</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

  <span class="c1"># --- Body ---</span>
  <span class="k">def</span> <span class="nf">inner_kernel</span><span class="p">(</span><span class="n">input_ref</span><span class="p">,</span> <span class="n">accum_ref</span><span class="p">):</span>
    <span class="c1"># We do not explicitly use += because we set should_accumulate_out=True.</span>
    <span class="n">accum_ref</span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_ref</span><span class="p">[</span><span class="o">...</span><span class="p">]</span>

  <span class="n">accum_pipeline</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">emit_pipeline</span><span class="p">(</span>
      <span class="n">inner_kernel</span><span class="p">,</span>
      <span class="n">in_specs</span><span class="o">=</span><span class="p">[</span><span class="n">inner_block_spec</span><span class="p">],</span>
      <span class="n">out_specs</span><span class="o">=</span><span class="n">inner_block_spec</span><span class="p">,</span>
      <span class="n">should_accumulate_out</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
      <span class="n">grid</span><span class="o">=</span><span class="n">inner_grid</span><span class="p">,</span>
  <span class="p">)</span>

  <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="o">~</span><span class="n">last_iteration</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
    <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">phase</span> <span class="o">==</span> <span class="n">LEFT</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
      <span class="n">accum_pipeline</span><span class="p">(</span>
          <span class="n">x_ref</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">left_copy_device</span><span class="p">,</span> <span class="n">left_copy_slice</span><span class="p">],</span>
          <span class="n">hbm_scratch</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">working_slot</span><span class="p">,</span> <span class="n">left_copy_slice</span><span class="p">],</span>
      <span class="p">)</span>

    <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">phase</span> <span class="o">==</span> <span class="n">RIGHT</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
      <span class="n">accum_pipeline</span><span class="p">(</span>
          <span class="n">x_ref</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">right_copy_device</span><span class="p">,</span> <span class="n">right_copy_slice</span><span class="p">],</span>
          <span class="n">hbm_scratch</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">working_slot</span><span class="p">,</span> <span class="n">right_copy_slice</span><span class="p">],</span>
      <span class="p">)</span>

  <span class="c1"># --- Epilogue ---</span>
  <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">is_start</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
    <span class="n">initial_right_copy</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

  <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="o">~</span><span class="n">is_start</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
    <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">phase</span> <span class="o">==</span> <span class="n">LEFT</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
      <span class="n">right_copy</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
      <span class="n">signal</span><span class="p">(</span><span class="n">LEFT</span><span class="p">,</span> <span class="n">right_capacity_sem</span><span class="p">)</span>

    <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">phase</span> <span class="o">==</span> <span class="n">RIGHT</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
      <span class="n">left_copy</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
      <span class="n">signal</span><span class="p">(</span><span class="n">RIGHT</span><span class="p">,</span> <span class="n">left_capacity_sem</span><span class="p">)</span>

  <span class="c1"># Store result on last iteration.</span>
  <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">last_iteration</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
    <span class="n">output_copy</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">make_async_copy</span><span class="p">(</span>
        <span class="n">src_ref</span><span class="o">=</span><span class="n">hbm_scratch</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">working_slot</span><span class="p">,</span> <span class="n">current_phase_slice</span><span class="p">],</span>
        <span class="n">dst_ref</span><span class="o">=</span><span class="n">o_ref</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">current_phase_slice</span><span class="p">],</span>
        <span class="n">sem</span><span class="o">=</span><span class="n">copy_sem</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">output_copy</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
    <span class="n">output_copy</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

    <span class="c1"># Clean up semaphores so that they exit with a value of 0.</span>
    <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">phase</span> <span class="o">==</span> <span class="n">LEFT</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
      <span class="n">pltpu</span><span class="o">.</span><span class="n">semaphore_wait</span><span class="p">(</span><span class="n">right_capacity_sem</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="nd">@pl</span><span class="o">.</span><span class="n">when</span><span class="p">(</span><span class="n">phase</span> <span class="o">==</span> <span class="n">RIGHT</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_</span><span class="p">():</span>
      <span class="n">pltpu</span><span class="o">.</span><span class="n">semaphore_wait</span><span class="p">(</span><span class="n">left_capacity_sem</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>


<span class="n">out_shape</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">jax</span><span class="o">.</span><span class="n">ShapeDtypeStruct</span><span class="p">(</span>
        <span class="p">(</span><span class="n">outer_block_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">outer_block_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span>
    <span class="p">),</span>
    <span class="c1"># Shape: [working/recv, block[0], block[1]]</span>
    <span class="n">jax</span><span class="o">.</span><span class="n">ShapeDtypeStruct</span><span class="p">(</span>
        <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">outer_block_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">outer_block_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">float32</span>
    <span class="p">),</span>  <span class="c1"># hbm_scratch</span>
<span class="p">)</span>

<span class="n">grid_spec</span> <span class="o">=</span> <span class="n">pltpu</span><span class="o">.</span><span class="n">PrefetchScalarGridSpec</span><span class="p">(</span>
    <span class="n">num_scalar_prefetch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">in_specs</span><span class="o">=</span><span class="p">[</span>
        <span class="n">pl</span><span class="o">.</span><span class="n">BlockSpec</span><span class="p">(</span><span class="n">memory_space</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">MemorySpace</span><span class="o">.</span><span class="n">ANY</span><span class="p">),</span>
    <span class="p">],</span>
    <span class="n">out_specs</span><span class="o">=</span><span class="p">[</span>
        <span class="n">pl</span><span class="o">.</span><span class="n">BlockSpec</span><span class="p">(</span><span class="n">memory_space</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">MemorySpace</span><span class="o">.</span><span class="n">ANY</span><span class="p">),</span>
        <span class="n">pl</span><span class="o">.</span><span class="n">BlockSpec</span><span class="p">(</span><span class="n">memory_space</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">MemorySpace</span><span class="o">.</span><span class="n">ANY</span><span class="p">),</span>
    <span class="p">],</span>
    <span class="n">grid</span><span class="o">=</span><span class="p">(</span><span class="n">num_devices</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
    <span class="n">scratch_shapes</span><span class="o">=</span><span class="p">(</span>
        <span class="p">[</span><span class="n">pltpu</span><span class="o">.</span><span class="n">SemaphoreType</span><span class="o">.</span><span class="n">DMA</span><span class="p">]</span> <span class="o">*</span> <span class="mi">5</span>
        <span class="o">+</span> <span class="p">[</span><span class="n">pltpu</span><span class="o">.</span><span class="n">SemaphoreType</span><span class="o">.</span><span class="n">REGULAR</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span>  <span class="c1"># Capacity semaphores</span>
    <span class="p">),</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">pallas_reduce_scatter</span><span class="p">(</span><span class="n">input_arr</span><span class="p">):</span>
  <span class="n">input_arr</span> <span class="o">=</span> <span class="n">input_arr</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
      <span class="n">num_devices</span><span class="p">,</span> <span class="n">outer_block_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">outer_block_size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
  <span class="p">)</span>
  <span class="k">return</span> <span class="n">pl</span><span class="o">.</span><span class="n">pallas_call</span><span class="p">(</span>
      <span class="n">reduce_scatter_kernel</span><span class="p">,</span>
      <span class="n">out_shape</span><span class="o">=</span><span class="n">out_shape</span><span class="p">,</span>
      <span class="n">grid_spec</span><span class="o">=</span><span class="n">grid_spec</span><span class="p">,</span>
      <span class="n">compiler_params</span><span class="o">=</span><span class="n">pltpu</span><span class="o">.</span><span class="n">CompilerParams</span><span class="p">(</span><span class="n">collective_id</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
  <span class="p">)(</span><span class="n">input_arr</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>


<span class="n">pallas_result</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span>
    <span class="n">jax</span><span class="o">.</span><span class="n">shard_map</span><span class="p">(</span>
        <span class="n">pallas_reduce_scatter</span><span class="p">,</span>
        <span class="n">mesh</span><span class="o">=</span><span class="n">mesh</span><span class="p">,</span>
        <span class="n">in_specs</span><span class="o">=</span><span class="n">P</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;x&#39;</span><span class="p">),</span>
        <span class="n">out_specs</span><span class="o">=</span><span class="n">P</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
        <span class="n">check_vma</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)(</span><span class="n">input_arr</span><span class="p">)</span>

<span class="n">pallas_result</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">block_until_ready</span><span class="p">(</span><span class="n">pallas_result</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Now we compare our result to XLA.</span>
<span class="k">def</span> <span class="nf">lax_reduce_sum_scatter</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">num_devices</span><span class="p">,</span> <span class="n">outer_block_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">outer_block_size</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
  <span class="k">return</span> <span class="n">lax</span><span class="o">.</span><span class="n">psum_scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;x&#39;</span><span class="p">)</span>


<span class="n">xla_result</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">(</span>
    <span class="n">jax</span><span class="o">.</span><span class="n">shard_map</span><span class="p">(</span>
        <span class="n">lax_reduce_sum_scatter</span><span class="p">,</span>
        <span class="n">mesh</span><span class="o">=</span><span class="n">mesh</span><span class="p">,</span>
        <span class="n">in_specs</span><span class="o">=</span><span class="n">P</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;x&#39;</span><span class="p">),</span>
        <span class="n">out_specs</span><span class="o">=</span><span class="n">P</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
    <span class="p">)</span>
<span class="p">)(</span><span class="n">input_arr</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Input:&#39;</span><span class="p">,</span> <span class="n">input_arr</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">input_arr</span><span class="p">[::</span><span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Pallas Result:&#39;</span><span class="p">,</span> <span class="n">pallas_result</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">pallas_result</span><span class="p">[::</span><span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;lax.psum_scatter Result:&#39;</span><span class="p">,</span> <span class="n">xla_result</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">xla_result</span><span class="p">[::</span><span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s1">&#39;Difference |Pallas - lax.psum_scatter|:&#39;</span><span class="p">,</span>
    <span class="n">jnp</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">pallas_result</span> <span class="o">-</span> <span class="n">xla_result</span><span class="p">)),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Input: (16384, 16384) [0.74162567 0.0242182  0.27751946 ... 0.05213022 0.36088037 0.04494429]
Pallas Result: (16384, 4096) [2.0648427 1.674587  1.9148926 ... 1.3371865 1.3296283 1.2887063]
lax.psum_scatter Result: (16384, 4096) [2.0648427 1.674587  1.9148926 ... 1.3371865 1.3296283 1.2887063]
Difference |Pallas - lax.psum_scatter|: 2.3841858e-07
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="final-notes">
<h2>Final Notes<a class="headerlink" href="#final-notes" title="Link to this heading">#</a></h2>
<section id="megacore">
<h3>Megacore<a class="headerlink" href="#megacore" title="Link to this heading">#</a></h3>
<p>Certain TPUs contain multiple cores in a <a class="reference internal" href="pipelining.html#pallas-tpu-megacore"><span class="std std-ref">Megacore</span></a> configuration. In this configuration, our general recommendation is to only initiate DMAs from a single core, and only perform HBM-HBM transfers. To do this, set one of the grid axes to the number of cores (can be obtained via <code class="docutils literal notranslate"><span class="pre">jax.devices()[0].num_cores</span></code>) and the dimension_semantics to <code class="docutils literal notranslate"><span class="pre">&quot;parallel&quot;</span></code>. Then, you can use <code class="docutils literal notranslate"><span class="pre">core_index</span> <span class="pre">=</span> <span class="pre">pl.program_id(axis)</span></code> to obtain the core index along that axis, and use <code class="docutils literal notranslate"><span class="pre">&#64;pl.when(core_index==i)</span></code> to execute code specific to that core.</p>
</section>
<section id="interaction-with-xla">
<h3>Interaction with XLA<a class="headerlink" href="#interaction-with-xla" title="Link to this heading">#</a></h3>
<p>In this tutorial we covered several kernel examples which replicate the functionality of collective operations in JAX such as <code class="docutils literal notranslate"><span class="pre">lax.all_gather</span></code>, <code class="docutils literal notranslate"><span class="pre">lax.psum</span></code>, and <code class="docutils literal notranslate"><span class="pre">lax.psum_scatter</span></code>. An important caveat to note is that a Pallas kernel is somewhat opaque to the XLA compiler and may cause it to miss some optimizations it would normally perform. For example, XLA can asynchronously dispatch collective operations in order to interleave communication and computation without writing a custom kernel. This is not guaranteed to happen when Pallas kernels are involved so it is important to profile your program to see if this is an issue. Another example is the fact that the <code class="docutils literal notranslate"><span class="pre">emit_pipeline</span></code> function we used in this tutorial to generate nested pipelines is not visible to the XLA compiler, and therefore cannot be fused with neighboring operations.</p>
</section>
<section id="next-steps">
<h3>Next Steps<a class="headerlink" href="#next-steps" title="Link to this heading">#</a></h3>
<p>Excellent follow-up exercises for the reader could include implementing a distributed matrix multiplication, implementing <code class="docutils literal notranslate"><span class="pre">lax.all_to_all</span></code>, and relaxing synchronization to allow for additional run-ahead.</p>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="sparse.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Scalar Prefetch and Block-Sparse Computation</p>
      </div>
    </a>
    <a class="right-next"
       href="../gpu/index.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Pallas:Mosaic GPU</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tpu-topologies">TPU Topologies</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#remote-direct-memory-access-rdma-model">Remote Direct Memory Access (RDMA) Model</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#async-remote-copy-operation">Async Remote Copy Operation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dma-semaphores">DMA Semaphores</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#routing">Routing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#failure-modes">Failure modes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-right-permute-lax-ppermute">Example: Right Permute (<code class="docutils literal notranslate"><span class="pre">lax.ppermute</span></code>)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-all-gather-lax-all-gather">Example: All-gather (<code class="docutils literal notranslate"><span class="pre">lax.all_gather</span></code>)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#ring-communication-pattern">Ring Communication Pattern</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#advanced-techniques">Advanced Techniques</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#synchronization-regular-and-barrier-semaphores">Synchronization: Regular and Barrier Semaphores</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#regular-semaphores">Regular Semaphores</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#barrier-semaphores">Barrier Semaphores</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#double-buffering">Double-buffering</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-all-reduce-sum-lax-psum">Example: All-Reduce Sum (<code class="docutils literal notranslate"><span class="pre">lax.psum</span></code>)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#putting-it-all-together">Putting it all together</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#run-ahead-and-race-conditions">Run-ahead and Race Conditions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bi-directional-communication">Bi-directional Communication</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-bi-directional-reduce-scatter-lax-psum-scatter">Example: Bi-directional Reduce-Scatter (<code class="docutils literal notranslate"><span class="pre">lax.psum_scatter</span></code>)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#nested-remote-and-local-dma-pipelines">Nested Remote and Local DMA Pipelines</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-reduce-scatter-with-large-hbm-blocks">Example: Reduce-Scatter with large HBM blocks</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#final-notes">Final Notes</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#megacore">Megacore</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interaction-with-xla">Interaction with XLA</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#next-steps">Next Steps</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The JAX authors
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024, The JAX Authors.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>